{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1tOS7oWba4s"
   },
   "source": [
    "# Large language models (LLMs): Part II\n",
    "\n",
    "Author: Archit Vasan , including materials on LLMs by Varuni Sastri, and discussion/editorial work by Taylor Childers, Carlo Graziani, Bethany Lusch, and Venkat Vishwanath (Argonne)\n",
    "\n",
    "Inspiration from the blog posts \"The Illustrated Transformer\" and \"The Illustrated GPT2\" by Jay Alammar, highly recommended reading.\n",
    "\n",
    "Before you begin, make sure that you have your environment set up and your repo refreshed, as described in previous lessons, and reviewed in the accompanying 'Readme.md' file. Make sure that you select the kernel 'datascience/conda-2023-01-10' at the top-left of the Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "1. Training and inference using Hugging Face\n",
    "2. Elements of an LLM\n",
    "3. Attention mechanisms\n",
    "4. Positional encoding\n",
    "5. Output layers\n",
    "6. Training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HTTP_PROXY\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "os.environ[\"HTTPS_PROXY\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "os.environ[\"http_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "os.environ[\"https_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "os.environ[\"ftp_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM training and inference using HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/hf-logo-with-title.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "HuggingFace is a platform and community that provides open-source library tools and resources like pre-trained models and datasets.\n",
    "Refer to the following links for more information :\n",
    "\n",
    "https://huggingface.co/docs/hub/index\n",
    "\n",
    "https://huggingface.co/docs/transformers/en/index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: _Large Language Models are only as good as their training data. They have no ethics, no judgement, or editing ability. We will be using some pretrained models from Hugging Face which used wide samples of internet hosted text. The datasets have not been strictly filtered to restrict all malign content so the generated text may be surprisingly dark or questionable. They do not reflect our core values and are only used for demonstration purposes._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "We can use the Huggingface pipeline with a pretrained GPT2 model to generate text given a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 00:00:26.697740: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.12.2 when it was built against 1.12.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n",
      "/soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'My dog really wanted to look at my puppy, and when this pup got down to earth I told'},\n",
       " {'generated_text': 'My dog really wanted to get some exercise and I didn\\'t have to do anything,\" she said.'},\n",
       " {'generated_text': 'My dog really wanted to play because I felt like the idea of being good for him in the first'},\n",
       " {'generated_text': 'My dog really wanted to help me. She would not leave me feeling scared of him, nor did'},\n",
       " {'generated_text': 'My dog really wanted to be with my mom. She was super loving, especially for my big boy'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM, AutoConfig\n",
    "input_text = \"My dog really wanted to\"\n",
    "from transformers import pipeline\n",
    "generator = pipeline(\"text-generation\", model=\"openai-community/gpt2\")\n",
    "generator(input_text, max_length=20, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will cover  evaluation metrics,as well as safe and responsibilities practices when using LLMs in **Session 8**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load in our own dataset and train a model with this data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate in /home/bilgin/.local/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (1.13.0a0+git49444c3)\n",
      "Requirement already satisfied: huggingface-hub in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (0.12.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/bilgin/.local/lib/python3.10/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.4.0)\n",
      "Requirement already satisfied: filelock in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from huggingface-hub->accelerate) (3.9.0)\n",
      "Requirement already satisfied: requests in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.64.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2022.12.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
    "\n",
    "def load_dataset(train_path,test_path,tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128) \n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)   \n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset,test_dataset,data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "train_dataset,test_dataset,data_collator = load_dataset('dataset/train_input.txt','dataset/test_input.txt', tokenizer)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=3, # number of training epochs\n",
    "    per_device_train_batch_size=32, # batch size for training\n",
    "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
    "    eval_steps = 40, # Number of update steps between two evaluations.\n",
    "    save_steps=80, # after # steps model is saved \n",
    "    warmup_steps=50,# number of warmup steps for learning rate scheduler\n",
    "    prediction_loss_only=True,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is going on below the hood?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two components that are \"black-boxes\" here:\n",
    "1. The method for tokenization\n",
    "2. The model that generates novel text.\n",
    "\n",
    "Carlo Graziani already gave a great explanation of tokenization last week and how this affects embeddings (https://github.com/argonne-lcf/ai-science-training-series/blob/main/04_intro_to_llms/Sequential_Data_Models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will take a closer look at how the model is designed to deal with language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look inside GPT2! GPT2 incorporates the `GPT2LMHeadModel` architecture so let's inspect this more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/bilgin/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/bilgin/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/model.safetensors\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at openai-community/gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/bilgin/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "model = GPT2LMHeadModel.from_pretrained('openai-community/gpt2')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General elements of an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-2 is an example of the popular Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cig2mvfguetQ"
   },
   "source": [
    "<img src=\"images/decoder_only_block.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "Image credit: https://arxiv.org/pdf/1706.03762.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gray section in this figure is the Transfomer Decoder and it is the main mechanism GPT2 uses to encode context of language into its predictions.\n",
    "\n",
    "<img src=\"images/transformer-decoder-intro.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "Image credit: https://jalammar.github.io/illustrated-gpt2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Transformer-Decoder is composed of Decoder blocks stacked ontop of each other where each contains two types of layers: \n",
    "1. Masked Self-Attention and \n",
    "2. Feed Forward Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have already discussed Feed Forward Neural Networks in detail in the other lectures in this series. To review this, please look at https://github.com/argonne-lcf/ai-science-training-series/blob/main/02_intro_neural_networks/01_introduction_mnist.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we will \n",
    "* First, discuss attention mechanisms at length as this is arguably the greatest contribution by Transformers.\n",
    "* Second, extend the discussion from last week (https://github.com/argonne-lcf/ai-science-training-series/blob/main/04_intro_to_llms/Sequential_Data_Models.ipynb) on embedding input data while taking into account position.\n",
    "* Third, discuss outputting real text/sequences from the models.\n",
    "* Fourth, build a training loop for a mini-LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's set up all the imports we will need**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1482964b4b90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## IMPORTS\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4 ## so head_size = 16\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BowLYFlCrDrr"
   },
   "source": [
    "## Attention mechanisms\n",
    "\n",
    "Suppose the following sentence is an input sentence we want to translate using an LLM:\n",
    "\n",
    "`‚ÄùThe animal didn't cross the street because it was too tired‚Äù`\n",
    "\n",
    "Last week, Carlo mentioned that the Transformer learns an embedding of all words allowing interpretation of meanings of words.\n",
    "\n",
    "<img src=\"images/viz-bert-voc-verbs.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "So, if the model did a good job in token embedding, it will \"know\" what all the words in this sentence mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to understand a full sentence, the model also need to understand what each word means in relation to other words.\n",
    "\n",
    "For example, when we read the sentence:\n",
    "`‚ÄùThe animal didn't cross the street because it was too tired‚Äù`\n",
    "we know intuitively that the word `\"it\"` refers to `\"animal\"`, the state for `\"it\"` is `\"tired\"`, and the associated action is `\"didn't cross\"`.\n",
    "\n",
    "However, the model needs a way to learn all of this information in a simple yet generalizable way.\n",
    "What makes Transformers particularly powerful compared to earlier sequential architectures is how it encodes context with the **self-attention mechanism**.\n",
    "\n",
    "As the model processes each word in the input sequence, attention looks at other positions in the input sequence for clues to a better understanding for this word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transformer_self-attention_visualization.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGbAi0cJ7x3a"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-attention mechanisms use 3 vectors to encode the context of a word in a sequence with another word:\n",
    "1. Query: the word representation we score other words against using the other word's keys\n",
    "2. Key: labels for the words in a sequence that we match against the query\n",
    "3. Value: actual word representation. We will use the queries and keys to score the word's relevance to the query, and multiply this by the value. \n",
    "\n",
    "An analogy provided by Jay Alammar is thinking about attention as choosing a file from a file cabinet according to information on a post-it note. You can use the post-it note (query) to identify the folder (key) that most matches the topic you are looking up. Then you access the contents of the file (value) according to its relevance to your query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/self-attention-example-folders-3.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "Image credit: https://jalammar.github.io/illustrated-gpt2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our models, we can encode queries, keys, and values using simple linear layers with the same size (`sequence length, head_size`). During the training process, these layers will be updated to best encode context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 32 # channels\n",
    "head_size = 16\n",
    "\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jzf9VE_AqWeR"
   },
   "source": [
    "The algorithm for self-attention is as follows:\n",
    "\n",
    "1. Generate query, key and value vectors for each word\n",
    "2. Calculate a score for each word in the input sentence against each other.\n",
    "3. Divide the scores by the square root of the dimension of the key vectors to stabilize the gradients. This is then passed through a softmax operation.\n",
    "4. Multiply each value vector by the softmax score.\n",
    "5. Sum up the weighted value vectors to produce the output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/self-attention-output.png\" alt=\"Drawing\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOwm-NkXA8U3"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how attention is performed in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# Here we want the wei to be data dependent - ie gather info from the past but in a data dependant way\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16) # each token here (totally B*T) produce a key and query in parallel and independently\n",
    "q = query(x) # (B, T, 16)\n",
    "v = value(x)\n",
    "\n",
    "wei =  q @ k.transpose(-2, -1) * head_size**-0.5 # (B, T, 16) @ (B, 16, T) ---> (B, T, T). #\n",
    "wei = F.softmax(wei, dim=-1) # exponentiate and normalize giving a nice distibution that sums to 1 and\n",
    "                             # now it tells us that in a data dependent manner how much of info to aggregate from\n",
    "\n",
    "out = wei @ v # aggregate the attention scores and value vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0618, -0.0091, -0.3488,  0.3208,  0.2971, -0.1573, -0.0561,  0.1068,\n",
      "          0.0368,  0.0139, -0.0017,  0.3110,  0.1404, -0.0158,  0.1853,  0.4290],\n",
      "        [ 0.1578, -0.0971, -0.4256,  0.3538,  0.3621, -0.2392, -0.0536,  0.1759,\n",
      "          0.1115,  0.0282, -0.0649,  0.3641,  0.1928,  0.0261,  0.2162,  0.3758],\n",
      "        [ 0.1293,  0.0759, -0.2946,  0.2292,  0.2215, -0.0710, -0.0107,  0.1616,\n",
      "         -0.0930, -0.0877,  0.0567,  0.1899,  0.0311, -0.0894,  0.0309,  0.5471],\n",
      "        [ 0.1247,  0.1400, -0.2436,  0.1819,  0.1976,  0.0338, -0.0028,  0.1124,\n",
      "         -0.1477, -0.0748,  0.0650,  0.1392, -0.0314, -0.0989,  0.0613,  0.5433],\n",
      "        [ 0.0667,  0.1845, -0.2135,  0.2813,  0.2064,  0.0873,  0.0084,  0.2055,\n",
      "         -0.1130, -0.1466,  0.0459,  0.1923, -0.0275, -0.1107,  0.0065,  0.4674],\n",
      "        [ 0.1924,  0.1693, -0.1568,  0.2284,  0.1620,  0.0737,  0.0443,  0.2519,\n",
      "         -0.1912, -0.1979,  0.0832,  0.0713, -0.0826, -0.0848, -0.1047,  0.6089],\n",
      "        [ 0.1184,  0.0884, -0.2652,  0.2560,  0.1840,  0.0284, -0.0621,  0.1181,\n",
      "         -0.0880,  0.0104,  0.1123,  0.1850,  0.0369, -0.0730,  0.0663,  0.5242],\n",
      "        [ 0.1243,  0.0453, -0.3412,  0.2709,  0.2335, -0.0948, -0.0421,  0.2143,\n",
      "         -0.0330, -0.0313,  0.0520,  0.2378,  0.1084, -0.0959,  0.0300,  0.4707]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lwyFlxKW6oA"
   },
   "source": [
    "### Multi-head attention\n",
    "\n",
    "In practice, multiple attention heads are used which\n",
    "1. Expands the model‚Äôs ability to focus on different positions and prevent the attention to be dominated by the word itself.\n",
    "2. Have multiple ‚Äúrepresentation subspaces‚Äù. Have multiple sets of Query/Key/Value weight matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transformer_multi-headed_self-attention-recap.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oHsezdVBIaf"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see attention mechanisms in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the powerful visualization tool bertviz, which allows an interactive experience of the attention mechanisms. Normally these mechanisms are abstracted away but this will allow us to inspect our model in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bertviz in /home/bilgin/.local/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: transformers>=2.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from bertviz) (4.26.0)\n",
      "Requirement already satisfied: torch>=1.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from bertviz) (1.13.0a0+git49444c3)\n",
      "Requirement already satisfied: tqdm in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from bertviz) (4.64.1)\n",
      "Requirement already satisfied: boto3 in /home/bilgin/.local/lib/python3.10/site-packages (from bertviz) (1.34.65)\n",
      "Requirement already satisfied: requests in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from bertviz) (2.28.1)\n",
      "Requirement already satisfied: regex in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from bertviz) (2022.10.31)\n",
      "Requirement already satisfied: sentencepiece in /home/bilgin/.local/lib/python3.10/site-packages (from bertviz) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from torch>=1.0->bertviz) (4.4.0)\n",
      "Requirement already satisfied: filelock in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (0.13.2)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.65 in /home/bilgin/.local/lib/python3.10/site-packages (from boto3->bertviz) (1.34.65)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/bilgin/.local/lib/python3.10/site-packages (from boto3->bertviz) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/bilgin/.local/lib/python3.10/site-packages (from boto3->bertviz) (0.10.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->bertviz) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->bertviz) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->bertviz) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->bertviz) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.65->boto3->bertviz) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from packaging>=20.0->transformers>=2.0->bertviz) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.65->boto3->bertviz) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bertviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the model, GPT2 and look at the attention mechanisms. \n",
    "\n",
    "**Hint... click on the different blocks in the visualization to see the attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "      \n",
       "        <div id=\"bertviz-3184429b902a44e391e08b8445c2cee0\" style=\"font-family:'Helvetica Neue', Helvetica, Arial, sans-serif;\">\n",
       "            <span style=\"user-select:none\">\n",
       "                \n",
       "            </span>\n",
       "            <div id='vis'></div>\n",
       "        </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/**\n",
       " * @fileoverview Transformer Visualization D3 javascript code.\n",
       " *\n",
       " * Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n",
       " *\n",
       " * Change log:\n",
       " *\n",
       " * 02/01/19  Jesse Vig   Initial implementation\n",
       " * 12/31/20  Jesse Vig   Support multiple visualizations in single notebook.\n",
       " * 01/19/21  Jesse Vig   Support light/dark modes\n",
       " * 02/06/21  Jesse Vig   Move require config from separate jupyter notebook step\n",
       " * 05/03/21  Jesse Vig   Adjust visualization height dynamically\n",
       " * 03/23/22  Daniel SC   Update requirement URLs for d3 and jQuery (source of bug not allowing end result to be displayed on browsers)\n",
       " **/\n",
       "\n",
       "require.config({\n",
       "  paths: {\n",
       "      d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min',\n",
       "    jquery: 'https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
       "  }\n",
       "});\n",
       "\n",
       "requirejs(['jquery', 'd3'], function($, d3) {\n",
       "\n",
       "        const params = {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.961219847202301, 0.038780149072408676, 0.0, 0.0, 0.0, 0.0], [0.7466979026794434, 0.11987314373254776, 0.1334289014339447, 0.0, 0.0, 0.0], [0.5885030031204224, 0.13792067766189575, 0.212137371301651, 0.06143897399306297, 0.0, 0.0], [0.6570857763290405, 0.08996301889419556, 0.12751281261444092, 0.08361563086509705, 0.041822850704193115, 0.0], [0.2728874385356903, 0.11203353852033615, 0.1663985401391983, 0.08467111736536026, 0.16952736675739288, 0.19448210299015045]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010616563260555267, 0.9893833994865417, 0.0, 0.0, 0.0, 0.0], [0.0024677535984665155, 0.008448007516562939, 0.9890841841697693, 0.0, 0.0, 0.0], [0.0001232847134815529, 0.0018733182223513722, 0.013126976788043976, 0.9848763942718506, 0.0, 0.0], [0.0010669564362615347, 0.001136627048254013, 0.003034998197108507, 0.0015735096530988812, 0.9931879043579102, 0.0], [0.00019791982776951045, 0.0010528112761676311, 0.0015437351539731026, 0.0009642760851420462, 3.4924432839034125e-05, 0.9962062835693359]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.47578439116477966, 0.524215579032898, 0.0, 0.0, 0.0, 0.0], [0.5906045436859131, 0.2486611008644104, 0.16073434054851532, 0.0, 0.0, 0.0], [0.5529289841651917, 0.18856702744960785, 0.14457571506500244, 0.11392831057310104, 0.0, 0.0], [0.45094072818756104, 0.16486799716949463, 0.17318038642406464, 0.11748014390468597, 0.09353074431419373, 0.0], [0.4257245659828186, 0.1732865273952484, 0.15651953220367432, 0.07022649794816971, 0.0808701142668724, 0.09337282180786133]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6133623123168945, 0.38663768768310547, 0.0, 0.0, 0.0, 0.0], [0.06098509579896927, 0.03253461793065071, 0.9064802527427673, 0.0, 0.0, 0.0], [0.006717085838317871, 0.0004012881254311651, 0.7572958469390869, 0.23558568954467773, 0.0, 0.0], [0.03722766041755676, 0.002948855282738805, 0.10081092268228531, 0.04142269119620323, 0.8175898790359497, 0.0], [0.04989781975746155, 0.00030758307548239827, 0.0024198265746235847, 0.0034334994852542877, 0.0006823898293077946, 0.9432588815689087]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9489555954933167, 0.051044441759586334, 0.0, 0.0, 0.0, 0.0], [0.6821408867835999, 0.1395241767168045, 0.17833495140075684, 0.0, 0.0, 0.0], [0.20366324484348297, 0.05641487240791321, 0.06399301439523697, 0.6759288311004639, 0.0, 0.0], [0.3419547975063324, 0.06725440919399261, 0.07926183938980103, 0.1783619523048401, 0.3331669867038727, 0.0], [0.09464015811681747, 0.0074282134883105755, 0.006983973551541567, 0.0071843694895505905, 0.018724264577031136, 0.865039050579071]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33834606409072876, 0.6616539359092712, 0.0, 0.0, 0.0, 0.0], [0.07855993509292603, 0.006165449041873217, 0.9152746200561523, 0.0, 0.0, 0.0], [0.01677597686648369, 0.0004037705948576331, 0.003340460592880845, 0.9794798493385315, 0.0, 0.0], [0.027600426226854324, 0.00044415233423933387, 0.0006541680195368826, 0.0002266185765620321, 0.971074640750885, 0.0], [0.010248198173940182, 3.701553578139283e-05, 0.00016064041119534522, 2.7341819077264518e-05, 1.0187304724240676e-05, 0.98951655626297]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.982503354549408, 0.017496665939688683, 0.0, 0.0, 0.0, 0.0], [0.8874197006225586, 0.05467939004302025, 0.05790085718035698, 0.0, 0.0, 0.0], [0.6849910616874695, 0.1228068619966507, 0.04972026124596596, 0.14248186349868774, 0.0, 0.0], [0.6015856862068176, 0.09881888329982758, 0.07070108503103256, 0.16652540862560272, 0.06236903741955757, 0.0], [0.3232504427433014, 0.12567411363124847, 0.04432179778814316, 0.07076980918645859, 0.06606649607419968, 0.36991727352142334]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9191647171974182, 0.0808352455496788, 0.0, 0.0, 0.0, 0.0], [0.45986413955688477, 0.39703112840652466, 0.14310479164123535, 0.0, 0.0, 0.0], [0.3003872334957123, 0.22181738913059235, 0.38161516189575195, 0.09618020057678223, 0.0, 0.0], [0.18963925540447235, 0.1376371532678604, 0.20173484086990356, 0.23632164299488068, 0.23466713726520538, 0.0], [0.15410441160202026, 0.09489496797323227, 0.11902562528848648, 0.10277965664863586, 0.4317220449447632, 0.09747327119112015]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.364999920129776, 0.6350001096725464, 0.0, 0.0, 0.0, 0.0], [0.24595215916633606, 0.5519201755523682, 0.20212766528129578, 0.0, 0.0, 0.0], [0.2721358835697174, 0.40738627314567566, 0.25186213850975037, 0.06861574947834015, 0.0, 0.0], [0.10242555290460587, 0.16683615744113922, 0.524804949760437, 0.05445462837815285, 0.15147870779037476, 0.0], [0.25029507279396057, 0.22198128700256348, 0.18899968266487122, 0.10677118599414825, 0.1303267478942871, 0.10162602365016937]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6990506649017334, 0.3009493350982666, 0.0, 0.0, 0.0, 0.0], [0.5107942819595337, 0.2948642075061798, 0.1943415403366089, 0.0, 0.0, 0.0], [0.4604707360267639, 0.2805190980434418, 0.19174803793430328, 0.0672621801495552, 0.0, 0.0], [0.37648412585258484, 0.21120662987232208, 0.20214538276195526, 0.10207021236419678, 0.10809355974197388, 0.0], [0.30138441920280457, 0.20456179976463318, 0.18250338733196259, 0.11019382625818253, 0.1629127413034439, 0.03844383731484413]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7131582498550415, 0.2868417799472809, 0.0, 0.0, 0.0, 0.0], [0.4058799147605896, 0.18063297867774963, 0.41348710656166077, 0.0, 0.0, 0.0], [0.265546053647995, 0.1698586493730545, 0.3358593285083771, 0.228736013174057, 0.0, 0.0], [0.31385406851768494, 0.1831669807434082, 0.14928358793258667, 0.05377671495079994, 0.29991865158081055, 0.0], [0.20466560125350952, 0.18731118738651276, 0.15959151089191437, 0.06381776183843613, 0.03642302006483078, 0.34819093346595764]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6586242914199829, 0.3413757383823395, 0.0, 0.0, 0.0, 0.0], [0.5917776226997375, 0.3160035014152527, 0.0922188088297844, 0.0, 0.0, 0.0], [0.5477152466773987, 0.23586955666542053, 0.061456020921468735, 0.1549593061208725, 0.0, 0.0], [0.4587061107158661, 0.22439992427825928, 0.07887422293424606, 0.0992034301161766, 0.13881628215312958, 0.0], [0.32743722200393677, 0.19600819051265717, 0.068057119846344, 0.0892510637640953, 0.11618079245090485, 0.20306548476219177]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9961552023887634, 0.0038448425475507975, 0.0, 0.0, 0.0, 0.0], [0.8594854474067688, 0.06906110048294067, 0.07145342975854874, 0.0, 0.0, 0.0], [0.3800053000450134, 0.04127567633986473, 0.5496612787246704, 0.029057776555418968, 0.0, 0.0], [0.21445226669311523, 0.05088742449879646, 0.4317440092563629, 0.25869303941726685, 0.044223275035619736, 0.0], [0.11175256222486496, 0.017593080177903175, 0.027507441118359566, 0.04086771607398987, 0.7754669785499573, 0.026812179014086723]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9285967946052551, 0.07140326499938965, 0.0, 0.0, 0.0, 0.0], [0.6077286005020142, 0.3121427297592163, 0.08012867718935013, 0.0, 0.0, 0.0], [0.4942909777164459, 0.28503698110580444, 0.11849315464496613, 0.10217894613742828, 0.0, 0.0], [0.4183879494667053, 0.23117904365062714, 0.0834062322974205, 0.11365949362516403, 0.1533672958612442, 0.0], [0.42215850949287415, 0.12917140126228333, 0.08740927278995514, 0.1016375944018364, 0.21230268478393555, 0.04732053726911545]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9786475896835327, 0.02135237120091915, 0.0, 0.0, 0.0, 0.0], [0.7749121785163879, 0.06510371714830399, 0.15998409688472748, 0.0, 0.0, 0.0], [0.6484923362731934, 0.07483134418725967, 0.14751605689525604, 0.12916021049022675, 0.0, 0.0], [0.5224639773368835, 0.06921815127134323, 0.13823404908180237, 0.1110658198595047, 0.15901805460453033, 0.0], [0.3964517116546631, 0.07325823605060577, 0.12938153743743896, 0.1064242571592331, 0.14864002168178558, 0.1458442211151123]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5525906085968018, 0.44740936160087585, 0.0, 0.0, 0.0, 0.0], [0.5585009455680847, 0.2176259458065033, 0.22387312352657318, 0.0, 0.0, 0.0], [0.5143128633499146, 0.15964674949645996, 0.15491968393325806, 0.1711207628250122, 0.0, 0.0], [0.5039961338043213, 0.11401888728141785, 0.11974027007818222, 0.12552587687969208, 0.13671889901161194, 0.0], [0.5061842799186707, 0.08567393571138382, 0.08903021365404129, 0.09759818762540817, 0.1027572825551033, 0.11875619739294052]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9242545366287231, 0.07574543356895447, 0.0, 0.0, 0.0, 0.0], [0.8257425427436829, 0.07932533323764801, 0.09493216127157211, 0.0, 0.0, 0.0], [0.7306380271911621, 0.0857183039188385, 0.08043931424617767, 0.10320431739091873, 0.0, 0.0], [0.6383238434791565, 0.07886394113302231, 0.07815027981996536, 0.08758097141981125, 0.1170809343457222, 0.0], [0.5552157163619995, 0.07409121096134186, 0.06834889203310013, 0.07778600603342056, 0.09999319165945053, 0.12456497550010681]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8578913807868958, 0.14210854470729828, 0.0, 0.0, 0.0, 0.0], [0.6423038244247437, 0.166290283203125, 0.19140593707561493, 0.0, 0.0, 0.0], [0.5530979633331299, 0.10609274357557297, 0.07821257412433624, 0.26259663701057434, 0.0, 0.0], [0.40121692419052124, 0.12223611027002335, 0.1934729963541031, 0.14164622128009796, 0.14142780005931854, 0.0], [0.40212565660476685, 0.18450751900672913, 0.07516805827617645, 0.05849048122763634, 0.1444634348154068, 0.13524490594863892]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791558980941772, 0.020844051614403725, 0.0, 0.0, 0.0, 0.0], [0.8829841613769531, 0.06233249977231026, 0.05468335747718811, 0.0, 0.0, 0.0], [0.8105455040931702, 0.08617085963487625, 0.07321777194738388, 0.03006584383547306, 0.0, 0.0], [0.6819812059402466, 0.04990820586681366, 0.08296552300453186, 0.08369525521993637, 0.10144983977079391, 0.0], [0.4056689441204071, 0.07337666302919388, 0.08601408451795578, 0.061709366738796234, 0.13226434588432312, 0.2409665435552597]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9670190811157227, 0.03298088163137436, 0.0, 0.0, 0.0, 0.0], [0.8449064493179321, 0.0851450264453888, 0.06994850933551788, 0.0, 0.0, 0.0], [0.7123572826385498, 0.07896047830581665, 0.055410757660865784, 0.15327158570289612, 0.0, 0.0], [0.6402613520622253, 0.0739755630493164, 0.044393062591552734, 0.14322125911712646, 0.09814881533384323, 0.0], [0.5073903799057007, 0.07523059099912643, 0.07754647731781006, 0.11362491548061371, 0.13947951793670654, 0.08672808855772018]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8487569093704224, 0.1512431502342224, 0.0, 0.0, 0.0, 0.0], [0.8415648937225342, 0.12107233703136444, 0.03736274689435959, 0.0, 0.0, 0.0], [0.7505517601966858, 0.11348944902420044, 0.06179959326982498, 0.07415912300348282, 0.0, 0.0], [0.6614719033241272, 0.10242646187543869, 0.052934251725673676, 0.07529708743095398, 0.10787025839090347, 0.0], [0.6014202237129211, 0.11340376734733582, 0.05631929263472557, 0.07096721231937408, 0.10906282067298889, 0.04882663115859032]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9445484280586243, 0.05545158311724663, 0.0, 0.0, 0.0, 0.0], [0.8874568939208984, 0.05474215745925903, 0.0578010231256485, 0.0, 0.0, 0.0], [0.8281888961791992, 0.06895001977682114, 0.059034693986177444, 0.0438263975083828, 0.0, 0.0], [0.6429892778396606, 0.0674755647778511, 0.11629703640937805, 0.05417950078845024, 0.11905858665704727, 0.0], [0.7367823719978333, 0.056119054555892944, 0.06857288628816605, 0.034219540655612946, 0.0787537544965744, 0.02555238828063011]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002913394710049033, 0.9997085928916931, 0.0, 0.0, 0.0, 0.0], [0.0007981209782883525, 0.5288336873054504, 0.4703682065010071, 0.0, 0.0, 0.0], [0.0007648481405340135, 0.34519824385643005, 0.3085267245769501, 0.34551018476486206, 0.0, 0.0], [0.0010283143492415547, 0.241359144449234, 0.23320138454437256, 0.2555713355541229, 0.2688397467136383, 0.0], [0.0009746829164214432, 0.17789699137210846, 0.16743157804012299, 0.1858760118484497, 0.18734444677829742, 0.28047630190849304]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.824492871761322, 0.17550717294216156, 0.0, 0.0, 0.0, 0.0], [0.12386877834796906, 0.044499922543764114, 0.8316312432289124, 0.0, 0.0, 0.0], [0.07924355566501617, 0.01296587660908699, 0.0015277155907824636, 0.9062628149986267, 0.0, 0.0], [0.08806384354829788, 0.0213409923017025, 0.0028886159416288137, 0.002845379989594221, 0.884861171245575, 0.0], [0.09983218461275101, 0.03363388776779175, 0.0054999832063913345, 0.002433052286505699, 0.0015082412865012884, 0.8570926189422607]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9646892547607422, 0.03531072288751602, 0.0, 0.0, 0.0, 0.0], [0.7529157400131226, 0.08733473718166351, 0.15974950790405273, 0.0, 0.0, 0.0], [0.4202282726764679, 0.09195102006196976, 0.23549850285053253, 0.25232216715812683, 0.0, 0.0], [0.30848920345306396, 0.05908140912652016, 0.38391315937042236, 0.15659146010875702, 0.09192468225955963, 0.0], [0.44790443778038025, 0.04329312965273857, 0.0796918049454689, 0.11081931740045547, 0.22124572098255157, 0.09704558551311493]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.991096019744873, 0.008904009126126766, 0.0, 0.0, 0.0, 0.0], [0.9697675704956055, 0.026084503158926964, 0.004147922620177269, 0.0, 0.0, 0.0], [0.9082901477813721, 0.033206019550561905, 0.00942116230726242, 0.049082688987255096, 0.0, 0.0], [0.8949133157730103, 0.05544555187225342, 0.005577624775469303, 0.03150692582130432, 0.012556522153317928, 0.0], [0.8497740030288696, 0.028890123590826988, 0.0036647915840148926, 0.03751987963914871, 0.038427725434303284, 0.04172350466251373]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9984525442123413, 0.0015474462416023016, 0.0, 0.0, 0.0, 0.0], [0.48947831988334656, 0.4812193810939789, 0.029302269220352173, 0.0, 0.0, 0.0], [0.11772153526544571, 0.13121186196804047, 0.6702314615249634, 0.08083520829677582, 0.0, 0.0], [0.13043689727783203, 0.04068669304251671, 0.2652038037776947, 0.4114362895488739, 0.15223638713359833, 0.0], [0.12661904096603394, 0.03275119513273239, 0.03567872568964958, 0.06039190664887428, 0.6021825075149536, 0.1423766165971756]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9805176854133606, 0.019482342526316643, 0.0, 0.0, 0.0, 0.0], [0.7948849201202393, 0.12061909586191177, 0.08449601382017136, 0.0, 0.0, 0.0], [0.5612356066703796, 0.15743127465248108, 0.20339730381965637, 0.0779358446598053, 0.0, 0.0], [0.42583736777305603, 0.10742014646530151, 0.15123659372329712, 0.08755031228065491, 0.22795552015304565, 0.0], [0.24752654135227203, 0.024188270792365074, 0.03039524517953396, 0.08586956560611725, 0.5714336633682251, 0.040586672723293304]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887767434120178, 0.011223225854337215, 0.0, 0.0, 0.0, 0.0], [0.7572693228721619, 0.22317346930503845, 0.019557112827897072, 0.0, 0.0, 0.0], [0.5341880321502686, 0.22107566893100739, 0.1762184202671051, 0.06851787120103836, 0.0, 0.0], [0.17095312476158142, 0.0822940468788147, 0.576022207736969, 0.11097585409879684, 0.059754710644483566, 0.0], [0.2487109899520874, 0.08880793303251266, 0.08980197459459305, 0.09729334712028503, 0.4413093626499176, 0.03407646715641022]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8422133326530457, 0.15778663754463196, 0.0, 0.0, 0.0, 0.0], [0.468412846326828, 0.46105360984802246, 0.07053359597921371, 0.0, 0.0, 0.0], [0.2588140666484833, 0.4635888636112213, 0.18503506481647491, 0.09256205707788467, 0.0, 0.0], [0.18399578332901, 0.29154160618782043, 0.17031098902225494, 0.27173006534576416, 0.08242159336805344, 0.0], [0.1646990180015564, 0.2472696155309677, 0.08770562708377838, 0.22575001418590546, 0.1774536371231079, 0.09712201356887817]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9919946193695068, 0.008005390875041485, 0.0, 0.0, 0.0, 0.0], [0.9068724513053894, 0.044065121561288834, 0.04906242713332176, 0.0, 0.0, 0.0], [0.8582221865653992, 0.055348269641399384, 0.040419407188892365, 0.046010036021471024, 0.0, 0.0], [0.7855252623558044, 0.041242364794015884, 0.08369296044111252, 0.04887620359659195, 0.040663279592990875, 0.0], [0.7856317162513733, 0.05014643445611, 0.04751267284154892, 0.027365952730178833, 0.05614755302667618, 0.03319567069411278]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9041035175323486, 0.09589648246765137, 0.0, 0.0, 0.0, 0.0], [0.5862312912940979, 0.07199832051992416, 0.34177035093307495, 0.0, 0.0, 0.0], [0.3878960907459259, 0.04660807177424431, 0.20278996229171753, 0.36270591616630554, 0.0, 0.0], [0.2665242552757263, 0.024533024057745934, 0.12211935967206955, 0.20041218400001526, 0.386411190032959, 0.0], [0.23357485234737396, 0.02053728699684143, 0.09610321372747421, 0.13062246143817902, 0.22990450263023376, 0.289257675409317]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639912247657776, 0.036008793860673904, 0.0, 0.0, 0.0, 0.0], [0.7075552344322205, 0.2542775869369507, 0.038167137652635574, 0.0, 0.0, 0.0], [0.2566526234149933, 0.20589298009872437, 0.01665665954351425, 0.5207977294921875, 0.0, 0.0], [0.1037939190864563, 0.04639088362455368, 0.008698614314198494, 0.7866851687431335, 0.05443140119314194, 0.0], [0.2214341163635254, 0.03379744663834572, 0.029023902490735054, 0.541292130947113, 0.15286092460155487, 0.021591555327177048]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891703724861145, 0.010829661041498184, 0.0, 0.0, 0.0, 0.0], [0.7913155555725098, 0.12309625744819641, 0.08558809012174606, 0.0, 0.0, 0.0], [0.2954600155353546, 0.15808308124542236, 0.4217240810394287, 0.1247328370809555, 0.0, 0.0], [0.23440983891487122, 0.09886523336172104, 0.33160170912742615, 0.1971396654844284, 0.1379835456609726, 0.0], [0.19728390872478485, 0.05741839483380318, 0.06909029185771942, 0.16469819843769073, 0.2797277867794037, 0.23178131878376007]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9359127879142761, 0.0640871673822403, 0.0, 0.0, 0.0, 0.0], [0.7888627648353577, 0.08673475682735443, 0.12440246343612671, 0.0, 0.0, 0.0], [0.6535118818283081, 0.07573551684617996, 0.09732568264007568, 0.17342689633369446, 0.0, 0.0], [0.522276759147644, 0.058278825134038925, 0.09920477122068405, 0.17020836472511292, 0.15003129839897156, 0.0], [0.4108840823173523, 0.047306034713983536, 0.07265672832727432, 0.10560744255781174, 0.10550004243850708, 0.25804558396339417]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9683833122253418, 0.03161672502756119, 0.0, 0.0, 0.0, 0.0], [0.8965396881103516, 0.038870569318532944, 0.06458976864814758, 0.0, 0.0, 0.0], [0.8264952898025513, 0.03213464096188545, 0.05196719989180565, 0.0894029513001442, 0.0, 0.0], [0.7718173265457153, 0.030402837321162224, 0.045827414840459824, 0.07118473201990128, 0.08076759427785873, 0.0], [0.7292331457138062, 0.021699821576476097, 0.033074747771024704, 0.04720093309879303, 0.06474557518959045, 0.10404567420482635]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9979567527770996, 0.0020432830788195133, 0.0, 0.0, 0.0, 0.0], [0.955294132232666, 0.00802531372755766, 0.03668047487735748, 0.0, 0.0, 0.0], [0.9254710078239441, 0.002755576279014349, 0.0020629852078855038, 0.06971040368080139, 0.0, 0.0], [0.8660576939582825, 0.0038883681409060955, 0.0006785982404835522, 0.0006981453043408692, 0.1286771297454834, 0.0], [0.8455929160118103, 0.0037804055027663708, 0.000253423087997362, 6.0270751419011503e-05, 0.00011820747749879956, 0.15019479393959045]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9262455105781555, 0.07375453412532806, 0.0, 0.0, 0.0, 0.0], [0.7717157006263733, 0.16241952776908875, 0.06586471945047379, 0.0, 0.0, 0.0], [0.8167637586593628, 0.07807160913944244, 0.06324034929275513, 0.041924238204956055, 0.0, 0.0], [0.6867184638977051, 0.07755157351493835, 0.10056912153959274, 0.05955080687999725, 0.07561002671718597, 0.0], [0.6421161890029907, 0.11014898866415024, 0.07688194513320923, 0.054033469408750534, 0.10333634912967682, 0.013483096845448017]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9395954608917236, 0.060404520481824875, 0.0, 0.0, 0.0, 0.0], [0.23004619777202606, 0.6617380380630493, 0.1082158014178276, 0.0, 0.0, 0.0], [0.2670227289199829, 0.3607950508594513, 0.3249626159667969, 0.047219593077898026, 0.0, 0.0], [0.595201313495636, 0.12269274890422821, 0.06302059441804886, 0.08916817605495453, 0.12991715967655182, 0.0], [0.10284596681594849, 0.02938011661171913, 0.013739082030951977, 0.045860596001148224, 0.7698501348495483, 0.03832406550645828]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9040980935096741, 0.09590194374322891, 0.0, 0.0, 0.0, 0.0], [0.357237845659256, 0.6274612545967102, 0.015300876460969448, 0.0, 0.0, 0.0], [0.5917996764183044, 0.2764042019844055, 0.10476048290729523, 0.027035649865865707, 0.0, 0.0], [0.7254403829574585, 0.04983152449131012, 0.014982940629124641, 0.1778142899274826, 0.031930916011333466, 0.0], [0.7612743973731995, 0.06158972904086113, 0.005942251533269882, 0.01642685756087303, 0.1267806589603424, 0.0279861893504858]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9947587847709656, 0.005241230130195618, 0.0, 0.0, 0.0, 0.0], [0.9632415771484375, 0.017816413193941116, 0.018942030146718025, 0.0, 0.0, 0.0], [0.9671078324317932, 0.008509586565196514, 0.00856222677975893, 0.015820473432540894, 0.0, 0.0], [0.9340996146202087, 0.011952387169003487, 0.02018021047115326, 0.02675083465874195, 0.0070168930105865, 0.0], [0.9587237238883972, 0.004657115787267685, 0.003326789475977421, 0.006545313633978367, 0.010182461701333523, 0.016564540565013885]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9769991040229797, 0.023000910878181458, 0.0, 0.0, 0.0, 0.0], [0.7917609214782715, 0.1753319948911667, 0.032907065004110336, 0.0, 0.0, 0.0], [0.7949192523956299, 0.10531841963529587, 0.040218502283096313, 0.05954383686184883, 0.0, 0.0], [0.7097718715667725, 0.10552527755498886, 0.06597573310136795, 0.05765606462955475, 0.061070989817380905, 0.0], [0.7506601214408875, 0.026514461264014244, 0.021576043218374252, 0.034296683967113495, 0.08494450151920319, 0.08200812339782715]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983751654624939, 0.016248304396867752, 0.0, 0.0, 0.0, 0.0], [0.5615494847297668, 0.08956841379404068, 0.3488820493221283, 0.0, 0.0, 0.0], [0.32929039001464844, 0.024114903062582016, 0.5428059697151184, 0.10378880053758621, 0.0, 0.0], [0.34330207109451294, 0.01308644749224186, 0.5121983289718628, 0.11146228760480881, 0.019950881600379944, 0.0], [0.4792812764644623, 0.01733359508216381, 0.1180536150932312, 0.06130281835794449, 0.20071913301944733, 0.12330964207649231]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9908847212791443, 0.009115329943597317, 0.0, 0.0, 0.0, 0.0], [0.5282707214355469, 0.3292262554168701, 0.1425030380487442, 0.0, 0.0, 0.0], [0.48788541555404663, 0.23368670046329498, 0.17578084766864777, 0.10264702141284943, 0.0, 0.0], [0.31444698572158813, 0.18065163493156433, 0.168714240193367, 0.09506598114967346, 0.24112118780612946, 0.0], [0.5168765187263489, 0.035897161811590195, 0.026188155636191368, 0.04039734974503517, 0.18791745603084564, 0.1927233189344406]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8750308156013489, 0.12496919929981232, 0.0, 0.0, 0.0, 0.0], [0.4550614655017853, 0.4900427758693695, 0.05489582195878029, 0.0, 0.0, 0.0], [0.2933720052242279, 0.5449907183647156, 0.09444297850131989, 0.06719419360160828, 0.0, 0.0], [0.489708811044693, 0.2720997631549835, 0.06861965358257294, 0.14694802463054657, 0.022623788565397263, 0.0], [0.4729066491127014, 0.08103099465370178, 0.016052134335041046, 0.30672287940979004, 0.10120721161365509, 0.022080255672335625]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9630220532417297, 0.03697792813181877, 0.0, 0.0, 0.0, 0.0], [0.7557195425033569, 0.16436372697353363, 0.07991670072078705, 0.0, 0.0, 0.0], [0.6947705745697021, 0.08409853279590607, 0.0638260766863823, 0.15730486810207367, 0.0, 0.0], [0.5821147561073303, 0.03297805413603783, 0.07936596870422363, 0.19441406428813934, 0.11112712323665619, 0.0], [0.5974540710449219, 0.04261096194386482, 0.06919723749160767, 0.14563441276550293, 0.12481734901666641, 0.020285936072468758]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9957822561264038, 0.004217816516757011, 0.0, 0.0, 0.0, 0.0], [0.9312832951545715, 0.010560247115790844, 0.05815650522708893, 0.0, 0.0, 0.0], [0.8435326814651489, 0.015695005655288696, 0.045751139521598816, 0.09502115100622177, 0.0, 0.0], [0.772409975528717, 0.011981245130300522, 0.03504609689116478, 0.03876771405339241, 0.14179500937461853, 0.0], [0.7642908692359924, 0.009868789464235306, 0.00812275055795908, 0.013314393348991871, 0.04824395477771759, 0.15615922212600708]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9701177477836609, 0.02988232672214508, 0.0, 0.0, 0.0, 0.0], [0.6564007997512817, 0.22506150603294373, 0.11853761970996857, 0.0, 0.0, 0.0], [0.6958062648773193, 0.14701850712299347, 0.07145983725786209, 0.08571550250053406, 0.0, 0.0], [0.6353274583816528, 0.1346064656972885, 0.030994214117527008, 0.056916315108537674, 0.1421555131673813, 0.0], [0.6779401898384094, 0.053654152899980545, 0.01800631172955036, 0.06284520775079727, 0.1103820651769638, 0.07717210054397583]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9822334051132202, 0.017766647040843964, 0.0, 0.0, 0.0, 0.0], [0.9037663340568542, 0.06541544198989868, 0.03081829659640789, 0.0, 0.0, 0.0], [0.8119193911552429, 0.03679030388593674, 0.060560714453458786, 0.09072960168123245, 0.0, 0.0], [0.40546438097953796, 0.10383912175893784, 0.10211236774921417, 0.35434210300445557, 0.03424208238720894, 0.0], [0.22824221849441528, 0.017278727144002914, 0.05055465176701546, 0.6015752553939819, 0.09411764144897461, 0.008231506682932377]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873148202896118, 0.012685136869549751, 0.0, 0.0, 0.0, 0.0], [0.35445743799209595, 0.5317603349685669, 0.11378221958875656, 0.0, 0.0, 0.0], [0.07823363691568375, 0.7221359014511108, 0.10936623811721802, 0.090264230966568, 0.0, 0.0], [0.21967869997024536, 0.4048435091972351, 0.12358088046312332, 0.20018866658210754, 0.051708199083805084, 0.0], [0.36089760065078735, 0.10459021478891373, 0.06983799487352371, 0.2976483404636383, 0.13869903981685638, 0.02832675166428089]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9732162356376648, 0.0267837755382061, 0.0, 0.0, 0.0, 0.0], [0.9167553782463074, 0.061452705413103104, 0.02179192565381527, 0.0, 0.0, 0.0], [0.8543081283569336, 0.08049600571393967, 0.030334919691085815, 0.03486092761158943, 0.0, 0.0], [0.8919214606285095, 0.04280779883265495, 0.022045055404305458, 0.023470671847462654, 0.01975487545132637, 0.0], [0.8116763234138489, 0.03413533419370651, 0.03567665070295334, 0.04748587682843208, 0.0253971628844738, 0.04562860727310181]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502761960029602, 0.04972382262349129, 0.0, 0.0, 0.0, 0.0], [0.7637454271316528, 0.2007361352443695, 0.03551840782165527, 0.0, 0.0, 0.0], [0.6279097199440002, 0.03768139332532883, 0.1994536966085434, 0.13495522737503052, 0.0, 0.0], [0.6397060751914978, 0.027007432654500008, 0.09082036465406418, 0.20653828978538513, 0.03592785820364952, 0.0], [0.4559425115585327, 0.021641194820404053, 0.12939567863941193, 0.21800927817821503, 0.10379841923713684, 0.07121295481920242]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498406648635864, 0.050159383565187454, 0.0, 0.0, 0.0, 0.0], [0.8688724637031555, 0.0872218981385231, 0.043905653059482574, 0.0, 0.0, 0.0], [0.6937950253486633, 0.06359200924634933, 0.091790571808815, 0.15082231163978577, 0.0, 0.0], [0.7266597151756287, 0.04389883577823639, 0.04683985933661461, 0.09851823002099991, 0.08408336341381073, 0.0], [0.7848998308181763, 0.037147827446460724, 0.012907838448882103, 0.01053939200937748, 0.12079165875911713, 0.03371351957321167]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891054034233093, 0.01089458167552948, 0.0, 0.0, 0.0, 0.0], [0.8929519653320312, 0.08700055629014969, 0.02004752680659294, 0.0, 0.0, 0.0], [0.7891124486923218, 0.09797251224517822, 0.08633202314376831, 0.026582980528473854, 0.0, 0.0], [0.8850635886192322, 0.03645012155175209, 0.05395457148551941, 0.01237727515399456, 0.012154522351920605, 0.0], [0.6861329674720764, 0.05720378831028938, 0.011636304669082165, 0.021660611033439636, 0.1748800277709961, 0.048486363142728806]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9396191835403442, 0.06038080155849457, 0.0, 0.0, 0.0, 0.0], [0.7851794958114624, 0.19751444458961487, 0.017306052148342133, 0.0, 0.0, 0.0], [0.7660509943962097, 0.15444670617580414, 0.03188290074467659, 0.04761936888098717, 0.0, 0.0], [0.703522801399231, 0.05171430483460426, 0.07760990411043167, 0.1533905267715454, 0.013762423768639565, 0.0], [0.7121888399124146, 0.04994234815239906, 0.03772548958659172, 0.08649132400751114, 0.06541401147842407, 0.04823806509375572]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.974072277545929, 0.025927715003490448, 0.0, 0.0, 0.0, 0.0], [0.792539656162262, 0.01171559002250433, 0.19574476778507233, 0.0, 0.0, 0.0], [0.5106770992279053, 0.007296787109225988, 0.039619915187358856, 0.4424062669277191, 0.0, 0.0], [0.5862472057342529, 0.012099712155759335, 0.024585209786891937, 0.06737840175628662, 0.30968940258026123, 0.0], [0.30196306109428406, 0.007724012713879347, 0.011518122628331184, 0.046947259455919266, 0.22146707773208618, 0.41038045287132263]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9744554162025452, 0.02554464340209961, 0.0, 0.0, 0.0, 0.0], [0.9769195318222046, 0.015048524364829063, 0.008031901903450489, 0.0, 0.0, 0.0], [0.9060619473457336, 0.025875424966216087, 0.025954782962799072, 0.04210779070854187, 0.0, 0.0], [0.9400081038475037, 0.00555665697902441, 0.005828304681926966, 0.031757812947034836, 0.016849134117364883, 0.0], [0.9105738401412964, 0.0019752182997763157, 0.008646721951663494, 0.013360846787691116, 0.03543964773416519, 0.030003678053617477]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791666865348816, 0.020833350718021393, 0.0, 0.0, 0.0, 0.0], [0.8444858193397522, 0.13507869839668274, 0.020435383543372154, 0.0, 0.0, 0.0], [0.7903086543083191, 0.14559169113636017, 0.037529975175857544, 0.026569725945591927, 0.0, 0.0], [0.7298924326896667, 0.056496407836675644, 0.032735615968704224, 0.10400459170341492, 0.07687094807624817, 0.0], [0.5684185028076172, 0.04388832300901413, 0.026293467730283737, 0.0811714455485344, 0.24314835667610168, 0.037079911679029465]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9499868154525757, 0.05001320689916611, 0.0, 0.0, 0.0, 0.0], [0.9336170554161072, 0.05848868936300278, 0.007894262671470642, 0.0, 0.0, 0.0], [0.7897834181785583, 0.11071821302175522, 0.05360178276896477, 0.04589657858014107, 0.0, 0.0], [0.885930061340332, 0.05752986669540405, 0.01374326553195715, 0.0033877466339617968, 0.03940902277827263, 0.0], [0.9337607622146606, 0.02647063508629799, 0.004523396957665682, 0.0061904797330498695, 0.014132906682789326, 0.014921708963811398]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.8521224554035598e-09, 0.0, 0.0, 0.0, 0.0], [6.6758907451003324e-06, 0.9999804496765137, 1.2841281204600818e-05, 0.0, 0.0, 0.0], [2.2194194926328237e-08, 2.6684581211355862e-09, 0.9999971389770508, 2.8136880700913025e-06, 0.0, 0.0], [1.0145409987671883e-06, 4.464065739284706e-08, 0.00035356366424821317, 0.9993677735328674, 0.0002776293840724975, 0.0], [9.436550429953172e-10, 1.382057315812979e-11, 5.017835036369434e-10, 2.965183876213473e-09, 0.9999971389770508, 2.8644042231462663e-06]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9948632121086121, 0.005136783700436354, 0.0, 0.0, 0.0, 0.0], [0.9274215698242188, 0.01832387037575245, 0.05425456911325455, 0.0, 0.0, 0.0], [0.9678993225097656, 0.004143435508012772, 0.004314453341066837, 0.023642776533961296, 0.0, 0.0], [0.8999068737030029, 0.001467161695472896, 0.00029133574571460485, 0.002585014794021845, 0.09574954956769943, 0.0], [0.9386115670204163, 0.00022248300956562161, 0.0006146665546111763, 0.0015495637198910117, 0.030689461156725883, 0.028312424197793007]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9999959468841553, 4.042720775032649e-06, 0.0, 0.0, 0.0, 0.0], [0.9982761144638062, 3.2613831990602193e-06, 0.001720669330097735, 0.0, 0.0, 0.0], [0.9998809099197388, 5.328835683826583e-08, 6.376215537784446e-07, 0.00011847059795400128, 0.0, 0.0], [0.9996154308319092, 3.473169556400535e-07, 3.8920820344401363e-08, 4.468433303372876e-07, 0.00038369710091501474, 0.0], [0.9994840621948242, 1.655020476221125e-08, 2.8715557931491276e-08, 1.0638284493325045e-06, 0.0002126671897713095, 0.00030212008277885616]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9514135718345642, 0.048586405813694, 0.0, 0.0, 0.0, 0.0], [0.5749948024749756, 0.39028096199035645, 0.03472418338060379, 0.0, 0.0, 0.0], [0.7442318201065063, 0.1752411425113678, 0.0756477490067482, 0.004879283253103495, 0.0, 0.0], [0.5232070684432983, 0.09429339319467545, 0.1138191670179367, 0.19979268312454224, 0.06888769567012787, 0.0], [0.47472575306892395, 0.05636607110500336, 0.04530389606952667, 0.06967321783304214, 0.3098014295101166, 0.0441296212375164]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8734648823738098, 0.12653514742851257, 0.0, 0.0, 0.0, 0.0], [0.6097912788391113, 0.3541727066040039, 0.036036062985658646, 0.0, 0.0, 0.0], [0.45984190702438354, 0.38697871565818787, 0.0996011346578598, 0.05357823893427849, 0.0, 0.0], [0.572220504283905, 0.23636263608932495, 0.08344558626413345, 0.06921917200088501, 0.03875211998820305, 0.0], [0.5143564343452454, 0.16723087430000305, 0.09019406139850616, 0.0765448659658432, 0.10578085482120514, 0.04589281603693962]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.981228768825531, 0.018771231174468994, 0.0, 0.0, 0.0, 0.0], [0.6142941117286682, 0.3503977954387665, 0.0353081189095974, 0.0, 0.0, 0.0], [0.5770686268806458, 0.32858458161354065, 0.05508256331086159, 0.03926428034901619, 0.0, 0.0], [0.17188192903995514, 0.011042501777410507, 0.054578714072704315, 0.7326585650444031, 0.029838265851140022, 0.0], [0.3783015012741089, 0.017070062458515167, 0.021754134446382523, 0.4409688115119934, 0.06093813106417656, 0.08096737414598465]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9923112392425537, 0.007688735146075487, 0.0, 0.0, 0.0, 0.0], [0.9498787522315979, 0.016709784045815468, 0.03341152146458626, 0.0, 0.0, 0.0], [0.9961295127868652, 0.0008787295082584023, 0.0006868162308819592, 0.0023048371076583862, 0.0, 0.0], [0.9935757517814636, 0.0032634998206049204, 0.0009993825806304812, 0.00027932299417443573, 0.0018820574041455984, 0.0], [0.9907532930374146, 0.00021344318520277739, 0.0004595233185682446, 0.0007905619568191469, 0.004424723796546459, 0.003358350833877921]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9647740125656128, 0.03522596135735512, 0.0, 0.0, 0.0, 0.0], [0.8194130063056946, 0.1365436613559723, 0.04404333233833313, 0.0, 0.0, 0.0], [0.7584245800971985, 0.006878929678350687, 0.20653395354747772, 0.028162529692053795, 0.0, 0.0], [0.5298128128051758, 0.002678812015801668, 0.07857988774776459, 0.3598373234272003, 0.02909109927713871, 0.0], [0.7544413208961487, 0.00036782227107323706, 0.0019713479559868574, 0.00324004958383739, 0.1942344754934311, 0.04574500769376755]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9749131202697754, 0.02508680149912834, 0.0, 0.0, 0.0, 0.0], [0.9306471943855286, 0.05705660209059715, 0.012296222150325775, 0.0, 0.0, 0.0], [0.9305251836776733, 0.052770983427762985, 0.01111945416778326, 0.005584415514022112, 0.0, 0.0], [0.8863320350646973, 0.01292418036609888, 0.017724711447954178, 0.06150198355317116, 0.021517015993595123, 0.0], [0.791684627532959, 0.015036096796393394, 0.0317479707300663, 0.03392200171947479, 0.03707978501915932, 0.09052948653697968]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9608501195907593, 0.039149850606918335, 0.0, 0.0, 0.0, 0.0], [0.9121272563934326, 0.02257651649415493, 0.06529619544744492, 0.0, 0.0, 0.0], [0.9364108443260193, 0.015584447421133518, 0.024544963613152504, 0.02345985174179077, 0.0, 0.0], [0.9454620480537415, 0.006762288510799408, 0.022026237100362778, 0.009137796238064766, 0.016611700877547264, 0.0], [0.8346164226531982, 0.001881699077785015, 0.00560904573649168, 0.01887359470129013, 0.12449200451374054, 0.014527074061334133]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9964227080345154, 0.0035772807896137238, 0.0, 0.0, 0.0, 0.0], [0.9713928699493408, 0.024453025311231613, 0.004154058638960123, 0.0, 0.0, 0.0], [0.9735792279243469, 0.019003381952643394, 0.003664410673081875, 0.0037529165856540203, 0.0, 0.0], [0.9586312174797058, 0.007116180844604969, 0.009218388237059116, 0.022725583985447884, 0.0023084774147719145, 0.0], [0.973607063293457, 0.008490582928061485, 0.0032512471079826355, 0.003606445388868451, 0.004877461586147547, 0.006167212035506964]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.97598797082901, 0.024011990055441856, 0.0, 0.0, 0.0, 0.0], [0.9460638165473938, 0.04211375489830971, 0.011822436936199665, 0.0, 0.0, 0.0], [0.8446813225746155, 0.04293116182088852, 0.05218198522925377, 0.06020559370517731, 0.0, 0.0], [0.9378372430801392, 0.03354858607053757, 0.008826455101370811, 0.0028792242519557476, 0.016908427700400352, 0.0], [0.8124931454658508, 0.02696753479540348, 0.05999218672513962, 0.03445731848478317, 0.011011860333383083, 0.05507794767618179]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9001203775405884, 0.09987961500883102, 0.0, 0.0, 0.0, 0.0], [0.627193033695221, 0.07988718152046204, 0.29291975498199463, 0.0, 0.0, 0.0], [0.7624077796936035, 0.02734432928264141, 0.038679543882608414, 0.17156831920146942, 0.0, 0.0], [0.7995968461036682, 0.014336260966956615, 0.01437566988170147, 0.025438452139496803, 0.14625284075737, 0.0], [0.7851970791816711, 0.04204057529568672, 0.025253651663661003, 0.02908395044505596, 0.029306314885616302, 0.08911846578121185]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954467415809631, 0.0045532057993113995, 0.0, 0.0, 0.0, 0.0], [0.9356001615524292, 0.04476744681596756, 0.019632352516055107, 0.0, 0.0, 0.0], [0.5605552792549133, 0.09861977398395538, 0.29983264207839966, 0.040992289781570435, 0.0, 0.0], [0.5893709659576416, 0.11000988632440567, 0.08033622056245804, 0.16754034161567688, 0.05274256691336632, 0.0], [0.22305884957313538, 0.05680817365646362, 0.05467984080314636, 0.24733951687812805, 0.3111244738101959, 0.1069890558719635]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9301451444625854, 0.06985488533973694, 0.0, 0.0, 0.0, 0.0], [0.8936478495597839, 0.08535721153020859, 0.020994966849684715, 0.0, 0.0, 0.0], [0.8404538035392761, 0.10619214922189713, 0.02363673783838749, 0.029717326164245605, 0.0, 0.0], [0.8927386403083801, 0.024784674867987633, 0.008319000713527203, 0.05165454372763634, 0.022503145039081573, 0.0], [0.8646610975265503, 0.009503193199634552, 0.0024329854641109705, 0.04796753078699112, 0.04273205250501633, 0.03270319849252701]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9859625697135925, 0.014037408865988255, 0.0, 0.0, 0.0, 0.0], [0.9702037572860718, 0.0168070700019598, 0.012989125214517117, 0.0, 0.0, 0.0], [0.9524770379066467, 0.016064459457993507, 0.013456220738589764, 0.018002323806285858, 0.0, 0.0], [0.9332928657531738, 0.01897200010716915, 0.02014683373272419, 0.017023753374814987, 0.010564540512859821, 0.0], [0.9113592505455017, 0.012528638355433941, 0.02209620550274849, 0.01751861348748207, 0.018517911434173584, 0.01797938533127308]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9681769013404846, 0.03182310611009598, 0.0, 0.0, 0.0, 0.0], [0.9096417427062988, 0.07916690409183502, 0.011191264726221561, 0.0, 0.0, 0.0], [0.8379932045936584, 0.13078266382217407, 0.012140989303588867, 0.019083037972450256, 0.0, 0.0], [0.9116525053977966, 0.05451957508921623, 0.009499342180788517, 0.00746585289016366, 0.01686275750398636, 0.0], [0.8510289192199707, 0.07338211685419083, 0.008022507652640343, 0.009083161130547523, 0.04261006414890289, 0.015873271971940994]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9799023866653442, 0.020097682252526283, 0.0, 0.0, 0.0, 0.0], [0.9558742642402649, 0.029063312336802483, 0.015062497928738594, 0.0, 0.0, 0.0], [0.7943133115768433, 0.06074100360274315, 0.06907659024000168, 0.07586916536092758, 0.0, 0.0], [0.5494324564933777, 0.03154711425304413, 0.05482015758752823, 0.05788077041506767, 0.3063195049762726, 0.0], [0.6453980803489685, 0.010770943015813828, 0.017528092488646507, 0.02157985046505928, 0.24958276748657227, 0.05514020845293999]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9506809115409851, 0.0493190623819828, 0.0, 0.0, 0.0, 0.0], [0.8553215265274048, 0.09256264567375183, 0.05211575701832771, 0.0, 0.0, 0.0], [0.850852370262146, 0.04734604433178902, 0.044177331030368805, 0.057624250650405884, 0.0, 0.0], [0.7697131633758545, 0.02788589708507061, 0.031017286702990532, 0.06842502951622009, 0.1029587835073471, 0.0], [0.7931903004646301, 0.04052198305726051, 0.029242033138871193, 0.04478124529123306, 0.04894689470529556, 0.04331749677658081]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9770310521125793, 0.02296893112361431, 0.0, 0.0, 0.0, 0.0], [0.9429817199707031, 0.017321482300758362, 0.03969680890440941, 0.0, 0.0, 0.0], [0.9144344925880432, 0.008583576418459415, 0.013035810552537441, 0.06394599378108978, 0.0, 0.0], [0.9222429990768433, 0.0036440351977944374, 0.003740275977179408, 0.010410364717245102, 0.05996239185333252, 0.0], [0.9198879599571228, 0.0030822583939880133, 0.0034827394410967827, 0.004206796642392874, 0.02125428058207035, 0.048085976392030716]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.977458119392395, 0.022541873157024384, 0.0, 0.0, 0.0, 0.0], [0.8929325342178345, 0.07475466281175613, 0.032312843948602676, 0.0, 0.0, 0.0], [0.8423511385917664, 0.05980278551578522, 0.03740081936120987, 0.06044524535536766, 0.0, 0.0], [0.7674624919891357, 0.03536349534988403, 0.042155250906944275, 0.06658654659986496, 0.08843226730823517, 0.0], [0.6182611584663391, 0.01611059531569481, 0.020167622715234756, 0.03868892416357994, 0.23147016763687134, 0.07530155777931213]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9634856581687927, 0.036514393985271454, 0.0, 0.0, 0.0, 0.0], [0.4363938570022583, 0.522637128829956, 0.04096902906894684, 0.0, 0.0, 0.0], [0.3608614206314087, 0.35129693150520325, 0.2655103802680969, 0.022331148386001587, 0.0, 0.0], [0.3942921757698059, 0.021704670041799545, 0.07794328778982162, 0.37168896198272705, 0.1343708038330078, 0.0], [0.6310713887214661, 0.01698400266468525, 0.025942081585526466, 0.08615949749946594, 0.2183200567960739, 0.021522950381040573]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9988250136375427, 0.0011750265257433057, 0.0, 0.0, 0.0, 0.0], [0.9944871068000793, 0.0004826401418540627, 0.0050302306190133095, 0.0, 0.0, 0.0], [0.9981209635734558, 2.705173392314464e-05, 0.0001130745149566792, 0.0017389442073181272, 0.0, 0.0], [0.9982239603996277, 6.83655816828832e-05, 0.00010199935059063137, 6.028370262356475e-05, 0.0015453165397047997, 0.0], [0.9982888102531433, 1.055222810464329e-06, 3.2781026675365865e-05, 0.00013038977340329438, 0.0006605894886888564, 0.0008863684488460422]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9936710596084595, 0.006328921765089035, 0.0, 0.0, 0.0, 0.0], [0.9727688431739807, 0.0018561368342489004, 0.025375060737133026, 0.0, 0.0, 0.0], [0.9724299907684326, 0.0019586149137467146, 0.011192461475729942, 0.014418890699744225, 0.0, 0.0], [0.9782041311264038, 0.0009589138207957149, 0.0018706483533605933, 0.006326568778604269, 0.012639678083360195, 0.0], [0.9592596888542175, 0.0024555064737796783, 0.00161241355817765, 0.005019655916839838, 0.006687097251415253, 0.024965662509202957]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629000425338745, 0.03709998354315758, 0.0, 0.0, 0.0, 0.0], [0.36801934242248535, 0.6152258515357971, 0.016754813492298126, 0.0, 0.0, 0.0], [0.3173511326313019, 0.6140013337135315, 0.05375149846076965, 0.014896026812493801, 0.0, 0.0], [0.48987284302711487, 0.21071474254131317, 0.04693019017577171, 0.20700432360172272, 0.04547784850001335, 0.0], [0.48774227499961853, 0.1769528090953827, 0.06915216147899628, 0.09849268198013306, 0.12091436982154846, 0.046745721250772476]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9794419407844543, 0.020558049902319908, 0.0, 0.0, 0.0, 0.0], [0.6677903532981873, 0.31032365560531616, 0.021886007860302925, 0.0, 0.0, 0.0], [0.7118757367134094, 0.11108540743589401, 0.14187385141849518, 0.03516504913568497, 0.0, 0.0], [0.4501457214355469, 0.04036055505275726, 0.040458209812641144, 0.388570100069046, 0.08046531677246094, 0.0], [0.49346262216567993, 0.013696977868676186, 0.008126799948513508, 0.13074499368667603, 0.3086138069629669, 0.04535480588674545]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846054315567017, 0.015394587069749832, 0.0, 0.0, 0.0, 0.0], [0.9806739091873169, 0.007713791914284229, 0.011612347327172756, 0.0, 0.0, 0.0], [0.932663083076477, 0.01957838423550129, 0.02410353161394596, 0.023654978722333908, 0.0, 0.0], [0.9422016739845276, 0.0009538981830701232, 0.0010898025939241052, 0.00319337984547019, 0.05256118252873421, 0.0], [0.9352930784225464, 0.0010279357666149735, 0.004444425459951162, 0.001637140172533691, 0.010590963996946812, 0.04700646549463272]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9985783100128174, 0.0014216724084690213, 0.0, 0.0, 0.0, 0.0], [0.9893348813056946, 0.0011178902350366116, 0.00954714696854353, 0.0, 0.0, 0.0], [0.9979978203773499, 7.997050124686211e-05, 0.00013218850654084235, 0.0017900333041325212, 0.0, 0.0], [0.9986976385116577, 4.1044117097044364e-05, 3.8683547245454974e-06, 2.3676282580709085e-05, 0.0012337174266576767, 0.0], [0.9971563816070557, 1.852225250331685e-05, 1.8826559653462027e-06, 2.7900125132873654e-05, 0.0006533482228405774, 0.0021419788245111704]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9768233299255371, 0.023176640272140503, 0.0, 0.0, 0.0, 0.0], [0.9194678068161011, 0.05088186264038086, 0.029650341719388962, 0.0, 0.0, 0.0], [0.8474554419517517, 0.06100169196724892, 0.04372376948595047, 0.04781914874911308, 0.0, 0.0], [0.8011623620986938, 0.041866958141326904, 0.04375807195901871, 0.041894737631082535, 0.07131782174110413, 0.0], [0.8031871914863586, 0.02450493723154068, 0.017323585227131844, 0.04744395986199379, 0.06109930947422981, 0.046441152691841125]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9829428195953369, 0.01705716922879219, 0.0, 0.0, 0.0, 0.0], [0.8863736987113953, 0.09492647647857666, 0.018699750304222107, 0.0, 0.0, 0.0], [0.9231085777282715, 0.03696346655488014, 0.032198335975408554, 0.007729663979262114, 0.0, 0.0], [0.9068527221679688, 0.016046639531850815, 0.014310522936284542, 0.04543786868453026, 0.017352323979139328, 0.0], [0.6555973887443542, 0.05091019719839096, 0.028384855017066002, 0.1256549060344696, 0.10546853393316269, 0.03398407623171806]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502318501472473, 0.049768079072237015, 0.0, 0.0, 0.0, 0.0], [0.8829865455627441, 0.1000962108373642, 0.01691717840731144, 0.0, 0.0, 0.0], [0.8057457804679871, 0.14463546872138977, 0.03018922731280327, 0.019429458305239677, 0.0, 0.0], [0.8706230521202087, 0.032440632581710815, 0.026951627805829048, 0.04410304129123688, 0.025881657376885414, 0.0], [0.688364565372467, 0.009681451134383678, 0.016449343413114548, 0.0987110361456871, 0.08971209079027176, 0.09708156436681747]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9792683124542236, 0.02073168195784092, 0.0, 0.0, 0.0, 0.0], [0.9523284435272217, 0.025933818891644478, 0.021737735718488693, 0.0, 0.0, 0.0], [0.9144353270530701, 0.017671240493655205, 0.022358495742082596, 0.04553484544157982, 0.0, 0.0], [0.9448292851448059, 0.006467597559094429, 0.006386063527315855, 0.03263096138834953, 0.00968620739877224, 0.0], [0.9347906112670898, 0.007862505502998829, 0.007788175716996193, 0.021432818844914436, 0.008491144515573978, 0.01963483914732933]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983370304107666, 0.016629677265882492, 0.0, 0.0, 0.0, 0.0], [0.963111400604248, 0.009229931980371475, 0.027658598497509956, 0.0, 0.0, 0.0], [0.9706628322601318, 0.0041494048200547695, 0.0068131014704704285, 0.018374638631939888, 0.0, 0.0], [0.987951934337616, 0.002165885642170906, 0.00034901127219200134, 0.001583816367201507, 0.00794942770153284, 0.0], [0.9457950592041016, 0.014583553187549114, 0.0003652951563708484, 0.0009569536778144538, 0.013621564954519272, 0.02467755414545536]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9878059029579163, 0.01219407469034195, 0.0, 0.0, 0.0, 0.0], [0.87103670835495, 0.09448163211345673, 0.03448161482810974, 0.0, 0.0, 0.0], [0.6309783458709717, 0.11090382188558578, 0.1923021823167801, 0.06581564992666245, 0.0, 0.0], [0.5360490083694458, 0.04618944972753525, 0.13605308532714844, 0.26455509662628174, 0.017153292894363403, 0.0], [0.8287520408630371, 0.023732755333185196, 0.02008037269115448, 0.07245264202356339, 0.030431220307946205, 0.024550989270210266]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8995685577392578, 0.10043150931596756, 0.0, 0.0, 0.0, 0.0], [0.270343542098999, 0.6504329442977905, 0.07922357320785522, 0.0, 0.0, 0.0], [0.20541730523109436, 0.5892508625984192, 0.18085837364196777, 0.024473490193486214, 0.0, 0.0], [0.5573861002922058, 0.1774134784936905, 0.08806808292865753, 0.09881848096847534, 0.07831384986639023, 0.0], [0.5922912359237671, 0.08700639009475708, 0.05643285810947418, 0.05685883015394211, 0.12181518226861954, 0.08559554070234299]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9316380620002747, 0.06836195290088654, 0.0, 0.0, 0.0, 0.0], [0.9572945833206177, 0.026243582367897034, 0.0164618119597435, 0.0, 0.0, 0.0], [0.9880544543266296, 0.00427332753315568, 0.002954584313556552, 0.004717645235359669, 0.0, 0.0], [0.99403977394104, 0.0009413420339114964, 0.0004739820142276585, 0.00011646930943243206, 0.004428447224199772, 0.0], [0.9806035161018372, 2.5468933017691597e-05, 0.00016239412070717663, 0.0001476418401580304, 0.0013442443450912833, 0.017716845497488976]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.993178129196167, 0.006821857299655676, 0.0, 0.0, 0.0, 0.0], [0.9756524562835693, 0.01318411435931921, 0.011163423769176006, 0.0, 0.0, 0.0], [0.9418966770172119, 0.004721744451671839, 0.0023818055633455515, 0.050999753177165985, 0.0, 0.0], [0.9905040860176086, 0.0022848136723041534, 6.198462506290525e-05, 0.0005984465242363513, 0.006550676189363003, 0.0], [0.9697660207748413, 0.0008878845837898552, 0.00023466735729016364, 0.0017040816601365805, 0.004128355998545885, 0.02327893301844597]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9716231822967529, 0.02837684564292431, 0.0, 0.0, 0.0, 0.0], [0.9223619699478149, 0.028907248750329018, 0.048730745911598206, 0.0, 0.0, 0.0], [0.8426317572593689, 0.023872116580605507, 0.04748132824897766, 0.08601479232311249, 0.0, 0.0], [0.8521121740341187, 0.020744236186146736, 0.04494619369506836, 0.05765002593398094, 0.02454746514558792, 0.0], [0.8800725936889648, 0.022448532283306122, 0.018235722556710243, 0.01925482600927353, 0.015854258090257645, 0.044134121388196945]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9412723779678345, 0.058727629482746124, 0.0, 0.0, 0.0, 0.0], [0.916313886642456, 0.05759201943874359, 0.02609400637447834, 0.0, 0.0, 0.0], [0.8392423391342163, 0.057690516114234924, 0.01382902916520834, 0.08923812955617905, 0.0, 0.0], [0.8987162113189697, 0.0134778693318367, 0.0003456450067460537, 0.003298751311376691, 0.08416149020195007, 0.0], [0.8701692223548889, 0.002700856188312173, 0.00143499206751585, 0.0056661744602024555, 0.08874300867319107, 0.031285665929317474]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9656725525856018, 0.03432750701904297, 0.0, 0.0, 0.0, 0.0], [0.9178615808486938, 0.062257930636405945, 0.019880469888448715, 0.0, 0.0, 0.0], [0.823314905166626, 0.06282395124435425, 0.03670429438352585, 0.07715693861246109, 0.0, 0.0], [0.8501748442649841, 0.03816927224397659, 0.03196492791175842, 0.0516013503074646, 0.02808968350291252, 0.0], [0.6572404503822327, 0.05877397954463959, 0.04336007311940193, 0.09013211727142334, 0.08146599680185318, 0.06902744621038437]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9162061810493469, 0.0837937667965889, 0.0, 0.0, 0.0, 0.0], [0.9451773762702942, 0.04099284112453461, 0.013829832896590233, 0.0, 0.0, 0.0], [0.8928355574607849, 0.05368670076131821, 0.017596954479813576, 0.03588071092963219, 0.0, 0.0], [0.8337052464485168, 0.04799601063132286, 0.033513229340314865, 0.04680858924984932, 0.03797686845064163, 0.0], [0.8167192339897156, 0.06337132304906845, 0.013286277651786804, 0.020469767972826958, 0.025292355567216873, 0.06086111441254616]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9525133371353149, 0.04748663306236267, 0.0, 0.0, 0.0, 0.0], [0.3019869327545166, 0.6520938873291016, 0.04591925069689751, 0.0, 0.0, 0.0], [0.285582959651947, 0.556952178478241, 0.1444743126630783, 0.012990524061024189, 0.0, 0.0], [0.843804121017456, 0.032251205295324326, 0.03954290598630905, 0.06848159432411194, 0.015920041128993034, 0.0], [0.6664940714836121, 0.06095913052558899, 0.04064354673027992, 0.06804485619068146, 0.09186329692602158, 0.07199501991271973]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9682655334472656, 0.031734466552734375, 0.0, 0.0, 0.0, 0.0], [0.738521933555603, 0.22856839001178741, 0.032909639179706573, 0.0, 0.0, 0.0], [0.5946676135063171, 0.2303314357995987, 0.14867636561393738, 0.02632458508014679, 0.0, 0.0], [0.6339254975318909, 0.05813034623861313, 0.09654320776462555, 0.14291946589946747, 0.06848153471946716, 0.0], [0.40375572443008423, 0.08945391327142715, 0.07635112851858139, 0.25587135553359985, 0.1433039754629135, 0.03126389905810356]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9869793653488159, 0.013020593672990799, 0.0, 0.0, 0.0, 0.0], [0.8631385564804077, 0.1105666309595108, 0.02629482001066208, 0.0, 0.0, 0.0], [0.9488080143928528, 0.028614996001124382, 0.006535546388477087, 0.016041526570916176, 0.0, 0.0], [0.9672170877456665, 0.006604980677366257, 0.00045171406236477196, 0.004844417329877615, 0.020881708711385727, 0.0], [0.9354621171951294, 0.02047806605696678, 0.0011700231116265059, 0.007056943140923977, 0.0163181871175766, 0.019514625892043114]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846673011779785, 0.015332723967730999, 0.0, 0.0, 0.0, 0.0], [0.9052747488021851, 0.08373606950044632, 0.010989243164658546, 0.0, 0.0, 0.0], [0.8145939111709595, 0.04283742979168892, 0.10568301379680634, 0.03688570484519005, 0.0, 0.0], [0.23519809544086456, 0.012018457986414433, 0.05280117318034172, 0.6516180038452148, 0.04836418479681015, 0.0], [0.31818512082099915, 0.018632443621754646, 0.03948190063238144, 0.3755541741847992, 0.20787373185157776, 0.04027257487177849]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9811733365058899, 0.018826685845851898, 0.0, 0.0, 0.0, 0.0], [0.8618939518928528, 0.06479164958000183, 0.07331438362598419, 0.0, 0.0, 0.0], [0.7664540410041809, 0.07330425828695297, 0.10353513062000275, 0.056706514209508896, 0.0, 0.0], [0.8128499984741211, 0.03215480223298073, 0.059005625545978546, 0.05416511744260788, 0.04182446748018265, 0.0], [0.8687856197357178, 0.026987861841917038, 0.02047000452876091, 0.01629738137125969, 0.03218390792608261, 0.03527523949742317]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9264583587646484, 0.07354167848825455, 0.0, 0.0, 0.0, 0.0], [0.8403540849685669, 0.06373751163482666, 0.09590838104486465, 0.0, 0.0, 0.0], [0.7330995798110962, 0.06451118737459183, 0.10380073636770248, 0.09858842939138412, 0.0, 0.0], [0.9143612384796143, 0.008257776498794556, 0.007320381235331297, 0.017966248095035553, 0.05209439620375633, 0.0], [0.8971915245056152, 0.008555498905479908, 0.007019453682005405, 0.014860544353723526, 0.03399762138724327, 0.03837529569864273]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9180347919464111, 0.08196526020765305, 0.0, 0.0, 0.0, 0.0], [0.8328666687011719, 0.1219901517033577, 0.04514322429895401, 0.0, 0.0, 0.0], [0.7994157075881958, 0.0874413549900055, 0.03605784848332405, 0.07708510011434555, 0.0, 0.0], [0.880984902381897, 0.020749641582369804, 0.020554615184664726, 0.017120830714702606, 0.06058995798230171, 0.0], [0.745303213596344, 0.044334057718515396, 0.022549288347363472, 0.0331527441740036, 0.03357058763504028, 0.12109009176492691]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9867060780525208, 0.013293893076479435, 0.0, 0.0, 0.0, 0.0], [0.982177734375, 0.012414131313562393, 0.005408108700066805, 0.0, 0.0, 0.0], [0.9630486369132996, 0.015290752984583378, 0.010345698334276676, 0.0113149369135499, 0.0, 0.0], [0.9213568568229675, 0.014132463373243809, 0.017639216035604477, 0.016567690297961235, 0.030303770676255226, 0.0], [0.9373326301574707, 0.009064299054443836, 0.007548365276306868, 0.006576443091034889, 0.011827622540295124, 0.027650514617562294]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9951004385948181, 0.00489962799474597, 0.0, 0.0, 0.0, 0.0], [0.9476007223129272, 0.041407931596040726, 0.010991275310516357, 0.0, 0.0, 0.0], [0.9142175316810608, 0.023523783311247826, 0.039145033806562424, 0.023113621398806572, 0.0, 0.0], [0.9534738659858704, 0.008932933211326599, 0.015272765420377254, 0.007908251136541367, 0.014412266202270985, 0.0], [0.9427101016044617, 0.00823307130485773, 0.004650997929275036, 0.004178107250481844, 0.005463531706482172, 0.03476419299840927]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9543376564979553, 0.045662373304367065, 0.0, 0.0, 0.0, 0.0], [0.9696040749549866, 0.01954760029911995, 0.01084828469902277, 0.0, 0.0, 0.0], [0.9710449576377869, 0.012425386346876621, 0.008068876340985298, 0.008460716344416142, 0.0, 0.0], [0.9726192951202393, 0.002697656163945794, 0.00044831327977590263, 0.0013814778067171574, 0.022853154689073563, 0.0], [0.9675466418266296, 0.009613442234694958, 0.003203035332262516, 0.00424883933737874, 0.007442260626703501, 0.00794589426368475]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887008666992188, 0.011299116536974907, 0.0, 0.0, 0.0, 0.0], [0.9382632374763489, 0.04204244911670685, 0.019694412127137184, 0.0, 0.0, 0.0], [0.8351995944976807, 0.03487853705883026, 0.05134471505880356, 0.07857715338468552, 0.0, 0.0], [0.9042676687240601, 0.010541575029492378, 0.016426723450422287, 0.025921987369656563, 0.04284200444817543, 0.0], [0.8913140892982483, 0.00891267228871584, 0.005010711494833231, 0.008175632916390896, 0.013514749705791473, 0.07307209819555283]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8693912029266357, 0.13060881197452545, 0.0, 0.0, 0.0, 0.0], [0.3507988452911377, 0.606351912021637, 0.04284917935729027, 0.0, 0.0, 0.0], [0.35475659370422363, 0.3502019941806793, 0.24722407758235931, 0.04781729355454445, 0.0, 0.0], [0.35370609164237976, 0.03527737781405449, 0.09567111730575562, 0.449796199798584, 0.06554921716451645, 0.0], [0.4132595360279083, 0.09055527299642563, 0.05286579951643944, 0.174679696559906, 0.173848956823349, 0.09479076415300369]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629756212234497, 0.037024300545454025, 0.0, 0.0, 0.0, 0.0], [0.9756426811218262, 0.01965854875743389, 0.004698706325143576, 0.0, 0.0, 0.0], [0.9775736927986145, 0.013286248780786991, 0.0025590297300368547, 0.006581062916666269, 0.0, 0.0], [0.9870142936706543, 0.007388236932456493, 0.0009579154429957271, 0.0018318220973014832, 0.0028077505994588137, 0.0], [0.9409245848655701, 0.016633737832307816, 0.0022979143541306257, 0.0058906711637973785, 0.0055129327811300755, 0.02874022163450718]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.962827205657959, 0.037172831594944, 0.0, 0.0, 0.0, 0.0], [0.9582237601280212, 0.024641817435622215, 0.017134377732872963, 0.0, 0.0, 0.0], [0.9351300001144409, 0.015331573784351349, 0.014810982160270214, 0.034727465361356735, 0.0, 0.0], [0.9225171208381653, 0.010528750717639923, 0.011010154150426388, 0.01944003626704216, 0.036503832787275314, 0.0], [0.8420165777206421, 0.04357199743390083, 0.007488282397389412, 0.01496153138577938, 0.02385285682976246, 0.06810864061117172]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9926387071609497, 0.00736132962629199, 0.0, 0.0, 0.0, 0.0], [0.9957393407821655, 0.0033469819463789463, 0.000913690309971571, 0.0, 0.0, 0.0], [0.9869900345802307, 0.001974786864593625, 0.001524551771581173, 0.009510699659585953, 0.0, 0.0], [0.9933527708053589, 0.001020324882119894, 0.00034337223041802645, 0.0010291127255186439, 0.004254369530826807, 0.0], [0.9749016761779785, 0.00043480272870510817, 0.0004306558985263109, 0.0012364407302811742, 0.0015347707085311413, 0.021461669355630875]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9897475242614746, 0.010252462700009346, 0.0, 0.0, 0.0, 0.0], [0.9790639281272888, 0.01650906540453434, 0.0044270907528698444, 0.0, 0.0, 0.0], [0.9521436095237732, 0.029432358220219612, 0.008943161927163601, 0.009480923414230347, 0.0, 0.0], [0.939594030380249, 0.021510960534214973, 0.010278552770614624, 0.004555229097604752, 0.024061163887381554, 0.0], [0.9205074906349182, 0.016153652220964432, 0.010818594135344028, 0.01664440892636776, 0.014566398225724697, 0.021309375762939453]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9898501634597778, 0.010149780660867691, 0.0, 0.0, 0.0, 0.0], [0.9820910096168518, 0.006907520350068808, 0.011001535691320896, 0.0, 0.0, 0.0], [0.9684997200965881, 0.008987602777779102, 0.015342563390731812, 0.007170087192207575, 0.0, 0.0], [0.9274120330810547, 0.009485266171395779, 0.022066107019782066, 0.03222890570759773, 0.008807653561234474, 0.0], [0.900665819644928, 0.021623756736516953, 0.013808279298245907, 0.009843860752880573, 0.008521373383700848, 0.04553695768117905]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954444169998169, 0.004555588588118553, 0.0, 0.0, 0.0, 0.0], [0.995254397392273, 0.002460238989442587, 0.002285485854372382, 0.0, 0.0, 0.0], [0.9862446188926697, 0.0015168144600465894, 0.004072288051247597, 0.008166354149580002, 0.0, 0.0], [0.9889963865280151, 0.001226040069013834, 0.0007996349013410509, 0.0006774227367714047, 0.008300574496388435, 0.0], [0.9865202903747559, 0.00039427157025784254, 0.0009571771952323616, 0.0004954367759637535, 0.0009604979422874749, 0.010672281496226788]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9821295142173767, 0.017870500683784485, 0.0, 0.0, 0.0, 0.0], [0.7489436268806458, 0.22002726793289185, 0.031029189005494118, 0.0, 0.0, 0.0], [0.28547799587249756, 0.21125678718090057, 0.47871601581573486, 0.024549242109060287, 0.0, 0.0], [0.8056644201278687, 0.026974644511938095, 0.04302806034684181, 0.06993705034255981, 0.05439583212137222, 0.0], [0.3307209014892578, 0.022326624020934105, 0.016627125442028046, 0.08019453287124634, 0.41574832797050476, 0.13438253104686737]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9697746634483337, 0.030225319787859917, 0.0, 0.0, 0.0, 0.0], [0.9800565838813782, 0.015018894337117672, 0.004924521781504154, 0.0, 0.0, 0.0], [0.9237861037254333, 0.052764780819416046, 0.00630240747705102, 0.017146753147244453, 0.0, 0.0], [0.9451844096183777, 0.03618047758936882, 0.001989208161830902, 0.003958724904805422, 0.012687299400568008, 0.0], [0.9633325934410095, 0.018662991002202034, 0.0030418417882174253, 0.007070912979543209, 0.0050094155594706535, 0.002882065251469612]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873244762420654, 0.012675459496676922, 0.0, 0.0, 0.0, 0.0], [0.9904569983482361, 0.0055419523268938065, 0.004001122899353504, 0.0, 0.0, 0.0], [0.9814971685409546, 0.004653455223888159, 0.003725277027115226, 0.010124054737389088, 0.0, 0.0], [0.9744365811347961, 0.004632251337170601, 0.002379992976784706, 0.006518087349832058, 0.012033028528094292, 0.0], [0.9624497294425964, 0.0033743639942258596, 0.0013198587112128735, 0.0017275003483518958, 0.002944675739854574, 0.028183799237012863]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9807674288749695, 0.01923258602619171, 0.0, 0.0, 0.0, 0.0], [0.9664245843887329, 0.015413926914334297, 0.018161438405513763, 0.0, 0.0, 0.0], [0.9632682204246521, 0.004538117907941341, 0.002925391308963299, 0.029268190264701843, 0.0, 0.0], [0.9562349319458008, 0.0012223608791828156, 0.0005304080550558865, 0.00867149606347084, 0.03334089741110802, 0.0], [0.9657101035118103, 0.0009808284230530262, 0.0016686266753822565, 0.002634831238538027, 0.005866361316293478, 0.023139292374253273]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639716148376465, 0.036028459668159485, 0.0, 0.0, 0.0, 0.0], [0.9562800526618958, 0.03373315557837486, 0.009986846707761288, 0.0, 0.0, 0.0], [0.8539998531341553, 0.08073022216558456, 0.03334445133805275, 0.031925540417432785, 0.0, 0.0], [0.9547491073608398, 0.009605025872588158, 0.004146162886172533, 0.0020133228972554207, 0.029486361891031265, 0.0], [0.9331137537956238, 0.028699662536382675, 0.005477475933730602, 0.006368075497448444, 0.012613046914339066, 0.013728085905313492]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9392993450164795, 0.06070063263177872, 0.0, 0.0, 0.0, 0.0], [0.9298391342163086, 0.061895377933979034, 0.008265496231615543, 0.0, 0.0, 0.0], [0.8471823334693909, 0.09035038203001022, 0.01763608679175377, 0.044831156730651855, 0.0, 0.0], [0.8857703804969788, 0.03918175399303436, 0.007867704145610332, 0.02276589721441269, 0.04441439360380173, 0.0], [0.8563280701637268, 0.10088995099067688, 0.006531452294439077, 0.008485927246510983, 0.007368441205471754, 0.020396249368786812]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8353264331817627, 0.1646735519170761, 0.0, 0.0, 0.0, 0.0], [0.6160858869552612, 0.3137648403644562, 0.07014927268028259, 0.0, 0.0, 0.0], [0.34316325187683105, 0.2758493721485138, 0.1196604073047638, 0.26132699847221375, 0.0, 0.0], [0.5908172130584717, 0.050290752202272415, 0.041665926575660706, 0.2199493646621704, 0.0972767099738121, 0.0], [0.8481413125991821, 0.06318090111017227, 0.014733693562448025, 0.055267371237277985, 0.00901501253247261, 0.009661628864705563]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9627319574356079, 0.03726799786090851, 0.0, 0.0, 0.0, 0.0], [0.7757522463798523, 0.1799626499414444, 0.044285036623477936, 0.0, 0.0, 0.0], [0.6317060589790344, 0.24380716681480408, 0.10925652086734772, 0.015230235643684864, 0.0, 0.0], [0.9539909958839417, 0.018182311207056046, 0.011601822450757027, 0.012299076654016972, 0.003925766795873642, 0.0], [0.40356943011283875, 0.14237558841705322, 0.05661217123270035, 0.1975736767053604, 0.0929921343922615, 0.10687707364559174]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9802619218826294, 0.019738124683499336, 0.0, 0.0, 0.0, 0.0], [0.9873908162117004, 0.007800452411174774, 0.004808681085705757, 0.0, 0.0, 0.0], [0.9283918738365173, 0.008301235735416412, 0.01330565195530653, 0.05000120773911476, 0.0, 0.0], [0.8981055021286011, 0.015591299161314964, 0.010177576914429665, 0.039987027645111084, 0.0361386202275753, 0.0], [0.9753499031066895, 0.00035433052107691765, 0.0005866039427928627, 0.0011877501383423805, 0.0010750899091362953, 0.021446440368890762]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9295330047607422, 0.07046692818403244, 0.0, 0.0, 0.0, 0.0], [0.9361506104469299, 0.04116682708263397, 0.022682538256049156, 0.0, 0.0, 0.0], [0.8486821055412292, 0.05802798643708229, 0.024856165051460266, 0.0684337466955185, 0.0, 0.0], [0.8661180734634399, 0.02232467755675316, 0.010369130410254002, 0.02600197121500969, 0.07518619298934937, 0.0], [0.8074421882629395, 0.044382549822330475, 0.01849711686372757, 0.03357789292931557, 0.018561245873570442, 0.07753907144069672]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9680535197257996, 0.03194643557071686, 0.0, 0.0, 0.0, 0.0], [0.9693689942359924, 0.02568492479622364, 0.004946070723235607, 0.0, 0.0, 0.0], [0.9620568156242371, 0.022552406415343285, 0.005471326876431704, 0.009919456206262112, 0.0, 0.0], [0.9727528095245361, 0.010137127712368965, 0.000757327419705689, 0.0028828983195126057, 0.013469807803630829, 0.0], [0.9624635577201843, 0.0031109037809073925, 0.0010007602395489812, 0.0019475930603221059, 0.008266227319836617, 0.02321087196469307]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8542501330375671, 0.14574992656707764, 0.0, 0.0, 0.0, 0.0], [0.9725967645645142, 0.014116315171122551, 0.01328685600310564, 0.0, 0.0, 0.0], [0.9257621765136719, 0.03257262706756592, 0.01461210660636425, 0.027053095400333405, 0.0, 0.0], [0.7923423051834106, 0.027305101975798607, 0.01880674995481968, 0.13854165375232697, 0.023004096001386642, 0.0], [0.6152060627937317, 0.02665526419878006, 0.029352931305766106, 0.05590886250138283, 0.11611279845237732, 0.15676409006118774]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9804654121398926, 0.019534552469849586, 0.0, 0.0, 0.0, 0.0], [0.9882452487945557, 0.007509466726332903, 0.004245325922966003, 0.0, 0.0, 0.0], [0.9584206938743591, 0.0109635591506958, 0.010456060990691185, 0.020159708335995674, 0.0, 0.0], [0.9604811668395996, 0.007182627450674772, 0.003072339342907071, 0.006898913532495499, 0.02236509881913662, 0.0], [0.966888964176178, 0.0032812939025461674, 0.00550054432824254, 0.004234083462506533, 0.005038043484091759, 0.015057181939482689]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498194456100464, 0.05018055811524391, 0.0, 0.0, 0.0, 0.0], [0.9781363606452942, 0.016430046409368515, 0.0054335566237568855, 0.0, 0.0, 0.0], [0.8618696331977844, 0.036093585193157196, 0.07555554062128067, 0.026481209322810173, 0.0, 0.0], [0.5449837446212769, 0.015411133877933025, 0.023516526445746422, 0.25743600726127625, 0.15865260362625122, 0.0], [0.9571874737739563, 0.0030803855042904615, 0.0014446862041950226, 0.006861559115350246, 0.014818714000284672, 0.01660723052918911]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6156560778617859, 0.3843439519405365, 0.0, 0.0, 0.0, 0.0], [0.36760634183883667, 0.42816370725631714, 0.20423001050949097, 0.0, 0.0, 0.0], [0.16471554338932037, 0.4136792719364166, 0.2509237229824066, 0.17068152129650116, 0.0, 0.0], [0.4184456169605255, 0.1524762362241745, 0.10305401682853699, 0.11071498692035675, 0.21530911326408386, 0.0], [0.19686934351921082, 0.2014620453119278, 0.12827259302139282, 0.09203246980905533, 0.09167550504207611, 0.2896881103515625]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9027364253997803, 0.09726352989673615, 0.0, 0.0, 0.0, 0.0], [0.9736634492874146, 0.014004302211105824, 0.01233230996876955, 0.0, 0.0, 0.0], [0.8504456281661987, 0.05690572410821915, 0.032060906291007996, 0.06058764085173607, 0.0, 0.0], [0.7661210298538208, 0.03530392050743103, 0.03433045372366905, 0.09675204753875732, 0.06749245524406433, 0.0], [0.8650374412536621, 0.020085260272026062, 0.01149806659668684, 0.01855834573507309, 0.018430285155773163, 0.06639053672552109]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9653082489967346, 0.03469168767333031, 0.0, 0.0, 0.0, 0.0], [0.9816323518753052, 0.014176066033542156, 0.004191514104604721, 0.0, 0.0, 0.0], [0.9275256395339966, 0.04737218841910362, 0.01152826938778162, 0.013573966920375824, 0.0, 0.0], [0.9293117523193359, 0.025833239778876305, 0.007227106485515833, 0.014300585724413395, 0.02332727052271366, 0.0], [0.8895062804222107, 0.04689619690179825, 0.0047171092592179775, 0.006286581978201866, 0.00609014043584466, 0.04650374501943588]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8938026428222656, 0.10619727522134781, 0.0, 0.0, 0.0, 0.0], [0.8221707940101624, 0.06304481625556946, 0.11478441953659058, 0.0, 0.0, 0.0], [0.5047380924224854, 0.15375731885433197, 0.2277037501335144, 0.11380083113908768, 0.0, 0.0], [0.4082071781158447, 0.09066355973482132, 0.11696872115135193, 0.24553199112415314, 0.13862857222557068, 0.0], [0.7291035652160645, 0.06638889014720917, 0.023112818598747253, 0.031103096902370453, 0.057143256068229675, 0.09314827620983124]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9247531890869141, 0.07524678111076355, 0.0, 0.0, 0.0, 0.0], [0.8957376480102539, 0.06989553570747375, 0.03436679765582085, 0.0, 0.0, 0.0], [0.7924937605857849, 0.0960114598274231, 0.05509118735790253, 0.056403566151857376, 0.0, 0.0], [0.7891505360603333, 0.07880303263664246, 0.03840155899524689, 0.05396979674696922, 0.03967496380209923, 0.0], [0.7807856798171997, 0.0799354612827301, 0.042531758546829224, 0.03234211727976799, 0.0178169384598732, 0.046588052064180374]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9480886459350586, 0.05191127583384514, 0.0, 0.0, 0.0, 0.0], [0.863694965839386, 0.04756204038858414, 0.08874296396970749, 0.0, 0.0, 0.0], [0.9341371059417725, 0.022224076092243195, 0.022624483332037926, 0.021014342084527016, 0.0, 0.0], [0.9588143229484558, 0.008020909503102303, 0.004490078426897526, 0.005862293299287558, 0.022812429815530777, 0.0], [0.9385918378829956, 0.021227721124887466, 0.0048724692314863205, 0.010940189473330975, 0.009524582885205746, 0.014843451790511608]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9763734340667725, 0.023626558482646942, 0.0, 0.0, 0.0, 0.0], [0.9884802103042603, 0.005189393647015095, 0.0063303736969828606, 0.0, 0.0, 0.0], [0.9477092027664185, 0.0179851483553648, 0.010156610049307346, 0.024149026721715927, 0.0, 0.0], [0.967192530632019, 0.006552813574671745, 0.0033227826934307814, 0.00556332478299737, 0.017368387430906296, 0.0], [0.9584562182426453, 0.007502961438149214, 0.0051363310776650906, 0.008071648888289928, 0.005997124593704939, 0.014835843816399574]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.884070873260498, 0.11592914164066315, 0.0, 0.0, 0.0, 0.0], [0.9931254386901855, 0.005070806015282869, 0.0018038019770756364, 0.0, 0.0, 0.0], [0.9534159302711487, 0.02382904477417469, 0.007748977281153202, 0.015006075613200665, 0.0, 0.0], [0.9151289463043213, 0.010873105376958847, 0.013190957717597485, 0.011050421744585037, 0.04975655674934387, 0.0], [0.8769673109054565, 0.03385210782289505, 0.00848648976534605, 0.009969149716198444, 0.03468578681349754, 0.036039214581251144]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003709519514814019, 0.999629020690918, 0.0, 0.0, 0.0, 0.0], [6.525027856696397e-05, 0.3737829029560089, 0.6261518597602844, 0.0, 0.0, 0.0], [4.606018774211407e-05, 0.210508793592453, 0.4115968942642212, 0.3778482675552368, 0.0, 0.0], [4.753069515572861e-05, 0.11616954207420349, 0.23264272511005402, 0.3985331058502197, 0.2526070475578308, 0.0], [1.247641534973809e-06, 0.14819711446762085, 0.15813173353672028, 0.30074331164360046, 0.11939018964767456, 0.27353641390800476]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.971555769443512, 0.028444187715649605, 0.0, 0.0, 0.0, 0.0], [0.9529065489768982, 0.03233075141906738, 0.014762768521904945, 0.0, 0.0, 0.0], [0.9343128204345703, 0.02351292595267296, 0.02049802988767624, 0.021676240488886833, 0.0, 0.0], [0.9529678225517273, 0.00855141133069992, 0.004359325394034386, 0.008064556866884232, 0.026056913658976555, 0.0], [0.9653593897819519, 0.008487647399306297, 0.003499280195683241, 0.002721576252952218, 0.0032828773837536573, 0.016649367287755013]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8630780577659607, 0.13692188262939453, 0.0, 0.0, 0.0, 0.0], [0.7696157097816467, 0.0851333811879158, 0.14525099098682404, 0.0, 0.0, 0.0], [0.7133337259292603, 0.10170899331569672, 0.11931268870830536, 0.06564456224441528, 0.0, 0.0], [0.7186222076416016, 0.05444284901022911, 0.01386815495789051, 0.07808027416467667, 0.13498654961585999, 0.0], [0.7990148663520813, 0.05805593729019165, 0.009447019547224045, 0.017770467326045036, 0.02113853208720684, 0.09457314014434814]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9518988728523254, 0.048101115971803665, 0.0, 0.0, 0.0, 0.0], [0.8580653071403503, 0.02944577857851982, 0.11248888075351715, 0.0, 0.0, 0.0], [0.6577738523483276, 0.08513449877500534, 0.1261308640241623, 0.1309608370065689, 0.0, 0.0], [0.8087368607521057, 0.0323016420006752, 0.01841817982494831, 0.06856140494346619, 0.07198194414377213, 0.0], [0.6683295965194702, 0.13281384110450745, 0.021880635991692543, 0.02787741646170616, 0.04923408478498459, 0.0998644009232521]]]], \"left_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"], \"right_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"]}], \"default_filter\": \"0\", \"display_mode\": \"dark\", \"root_div_id\": \"bertviz-3184429b902a44e391e08b8445c2cee0\", \"include_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"include_heads\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"total_heads\": 12}; // HACK: {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.961219847202301, 0.038780149072408676, 0.0, 0.0, 0.0, 0.0], [0.7466979026794434, 0.11987314373254776, 0.1334289014339447, 0.0, 0.0, 0.0], [0.5885030031204224, 0.13792067766189575, 0.212137371301651, 0.06143897399306297, 0.0, 0.0], [0.6570857763290405, 0.08996301889419556, 0.12751281261444092, 0.08361563086509705, 0.041822850704193115, 0.0], [0.2728874385356903, 0.11203353852033615, 0.1663985401391983, 0.08467111736536026, 0.16952736675739288, 0.19448210299015045]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010616563260555267, 0.9893833994865417, 0.0, 0.0, 0.0, 0.0], [0.0024677535984665155, 0.008448007516562939, 0.9890841841697693, 0.0, 0.0, 0.0], [0.0001232847134815529, 0.0018733182223513722, 0.013126976788043976, 0.9848763942718506, 0.0, 0.0], [0.0010669564362615347, 0.001136627048254013, 0.003034998197108507, 0.0015735096530988812, 0.9931879043579102, 0.0], [0.00019791982776951045, 0.0010528112761676311, 0.0015437351539731026, 0.0009642760851420462, 3.4924432839034125e-05, 0.9962062835693359]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.47578439116477966, 0.524215579032898, 0.0, 0.0, 0.0, 0.0], [0.5906045436859131, 0.2486611008644104, 0.16073434054851532, 0.0, 0.0, 0.0], [0.5529289841651917, 0.18856702744960785, 0.14457571506500244, 0.11392831057310104, 0.0, 0.0], [0.45094072818756104, 0.16486799716949463, 0.17318038642406464, 0.11748014390468597, 0.09353074431419373, 0.0], [0.4257245659828186, 0.1732865273952484, 0.15651953220367432, 0.07022649794816971, 0.0808701142668724, 0.09337282180786133]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6133623123168945, 0.38663768768310547, 0.0, 0.0, 0.0, 0.0], [0.06098509579896927, 0.03253461793065071, 0.9064802527427673, 0.0, 0.0, 0.0], [0.006717085838317871, 0.0004012881254311651, 0.7572958469390869, 0.23558568954467773, 0.0, 0.0], [0.03722766041755676, 0.002948855282738805, 0.10081092268228531, 0.04142269119620323, 0.8175898790359497, 0.0], [0.04989781975746155, 0.00030758307548239827, 0.0024198265746235847, 0.0034334994852542877, 0.0006823898293077946, 0.9432588815689087]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9489555954933167, 0.051044441759586334, 0.0, 0.0, 0.0, 0.0], [0.6821408867835999, 0.1395241767168045, 0.17833495140075684, 0.0, 0.0, 0.0], [0.20366324484348297, 0.05641487240791321, 0.06399301439523697, 0.6759288311004639, 0.0, 0.0], [0.3419547975063324, 0.06725440919399261, 0.07926183938980103, 0.1783619523048401, 0.3331669867038727, 0.0], [0.09464015811681747, 0.0074282134883105755, 0.006983973551541567, 0.0071843694895505905, 0.018724264577031136, 0.865039050579071]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33834606409072876, 0.6616539359092712, 0.0, 0.0, 0.0, 0.0], [0.07855993509292603, 0.006165449041873217, 0.9152746200561523, 0.0, 0.0, 0.0], [0.01677597686648369, 0.0004037705948576331, 0.003340460592880845, 0.9794798493385315, 0.0, 0.0], [0.027600426226854324, 0.00044415233423933387, 0.0006541680195368826, 0.0002266185765620321, 0.971074640750885, 0.0], [0.010248198173940182, 3.701553578139283e-05, 0.00016064041119534522, 2.7341819077264518e-05, 1.0187304724240676e-05, 0.98951655626297]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.982503354549408, 0.017496665939688683, 0.0, 0.0, 0.0, 0.0], [0.8874197006225586, 0.05467939004302025, 0.05790085718035698, 0.0, 0.0, 0.0], [0.6849910616874695, 0.1228068619966507, 0.04972026124596596, 0.14248186349868774, 0.0, 0.0], [0.6015856862068176, 0.09881888329982758, 0.07070108503103256, 0.16652540862560272, 0.06236903741955757, 0.0], [0.3232504427433014, 0.12567411363124847, 0.04432179778814316, 0.07076980918645859, 0.06606649607419968, 0.36991727352142334]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9191647171974182, 0.0808352455496788, 0.0, 0.0, 0.0, 0.0], [0.45986413955688477, 0.39703112840652466, 0.14310479164123535, 0.0, 0.0, 0.0], [0.3003872334957123, 0.22181738913059235, 0.38161516189575195, 0.09618020057678223, 0.0, 0.0], [0.18963925540447235, 0.1376371532678604, 0.20173484086990356, 0.23632164299488068, 0.23466713726520538, 0.0], [0.15410441160202026, 0.09489496797323227, 0.11902562528848648, 0.10277965664863586, 0.4317220449447632, 0.09747327119112015]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.364999920129776, 0.6350001096725464, 0.0, 0.0, 0.0, 0.0], [0.24595215916633606, 0.5519201755523682, 0.20212766528129578, 0.0, 0.0, 0.0], [0.2721358835697174, 0.40738627314567566, 0.25186213850975037, 0.06861574947834015, 0.0, 0.0], [0.10242555290460587, 0.16683615744113922, 0.524804949760437, 0.05445462837815285, 0.15147870779037476, 0.0], [0.25029507279396057, 0.22198128700256348, 0.18899968266487122, 0.10677118599414825, 0.1303267478942871, 0.10162602365016937]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6990506649017334, 0.3009493350982666, 0.0, 0.0, 0.0, 0.0], [0.5107942819595337, 0.2948642075061798, 0.1943415403366089, 0.0, 0.0, 0.0], [0.4604707360267639, 0.2805190980434418, 0.19174803793430328, 0.0672621801495552, 0.0, 0.0], [0.37648412585258484, 0.21120662987232208, 0.20214538276195526, 0.10207021236419678, 0.10809355974197388, 0.0], [0.30138441920280457, 0.20456179976463318, 0.18250338733196259, 0.11019382625818253, 0.1629127413034439, 0.03844383731484413]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7131582498550415, 0.2868417799472809, 0.0, 0.0, 0.0, 0.0], [0.4058799147605896, 0.18063297867774963, 0.41348710656166077, 0.0, 0.0, 0.0], [0.265546053647995, 0.1698586493730545, 0.3358593285083771, 0.228736013174057, 0.0, 0.0], [0.31385406851768494, 0.1831669807434082, 0.14928358793258667, 0.05377671495079994, 0.29991865158081055, 0.0], [0.20466560125350952, 0.18731118738651276, 0.15959151089191437, 0.06381776183843613, 0.03642302006483078, 0.34819093346595764]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6586242914199829, 0.3413757383823395, 0.0, 0.0, 0.0, 0.0], [0.5917776226997375, 0.3160035014152527, 0.0922188088297844, 0.0, 0.0, 0.0], [0.5477152466773987, 0.23586955666542053, 0.061456020921468735, 0.1549593061208725, 0.0, 0.0], [0.4587061107158661, 0.22439992427825928, 0.07887422293424606, 0.0992034301161766, 0.13881628215312958, 0.0], [0.32743722200393677, 0.19600819051265717, 0.068057119846344, 0.0892510637640953, 0.11618079245090485, 0.20306548476219177]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9961552023887634, 0.0038448425475507975, 0.0, 0.0, 0.0, 0.0], [0.8594854474067688, 0.06906110048294067, 0.07145342975854874, 0.0, 0.0, 0.0], [0.3800053000450134, 0.04127567633986473, 0.5496612787246704, 0.029057776555418968, 0.0, 0.0], [0.21445226669311523, 0.05088742449879646, 0.4317440092563629, 0.25869303941726685, 0.044223275035619736, 0.0], [0.11175256222486496, 0.017593080177903175, 0.027507441118359566, 0.04086771607398987, 0.7754669785499573, 0.026812179014086723]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9285967946052551, 0.07140326499938965, 0.0, 0.0, 0.0, 0.0], [0.6077286005020142, 0.3121427297592163, 0.08012867718935013, 0.0, 0.0, 0.0], [0.4942909777164459, 0.28503698110580444, 0.11849315464496613, 0.10217894613742828, 0.0, 0.0], [0.4183879494667053, 0.23117904365062714, 0.0834062322974205, 0.11365949362516403, 0.1533672958612442, 0.0], [0.42215850949287415, 0.12917140126228333, 0.08740927278995514, 0.1016375944018364, 0.21230268478393555, 0.04732053726911545]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9786475896835327, 0.02135237120091915, 0.0, 0.0, 0.0, 0.0], [0.7749121785163879, 0.06510371714830399, 0.15998409688472748, 0.0, 0.0, 0.0], [0.6484923362731934, 0.07483134418725967, 0.14751605689525604, 0.12916021049022675, 0.0, 0.0], [0.5224639773368835, 0.06921815127134323, 0.13823404908180237, 0.1110658198595047, 0.15901805460453033, 0.0], [0.3964517116546631, 0.07325823605060577, 0.12938153743743896, 0.1064242571592331, 0.14864002168178558, 0.1458442211151123]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5525906085968018, 0.44740936160087585, 0.0, 0.0, 0.0, 0.0], [0.5585009455680847, 0.2176259458065033, 0.22387312352657318, 0.0, 0.0, 0.0], [0.5143128633499146, 0.15964674949645996, 0.15491968393325806, 0.1711207628250122, 0.0, 0.0], [0.5039961338043213, 0.11401888728141785, 0.11974027007818222, 0.12552587687969208, 0.13671889901161194, 0.0], [0.5061842799186707, 0.08567393571138382, 0.08903021365404129, 0.09759818762540817, 0.1027572825551033, 0.11875619739294052]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9242545366287231, 0.07574543356895447, 0.0, 0.0, 0.0, 0.0], [0.8257425427436829, 0.07932533323764801, 0.09493216127157211, 0.0, 0.0, 0.0], [0.7306380271911621, 0.0857183039188385, 0.08043931424617767, 0.10320431739091873, 0.0, 0.0], [0.6383238434791565, 0.07886394113302231, 0.07815027981996536, 0.08758097141981125, 0.1170809343457222, 0.0], [0.5552157163619995, 0.07409121096134186, 0.06834889203310013, 0.07778600603342056, 0.09999319165945053, 0.12456497550010681]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8578913807868958, 0.14210854470729828, 0.0, 0.0, 0.0, 0.0], [0.6423038244247437, 0.166290283203125, 0.19140593707561493, 0.0, 0.0, 0.0], [0.5530979633331299, 0.10609274357557297, 0.07821257412433624, 0.26259663701057434, 0.0, 0.0], [0.40121692419052124, 0.12223611027002335, 0.1934729963541031, 0.14164622128009796, 0.14142780005931854, 0.0], [0.40212565660476685, 0.18450751900672913, 0.07516805827617645, 0.05849048122763634, 0.1444634348154068, 0.13524490594863892]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791558980941772, 0.020844051614403725, 0.0, 0.0, 0.0, 0.0], [0.8829841613769531, 0.06233249977231026, 0.05468335747718811, 0.0, 0.0, 0.0], [0.8105455040931702, 0.08617085963487625, 0.07321777194738388, 0.03006584383547306, 0.0, 0.0], [0.6819812059402466, 0.04990820586681366, 0.08296552300453186, 0.08369525521993637, 0.10144983977079391, 0.0], [0.4056689441204071, 0.07337666302919388, 0.08601408451795578, 0.061709366738796234, 0.13226434588432312, 0.2409665435552597]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9670190811157227, 0.03298088163137436, 0.0, 0.0, 0.0, 0.0], [0.8449064493179321, 0.0851450264453888, 0.06994850933551788, 0.0, 0.0, 0.0], [0.7123572826385498, 0.07896047830581665, 0.055410757660865784, 0.15327158570289612, 0.0, 0.0], [0.6402613520622253, 0.0739755630493164, 0.044393062591552734, 0.14322125911712646, 0.09814881533384323, 0.0], [0.5073903799057007, 0.07523059099912643, 0.07754647731781006, 0.11362491548061371, 0.13947951793670654, 0.08672808855772018]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8487569093704224, 0.1512431502342224, 0.0, 0.0, 0.0, 0.0], [0.8415648937225342, 0.12107233703136444, 0.03736274689435959, 0.0, 0.0, 0.0], [0.7505517601966858, 0.11348944902420044, 0.06179959326982498, 0.07415912300348282, 0.0, 0.0], [0.6614719033241272, 0.10242646187543869, 0.052934251725673676, 0.07529708743095398, 0.10787025839090347, 0.0], [0.6014202237129211, 0.11340376734733582, 0.05631929263472557, 0.07096721231937408, 0.10906282067298889, 0.04882663115859032]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9445484280586243, 0.05545158311724663, 0.0, 0.0, 0.0, 0.0], [0.8874568939208984, 0.05474215745925903, 0.0578010231256485, 0.0, 0.0, 0.0], [0.8281888961791992, 0.06895001977682114, 0.059034693986177444, 0.0438263975083828, 0.0, 0.0], [0.6429892778396606, 0.0674755647778511, 0.11629703640937805, 0.05417950078845024, 0.11905858665704727, 0.0], [0.7367823719978333, 0.056119054555892944, 0.06857288628816605, 0.034219540655612946, 0.0787537544965744, 0.02555238828063011]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002913394710049033, 0.9997085928916931, 0.0, 0.0, 0.0, 0.0], [0.0007981209782883525, 0.5288336873054504, 0.4703682065010071, 0.0, 0.0, 0.0], [0.0007648481405340135, 0.34519824385643005, 0.3085267245769501, 0.34551018476486206, 0.0, 0.0], [0.0010283143492415547, 0.241359144449234, 0.23320138454437256, 0.2555713355541229, 0.2688397467136383, 0.0], [0.0009746829164214432, 0.17789699137210846, 0.16743157804012299, 0.1858760118484497, 0.18734444677829742, 0.28047630190849304]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.824492871761322, 0.17550717294216156, 0.0, 0.0, 0.0, 0.0], [0.12386877834796906, 0.044499922543764114, 0.8316312432289124, 0.0, 0.0, 0.0], [0.07924355566501617, 0.01296587660908699, 0.0015277155907824636, 0.9062628149986267, 0.0, 0.0], [0.08806384354829788, 0.0213409923017025, 0.0028886159416288137, 0.002845379989594221, 0.884861171245575, 0.0], [0.09983218461275101, 0.03363388776779175, 0.0054999832063913345, 0.002433052286505699, 0.0015082412865012884, 0.8570926189422607]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9646892547607422, 0.03531072288751602, 0.0, 0.0, 0.0, 0.0], [0.7529157400131226, 0.08733473718166351, 0.15974950790405273, 0.0, 0.0, 0.0], [0.4202282726764679, 0.09195102006196976, 0.23549850285053253, 0.25232216715812683, 0.0, 0.0], [0.30848920345306396, 0.05908140912652016, 0.38391315937042236, 0.15659146010875702, 0.09192468225955963, 0.0], [0.44790443778038025, 0.04329312965273857, 0.0796918049454689, 0.11081931740045547, 0.22124572098255157, 0.09704558551311493]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.991096019744873, 0.008904009126126766, 0.0, 0.0, 0.0, 0.0], [0.9697675704956055, 0.026084503158926964, 0.004147922620177269, 0.0, 0.0, 0.0], [0.9082901477813721, 0.033206019550561905, 0.00942116230726242, 0.049082688987255096, 0.0, 0.0], [0.8949133157730103, 0.05544555187225342, 0.005577624775469303, 0.03150692582130432, 0.012556522153317928, 0.0], [0.8497740030288696, 0.028890123590826988, 0.0036647915840148926, 0.03751987963914871, 0.038427725434303284, 0.04172350466251373]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9984525442123413, 0.0015474462416023016, 0.0, 0.0, 0.0, 0.0], [0.48947831988334656, 0.4812193810939789, 0.029302269220352173, 0.0, 0.0, 0.0], [0.11772153526544571, 0.13121186196804047, 0.6702314615249634, 0.08083520829677582, 0.0, 0.0], [0.13043689727783203, 0.04068669304251671, 0.2652038037776947, 0.4114362895488739, 0.15223638713359833, 0.0], [0.12661904096603394, 0.03275119513273239, 0.03567872568964958, 0.06039190664887428, 0.6021825075149536, 0.1423766165971756]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9805176854133606, 0.019482342526316643, 0.0, 0.0, 0.0, 0.0], [0.7948849201202393, 0.12061909586191177, 0.08449601382017136, 0.0, 0.0, 0.0], [0.5612356066703796, 0.15743127465248108, 0.20339730381965637, 0.0779358446598053, 0.0, 0.0], [0.42583736777305603, 0.10742014646530151, 0.15123659372329712, 0.08755031228065491, 0.22795552015304565, 0.0], [0.24752654135227203, 0.024188270792365074, 0.03039524517953396, 0.08586956560611725, 0.5714336633682251, 0.040586672723293304]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887767434120178, 0.011223225854337215, 0.0, 0.0, 0.0, 0.0], [0.7572693228721619, 0.22317346930503845, 0.019557112827897072, 0.0, 0.0, 0.0], [0.5341880321502686, 0.22107566893100739, 0.1762184202671051, 0.06851787120103836, 0.0, 0.0], [0.17095312476158142, 0.0822940468788147, 0.576022207736969, 0.11097585409879684, 0.059754710644483566, 0.0], [0.2487109899520874, 0.08880793303251266, 0.08980197459459305, 0.09729334712028503, 0.4413093626499176, 0.03407646715641022]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8422133326530457, 0.15778663754463196, 0.0, 0.0, 0.0, 0.0], [0.468412846326828, 0.46105360984802246, 0.07053359597921371, 0.0, 0.0, 0.0], [0.2588140666484833, 0.4635888636112213, 0.18503506481647491, 0.09256205707788467, 0.0, 0.0], [0.18399578332901, 0.29154160618782043, 0.17031098902225494, 0.27173006534576416, 0.08242159336805344, 0.0], [0.1646990180015564, 0.2472696155309677, 0.08770562708377838, 0.22575001418590546, 0.1774536371231079, 0.09712201356887817]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9919946193695068, 0.008005390875041485, 0.0, 0.0, 0.0, 0.0], [0.9068724513053894, 0.044065121561288834, 0.04906242713332176, 0.0, 0.0, 0.0], [0.8582221865653992, 0.055348269641399384, 0.040419407188892365, 0.046010036021471024, 0.0, 0.0], [0.7855252623558044, 0.041242364794015884, 0.08369296044111252, 0.04887620359659195, 0.040663279592990875, 0.0], [0.7856317162513733, 0.05014643445611, 0.04751267284154892, 0.027365952730178833, 0.05614755302667618, 0.03319567069411278]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9041035175323486, 0.09589648246765137, 0.0, 0.0, 0.0, 0.0], [0.5862312912940979, 0.07199832051992416, 0.34177035093307495, 0.0, 0.0, 0.0], [0.3878960907459259, 0.04660807177424431, 0.20278996229171753, 0.36270591616630554, 0.0, 0.0], [0.2665242552757263, 0.024533024057745934, 0.12211935967206955, 0.20041218400001526, 0.386411190032959, 0.0], [0.23357485234737396, 0.02053728699684143, 0.09610321372747421, 0.13062246143817902, 0.22990450263023376, 0.289257675409317]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639912247657776, 0.036008793860673904, 0.0, 0.0, 0.0, 0.0], [0.7075552344322205, 0.2542775869369507, 0.038167137652635574, 0.0, 0.0, 0.0], [0.2566526234149933, 0.20589298009872437, 0.01665665954351425, 0.5207977294921875, 0.0, 0.0], [0.1037939190864563, 0.04639088362455368, 0.008698614314198494, 0.7866851687431335, 0.05443140119314194, 0.0], [0.2214341163635254, 0.03379744663834572, 0.029023902490735054, 0.541292130947113, 0.15286092460155487, 0.021591555327177048]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891703724861145, 0.010829661041498184, 0.0, 0.0, 0.0, 0.0], [0.7913155555725098, 0.12309625744819641, 0.08558809012174606, 0.0, 0.0, 0.0], [0.2954600155353546, 0.15808308124542236, 0.4217240810394287, 0.1247328370809555, 0.0, 0.0], [0.23440983891487122, 0.09886523336172104, 0.33160170912742615, 0.1971396654844284, 0.1379835456609726, 0.0], [0.19728390872478485, 0.05741839483380318, 0.06909029185771942, 0.16469819843769073, 0.2797277867794037, 0.23178131878376007]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9359127879142761, 0.0640871673822403, 0.0, 0.0, 0.0, 0.0], [0.7888627648353577, 0.08673475682735443, 0.12440246343612671, 0.0, 0.0, 0.0], [0.6535118818283081, 0.07573551684617996, 0.09732568264007568, 0.17342689633369446, 0.0, 0.0], [0.522276759147644, 0.058278825134038925, 0.09920477122068405, 0.17020836472511292, 0.15003129839897156, 0.0], [0.4108840823173523, 0.047306034713983536, 0.07265672832727432, 0.10560744255781174, 0.10550004243850708, 0.25804558396339417]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9683833122253418, 0.03161672502756119, 0.0, 0.0, 0.0, 0.0], [0.8965396881103516, 0.038870569318532944, 0.06458976864814758, 0.0, 0.0, 0.0], [0.8264952898025513, 0.03213464096188545, 0.05196719989180565, 0.0894029513001442, 0.0, 0.0], [0.7718173265457153, 0.030402837321162224, 0.045827414840459824, 0.07118473201990128, 0.08076759427785873, 0.0], [0.7292331457138062, 0.021699821576476097, 0.033074747771024704, 0.04720093309879303, 0.06474557518959045, 0.10404567420482635]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9979567527770996, 0.0020432830788195133, 0.0, 0.0, 0.0, 0.0], [0.955294132232666, 0.00802531372755766, 0.03668047487735748, 0.0, 0.0, 0.0], [0.9254710078239441, 0.002755576279014349, 0.0020629852078855038, 0.06971040368080139, 0.0, 0.0], [0.8660576939582825, 0.0038883681409060955, 0.0006785982404835522, 0.0006981453043408692, 0.1286771297454834, 0.0], [0.8455929160118103, 0.0037804055027663708, 0.000253423087997362, 6.0270751419011503e-05, 0.00011820747749879956, 0.15019479393959045]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9262455105781555, 0.07375453412532806, 0.0, 0.0, 0.0, 0.0], [0.7717157006263733, 0.16241952776908875, 0.06586471945047379, 0.0, 0.0, 0.0], [0.8167637586593628, 0.07807160913944244, 0.06324034929275513, 0.041924238204956055, 0.0, 0.0], [0.6867184638977051, 0.07755157351493835, 0.10056912153959274, 0.05955080687999725, 0.07561002671718597, 0.0], [0.6421161890029907, 0.11014898866415024, 0.07688194513320923, 0.054033469408750534, 0.10333634912967682, 0.013483096845448017]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9395954608917236, 0.060404520481824875, 0.0, 0.0, 0.0, 0.0], [0.23004619777202606, 0.6617380380630493, 0.1082158014178276, 0.0, 0.0, 0.0], [0.2670227289199829, 0.3607950508594513, 0.3249626159667969, 0.047219593077898026, 0.0, 0.0], [0.595201313495636, 0.12269274890422821, 0.06302059441804886, 0.08916817605495453, 0.12991715967655182, 0.0], [0.10284596681594849, 0.02938011661171913, 0.013739082030951977, 0.045860596001148224, 0.7698501348495483, 0.03832406550645828]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9040980935096741, 0.09590194374322891, 0.0, 0.0, 0.0, 0.0], [0.357237845659256, 0.6274612545967102, 0.015300876460969448, 0.0, 0.0, 0.0], [0.5917996764183044, 0.2764042019844055, 0.10476048290729523, 0.027035649865865707, 0.0, 0.0], [0.7254403829574585, 0.04983152449131012, 0.014982940629124641, 0.1778142899274826, 0.031930916011333466, 0.0], [0.7612743973731995, 0.06158972904086113, 0.005942251533269882, 0.01642685756087303, 0.1267806589603424, 0.0279861893504858]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9947587847709656, 0.005241230130195618, 0.0, 0.0, 0.0, 0.0], [0.9632415771484375, 0.017816413193941116, 0.018942030146718025, 0.0, 0.0, 0.0], [0.9671078324317932, 0.008509586565196514, 0.00856222677975893, 0.015820473432540894, 0.0, 0.0], [0.9340996146202087, 0.011952387169003487, 0.02018021047115326, 0.02675083465874195, 0.0070168930105865, 0.0], [0.9587237238883972, 0.004657115787267685, 0.003326789475977421, 0.006545313633978367, 0.010182461701333523, 0.016564540565013885]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9769991040229797, 0.023000910878181458, 0.0, 0.0, 0.0, 0.0], [0.7917609214782715, 0.1753319948911667, 0.032907065004110336, 0.0, 0.0, 0.0], [0.7949192523956299, 0.10531841963529587, 0.040218502283096313, 0.05954383686184883, 0.0, 0.0], [0.7097718715667725, 0.10552527755498886, 0.06597573310136795, 0.05765606462955475, 0.061070989817380905, 0.0], [0.7506601214408875, 0.026514461264014244, 0.021576043218374252, 0.034296683967113495, 0.08494450151920319, 0.08200812339782715]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983751654624939, 0.016248304396867752, 0.0, 0.0, 0.0, 0.0], [0.5615494847297668, 0.08956841379404068, 0.3488820493221283, 0.0, 0.0, 0.0], [0.32929039001464844, 0.024114903062582016, 0.5428059697151184, 0.10378880053758621, 0.0, 0.0], [0.34330207109451294, 0.01308644749224186, 0.5121983289718628, 0.11146228760480881, 0.019950881600379944, 0.0], [0.4792812764644623, 0.01733359508216381, 0.1180536150932312, 0.06130281835794449, 0.20071913301944733, 0.12330964207649231]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9908847212791443, 0.009115329943597317, 0.0, 0.0, 0.0, 0.0], [0.5282707214355469, 0.3292262554168701, 0.1425030380487442, 0.0, 0.0, 0.0], [0.48788541555404663, 0.23368670046329498, 0.17578084766864777, 0.10264702141284943, 0.0, 0.0], [0.31444698572158813, 0.18065163493156433, 0.168714240193367, 0.09506598114967346, 0.24112118780612946, 0.0], [0.5168765187263489, 0.035897161811590195, 0.026188155636191368, 0.04039734974503517, 0.18791745603084564, 0.1927233189344406]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8750308156013489, 0.12496919929981232, 0.0, 0.0, 0.0, 0.0], [0.4550614655017853, 0.4900427758693695, 0.05489582195878029, 0.0, 0.0, 0.0], [0.2933720052242279, 0.5449907183647156, 0.09444297850131989, 0.06719419360160828, 0.0, 0.0], [0.489708811044693, 0.2720997631549835, 0.06861965358257294, 0.14694802463054657, 0.022623788565397263, 0.0], [0.4729066491127014, 0.08103099465370178, 0.016052134335041046, 0.30672287940979004, 0.10120721161365509, 0.022080255672335625]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9630220532417297, 0.03697792813181877, 0.0, 0.0, 0.0, 0.0], [0.7557195425033569, 0.16436372697353363, 0.07991670072078705, 0.0, 0.0, 0.0], [0.6947705745697021, 0.08409853279590607, 0.0638260766863823, 0.15730486810207367, 0.0, 0.0], [0.5821147561073303, 0.03297805413603783, 0.07936596870422363, 0.19441406428813934, 0.11112712323665619, 0.0], [0.5974540710449219, 0.04261096194386482, 0.06919723749160767, 0.14563441276550293, 0.12481734901666641, 0.020285936072468758]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9957822561264038, 0.004217816516757011, 0.0, 0.0, 0.0, 0.0], [0.9312832951545715, 0.010560247115790844, 0.05815650522708893, 0.0, 0.0, 0.0], [0.8435326814651489, 0.015695005655288696, 0.045751139521598816, 0.09502115100622177, 0.0, 0.0], [0.772409975528717, 0.011981245130300522, 0.03504609689116478, 0.03876771405339241, 0.14179500937461853, 0.0], [0.7642908692359924, 0.009868789464235306, 0.00812275055795908, 0.013314393348991871, 0.04824395477771759, 0.15615922212600708]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9701177477836609, 0.02988232672214508, 0.0, 0.0, 0.0, 0.0], [0.6564007997512817, 0.22506150603294373, 0.11853761970996857, 0.0, 0.0, 0.0], [0.6958062648773193, 0.14701850712299347, 0.07145983725786209, 0.08571550250053406, 0.0, 0.0], [0.6353274583816528, 0.1346064656972885, 0.030994214117527008, 0.056916315108537674, 0.1421555131673813, 0.0], [0.6779401898384094, 0.053654152899980545, 0.01800631172955036, 0.06284520775079727, 0.1103820651769638, 0.07717210054397583]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9822334051132202, 0.017766647040843964, 0.0, 0.0, 0.0, 0.0], [0.9037663340568542, 0.06541544198989868, 0.03081829659640789, 0.0, 0.0, 0.0], [0.8119193911552429, 0.03679030388593674, 0.060560714453458786, 0.09072960168123245, 0.0, 0.0], [0.40546438097953796, 0.10383912175893784, 0.10211236774921417, 0.35434210300445557, 0.03424208238720894, 0.0], [0.22824221849441528, 0.017278727144002914, 0.05055465176701546, 0.6015752553939819, 0.09411764144897461, 0.008231506682932377]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873148202896118, 0.012685136869549751, 0.0, 0.0, 0.0, 0.0], [0.35445743799209595, 0.5317603349685669, 0.11378221958875656, 0.0, 0.0, 0.0], [0.07823363691568375, 0.7221359014511108, 0.10936623811721802, 0.090264230966568, 0.0, 0.0], [0.21967869997024536, 0.4048435091972351, 0.12358088046312332, 0.20018866658210754, 0.051708199083805084, 0.0], [0.36089760065078735, 0.10459021478891373, 0.06983799487352371, 0.2976483404636383, 0.13869903981685638, 0.02832675166428089]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9732162356376648, 0.0267837755382061, 0.0, 0.0, 0.0, 0.0], [0.9167553782463074, 0.061452705413103104, 0.02179192565381527, 0.0, 0.0, 0.0], [0.8543081283569336, 0.08049600571393967, 0.030334919691085815, 0.03486092761158943, 0.0, 0.0], [0.8919214606285095, 0.04280779883265495, 0.022045055404305458, 0.023470671847462654, 0.01975487545132637, 0.0], [0.8116763234138489, 0.03413533419370651, 0.03567665070295334, 0.04748587682843208, 0.0253971628844738, 0.04562860727310181]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502761960029602, 0.04972382262349129, 0.0, 0.0, 0.0, 0.0], [0.7637454271316528, 0.2007361352443695, 0.03551840782165527, 0.0, 0.0, 0.0], [0.6279097199440002, 0.03768139332532883, 0.1994536966085434, 0.13495522737503052, 0.0, 0.0], [0.6397060751914978, 0.027007432654500008, 0.09082036465406418, 0.20653828978538513, 0.03592785820364952, 0.0], [0.4559425115585327, 0.021641194820404053, 0.12939567863941193, 0.21800927817821503, 0.10379841923713684, 0.07121295481920242]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498406648635864, 0.050159383565187454, 0.0, 0.0, 0.0, 0.0], [0.8688724637031555, 0.0872218981385231, 0.043905653059482574, 0.0, 0.0, 0.0], [0.6937950253486633, 0.06359200924634933, 0.091790571808815, 0.15082231163978577, 0.0, 0.0], [0.7266597151756287, 0.04389883577823639, 0.04683985933661461, 0.09851823002099991, 0.08408336341381073, 0.0], [0.7848998308181763, 0.037147827446460724, 0.012907838448882103, 0.01053939200937748, 0.12079165875911713, 0.03371351957321167]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891054034233093, 0.01089458167552948, 0.0, 0.0, 0.0, 0.0], [0.8929519653320312, 0.08700055629014969, 0.02004752680659294, 0.0, 0.0, 0.0], [0.7891124486923218, 0.09797251224517822, 0.08633202314376831, 0.026582980528473854, 0.0, 0.0], [0.8850635886192322, 0.03645012155175209, 0.05395457148551941, 0.01237727515399456, 0.012154522351920605, 0.0], [0.6861329674720764, 0.05720378831028938, 0.011636304669082165, 0.021660611033439636, 0.1748800277709961, 0.048486363142728806]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9396191835403442, 0.06038080155849457, 0.0, 0.0, 0.0, 0.0], [0.7851794958114624, 0.19751444458961487, 0.017306052148342133, 0.0, 0.0, 0.0], [0.7660509943962097, 0.15444670617580414, 0.03188290074467659, 0.04761936888098717, 0.0, 0.0], [0.703522801399231, 0.05171430483460426, 0.07760990411043167, 0.1533905267715454, 0.013762423768639565, 0.0], [0.7121888399124146, 0.04994234815239906, 0.03772548958659172, 0.08649132400751114, 0.06541401147842407, 0.04823806509375572]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.974072277545929, 0.025927715003490448, 0.0, 0.0, 0.0, 0.0], [0.792539656162262, 0.01171559002250433, 0.19574476778507233, 0.0, 0.0, 0.0], [0.5106770992279053, 0.007296787109225988, 0.039619915187358856, 0.4424062669277191, 0.0, 0.0], [0.5862472057342529, 0.012099712155759335, 0.024585209786891937, 0.06737840175628662, 0.30968940258026123, 0.0], [0.30196306109428406, 0.007724012713879347, 0.011518122628331184, 0.046947259455919266, 0.22146707773208618, 0.41038045287132263]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9744554162025452, 0.02554464340209961, 0.0, 0.0, 0.0, 0.0], [0.9769195318222046, 0.015048524364829063, 0.008031901903450489, 0.0, 0.0, 0.0], [0.9060619473457336, 0.025875424966216087, 0.025954782962799072, 0.04210779070854187, 0.0, 0.0], [0.9400081038475037, 0.00555665697902441, 0.005828304681926966, 0.031757812947034836, 0.016849134117364883, 0.0], [0.9105738401412964, 0.0019752182997763157, 0.008646721951663494, 0.013360846787691116, 0.03543964773416519, 0.030003678053617477]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791666865348816, 0.020833350718021393, 0.0, 0.0, 0.0, 0.0], [0.8444858193397522, 0.13507869839668274, 0.020435383543372154, 0.0, 0.0, 0.0], [0.7903086543083191, 0.14559169113636017, 0.037529975175857544, 0.026569725945591927, 0.0, 0.0], [0.7298924326896667, 0.056496407836675644, 0.032735615968704224, 0.10400459170341492, 0.07687094807624817, 0.0], [0.5684185028076172, 0.04388832300901413, 0.026293467730283737, 0.0811714455485344, 0.24314835667610168, 0.037079911679029465]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9499868154525757, 0.05001320689916611, 0.0, 0.0, 0.0, 0.0], [0.9336170554161072, 0.05848868936300278, 0.007894262671470642, 0.0, 0.0, 0.0], [0.7897834181785583, 0.11071821302175522, 0.05360178276896477, 0.04589657858014107, 0.0, 0.0], [0.885930061340332, 0.05752986669540405, 0.01374326553195715, 0.0033877466339617968, 0.03940902277827263, 0.0], [0.9337607622146606, 0.02647063508629799, 0.004523396957665682, 0.0061904797330498695, 0.014132906682789326, 0.014921708963811398]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.8521224554035598e-09, 0.0, 0.0, 0.0, 0.0], [6.6758907451003324e-06, 0.9999804496765137, 1.2841281204600818e-05, 0.0, 0.0, 0.0], [2.2194194926328237e-08, 2.6684581211355862e-09, 0.9999971389770508, 2.8136880700913025e-06, 0.0, 0.0], [1.0145409987671883e-06, 4.464065739284706e-08, 0.00035356366424821317, 0.9993677735328674, 0.0002776293840724975, 0.0], [9.436550429953172e-10, 1.382057315812979e-11, 5.017835036369434e-10, 2.965183876213473e-09, 0.9999971389770508, 2.8644042231462663e-06]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9948632121086121, 0.005136783700436354, 0.0, 0.0, 0.0, 0.0], [0.9274215698242188, 0.01832387037575245, 0.05425456911325455, 0.0, 0.0, 0.0], [0.9678993225097656, 0.004143435508012772, 0.004314453341066837, 0.023642776533961296, 0.0, 0.0], [0.8999068737030029, 0.001467161695472896, 0.00029133574571460485, 0.002585014794021845, 0.09574954956769943, 0.0], [0.9386115670204163, 0.00022248300956562161, 0.0006146665546111763, 0.0015495637198910117, 0.030689461156725883, 0.028312424197793007]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9999959468841553, 4.042720775032649e-06, 0.0, 0.0, 0.0, 0.0], [0.9982761144638062, 3.2613831990602193e-06, 0.001720669330097735, 0.0, 0.0, 0.0], [0.9998809099197388, 5.328835683826583e-08, 6.376215537784446e-07, 0.00011847059795400128, 0.0, 0.0], [0.9996154308319092, 3.473169556400535e-07, 3.8920820344401363e-08, 4.468433303372876e-07, 0.00038369710091501474, 0.0], [0.9994840621948242, 1.655020476221125e-08, 2.8715557931491276e-08, 1.0638284493325045e-06, 0.0002126671897713095, 0.00030212008277885616]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9514135718345642, 0.048586405813694, 0.0, 0.0, 0.0, 0.0], [0.5749948024749756, 0.39028096199035645, 0.03472418338060379, 0.0, 0.0, 0.0], [0.7442318201065063, 0.1752411425113678, 0.0756477490067482, 0.004879283253103495, 0.0, 0.0], [0.5232070684432983, 0.09429339319467545, 0.1138191670179367, 0.19979268312454224, 0.06888769567012787, 0.0], [0.47472575306892395, 0.05636607110500336, 0.04530389606952667, 0.06967321783304214, 0.3098014295101166, 0.0441296212375164]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8734648823738098, 0.12653514742851257, 0.0, 0.0, 0.0, 0.0], [0.6097912788391113, 0.3541727066040039, 0.036036062985658646, 0.0, 0.0, 0.0], [0.45984190702438354, 0.38697871565818787, 0.0996011346578598, 0.05357823893427849, 0.0, 0.0], [0.572220504283905, 0.23636263608932495, 0.08344558626413345, 0.06921917200088501, 0.03875211998820305, 0.0], [0.5143564343452454, 0.16723087430000305, 0.09019406139850616, 0.0765448659658432, 0.10578085482120514, 0.04589281603693962]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.981228768825531, 0.018771231174468994, 0.0, 0.0, 0.0, 0.0], [0.6142941117286682, 0.3503977954387665, 0.0353081189095974, 0.0, 0.0, 0.0], [0.5770686268806458, 0.32858458161354065, 0.05508256331086159, 0.03926428034901619, 0.0, 0.0], [0.17188192903995514, 0.011042501777410507, 0.054578714072704315, 0.7326585650444031, 0.029838265851140022, 0.0], [0.3783015012741089, 0.017070062458515167, 0.021754134446382523, 0.4409688115119934, 0.06093813106417656, 0.08096737414598465]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9923112392425537, 0.007688735146075487, 0.0, 0.0, 0.0, 0.0], [0.9498787522315979, 0.016709784045815468, 0.03341152146458626, 0.0, 0.0, 0.0], [0.9961295127868652, 0.0008787295082584023, 0.0006868162308819592, 0.0023048371076583862, 0.0, 0.0], [0.9935757517814636, 0.0032634998206049204, 0.0009993825806304812, 0.00027932299417443573, 0.0018820574041455984, 0.0], [0.9907532930374146, 0.00021344318520277739, 0.0004595233185682446, 0.0007905619568191469, 0.004424723796546459, 0.003358350833877921]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9647740125656128, 0.03522596135735512, 0.0, 0.0, 0.0, 0.0], [0.8194130063056946, 0.1365436613559723, 0.04404333233833313, 0.0, 0.0, 0.0], [0.7584245800971985, 0.006878929678350687, 0.20653395354747772, 0.028162529692053795, 0.0, 0.0], [0.5298128128051758, 0.002678812015801668, 0.07857988774776459, 0.3598373234272003, 0.02909109927713871, 0.0], [0.7544413208961487, 0.00036782227107323706, 0.0019713479559868574, 0.00324004958383739, 0.1942344754934311, 0.04574500769376755]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9749131202697754, 0.02508680149912834, 0.0, 0.0, 0.0, 0.0], [0.9306471943855286, 0.05705660209059715, 0.012296222150325775, 0.0, 0.0, 0.0], [0.9305251836776733, 0.052770983427762985, 0.01111945416778326, 0.005584415514022112, 0.0, 0.0], [0.8863320350646973, 0.01292418036609888, 0.017724711447954178, 0.06150198355317116, 0.021517015993595123, 0.0], [0.791684627532959, 0.015036096796393394, 0.0317479707300663, 0.03392200171947479, 0.03707978501915932, 0.09052948653697968]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9608501195907593, 0.039149850606918335, 0.0, 0.0, 0.0, 0.0], [0.9121272563934326, 0.02257651649415493, 0.06529619544744492, 0.0, 0.0, 0.0], [0.9364108443260193, 0.015584447421133518, 0.024544963613152504, 0.02345985174179077, 0.0, 0.0], [0.9454620480537415, 0.006762288510799408, 0.022026237100362778, 0.009137796238064766, 0.016611700877547264, 0.0], [0.8346164226531982, 0.001881699077785015, 0.00560904573649168, 0.01887359470129013, 0.12449200451374054, 0.014527074061334133]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9964227080345154, 0.0035772807896137238, 0.0, 0.0, 0.0, 0.0], [0.9713928699493408, 0.024453025311231613, 0.004154058638960123, 0.0, 0.0, 0.0], [0.9735792279243469, 0.019003381952643394, 0.003664410673081875, 0.0037529165856540203, 0.0, 0.0], [0.9586312174797058, 0.007116180844604969, 0.009218388237059116, 0.022725583985447884, 0.0023084774147719145, 0.0], [0.973607063293457, 0.008490582928061485, 0.0032512471079826355, 0.003606445388868451, 0.004877461586147547, 0.006167212035506964]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.97598797082901, 0.024011990055441856, 0.0, 0.0, 0.0, 0.0], [0.9460638165473938, 0.04211375489830971, 0.011822436936199665, 0.0, 0.0, 0.0], [0.8446813225746155, 0.04293116182088852, 0.05218198522925377, 0.06020559370517731, 0.0, 0.0], [0.9378372430801392, 0.03354858607053757, 0.008826455101370811, 0.0028792242519557476, 0.016908427700400352, 0.0], [0.8124931454658508, 0.02696753479540348, 0.05999218672513962, 0.03445731848478317, 0.011011860333383083, 0.05507794767618179]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9001203775405884, 0.09987961500883102, 0.0, 0.0, 0.0, 0.0], [0.627193033695221, 0.07988718152046204, 0.29291975498199463, 0.0, 0.0, 0.0], [0.7624077796936035, 0.02734432928264141, 0.038679543882608414, 0.17156831920146942, 0.0, 0.0], [0.7995968461036682, 0.014336260966956615, 0.01437566988170147, 0.025438452139496803, 0.14625284075737, 0.0], [0.7851970791816711, 0.04204057529568672, 0.025253651663661003, 0.02908395044505596, 0.029306314885616302, 0.08911846578121185]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954467415809631, 0.0045532057993113995, 0.0, 0.0, 0.0, 0.0], [0.9356001615524292, 0.04476744681596756, 0.019632352516055107, 0.0, 0.0, 0.0], [0.5605552792549133, 0.09861977398395538, 0.29983264207839966, 0.040992289781570435, 0.0, 0.0], [0.5893709659576416, 0.11000988632440567, 0.08033622056245804, 0.16754034161567688, 0.05274256691336632, 0.0], [0.22305884957313538, 0.05680817365646362, 0.05467984080314636, 0.24733951687812805, 0.3111244738101959, 0.1069890558719635]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9301451444625854, 0.06985488533973694, 0.0, 0.0, 0.0, 0.0], [0.8936478495597839, 0.08535721153020859, 0.020994966849684715, 0.0, 0.0, 0.0], [0.8404538035392761, 0.10619214922189713, 0.02363673783838749, 0.029717326164245605, 0.0, 0.0], [0.8927386403083801, 0.024784674867987633, 0.008319000713527203, 0.05165454372763634, 0.022503145039081573, 0.0], [0.8646610975265503, 0.009503193199634552, 0.0024329854641109705, 0.04796753078699112, 0.04273205250501633, 0.03270319849252701]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9859625697135925, 0.014037408865988255, 0.0, 0.0, 0.0, 0.0], [0.9702037572860718, 0.0168070700019598, 0.012989125214517117, 0.0, 0.0, 0.0], [0.9524770379066467, 0.016064459457993507, 0.013456220738589764, 0.018002323806285858, 0.0, 0.0], [0.9332928657531738, 0.01897200010716915, 0.02014683373272419, 0.017023753374814987, 0.010564540512859821, 0.0], [0.9113592505455017, 0.012528638355433941, 0.02209620550274849, 0.01751861348748207, 0.018517911434173584, 0.01797938533127308]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9681769013404846, 0.03182310611009598, 0.0, 0.0, 0.0, 0.0], [0.9096417427062988, 0.07916690409183502, 0.011191264726221561, 0.0, 0.0, 0.0], [0.8379932045936584, 0.13078266382217407, 0.012140989303588867, 0.019083037972450256, 0.0, 0.0], [0.9116525053977966, 0.05451957508921623, 0.009499342180788517, 0.00746585289016366, 0.01686275750398636, 0.0], [0.8510289192199707, 0.07338211685419083, 0.008022507652640343, 0.009083161130547523, 0.04261006414890289, 0.015873271971940994]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9799023866653442, 0.020097682252526283, 0.0, 0.0, 0.0, 0.0], [0.9558742642402649, 0.029063312336802483, 0.015062497928738594, 0.0, 0.0, 0.0], [0.7943133115768433, 0.06074100360274315, 0.06907659024000168, 0.07586916536092758, 0.0, 0.0], [0.5494324564933777, 0.03154711425304413, 0.05482015758752823, 0.05788077041506767, 0.3063195049762726, 0.0], [0.6453980803489685, 0.010770943015813828, 0.017528092488646507, 0.02157985046505928, 0.24958276748657227, 0.05514020845293999]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9506809115409851, 0.0493190623819828, 0.0, 0.0, 0.0, 0.0], [0.8553215265274048, 0.09256264567375183, 0.05211575701832771, 0.0, 0.0, 0.0], [0.850852370262146, 0.04734604433178902, 0.044177331030368805, 0.057624250650405884, 0.0, 0.0], [0.7697131633758545, 0.02788589708507061, 0.031017286702990532, 0.06842502951622009, 0.1029587835073471, 0.0], [0.7931903004646301, 0.04052198305726051, 0.029242033138871193, 0.04478124529123306, 0.04894689470529556, 0.04331749677658081]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9770310521125793, 0.02296893112361431, 0.0, 0.0, 0.0, 0.0], [0.9429817199707031, 0.017321482300758362, 0.03969680890440941, 0.0, 0.0, 0.0], [0.9144344925880432, 0.008583576418459415, 0.013035810552537441, 0.06394599378108978, 0.0, 0.0], [0.9222429990768433, 0.0036440351977944374, 0.003740275977179408, 0.010410364717245102, 0.05996239185333252, 0.0], [0.9198879599571228, 0.0030822583939880133, 0.0034827394410967827, 0.004206796642392874, 0.02125428058207035, 0.048085976392030716]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.977458119392395, 0.022541873157024384, 0.0, 0.0, 0.0, 0.0], [0.8929325342178345, 0.07475466281175613, 0.032312843948602676, 0.0, 0.0, 0.0], [0.8423511385917664, 0.05980278551578522, 0.03740081936120987, 0.06044524535536766, 0.0, 0.0], [0.7674624919891357, 0.03536349534988403, 0.042155250906944275, 0.06658654659986496, 0.08843226730823517, 0.0], [0.6182611584663391, 0.01611059531569481, 0.020167622715234756, 0.03868892416357994, 0.23147016763687134, 0.07530155777931213]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9634856581687927, 0.036514393985271454, 0.0, 0.0, 0.0, 0.0], [0.4363938570022583, 0.522637128829956, 0.04096902906894684, 0.0, 0.0, 0.0], [0.3608614206314087, 0.35129693150520325, 0.2655103802680969, 0.022331148386001587, 0.0, 0.0], [0.3942921757698059, 0.021704670041799545, 0.07794328778982162, 0.37168896198272705, 0.1343708038330078, 0.0], [0.6310713887214661, 0.01698400266468525, 0.025942081585526466, 0.08615949749946594, 0.2183200567960739, 0.021522950381040573]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9988250136375427, 0.0011750265257433057, 0.0, 0.0, 0.0, 0.0], [0.9944871068000793, 0.0004826401418540627, 0.0050302306190133095, 0.0, 0.0, 0.0], [0.9981209635734558, 2.705173392314464e-05, 0.0001130745149566792, 0.0017389442073181272, 0.0, 0.0], [0.9982239603996277, 6.83655816828832e-05, 0.00010199935059063137, 6.028370262356475e-05, 0.0015453165397047997, 0.0], [0.9982888102531433, 1.055222810464329e-06, 3.2781026675365865e-05, 0.00013038977340329438, 0.0006605894886888564, 0.0008863684488460422]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9936710596084595, 0.006328921765089035, 0.0, 0.0, 0.0, 0.0], [0.9727688431739807, 0.0018561368342489004, 0.025375060737133026, 0.0, 0.0, 0.0], [0.9724299907684326, 0.0019586149137467146, 0.011192461475729942, 0.014418890699744225, 0.0, 0.0], [0.9782041311264038, 0.0009589138207957149, 0.0018706483533605933, 0.006326568778604269, 0.012639678083360195, 0.0], [0.9592596888542175, 0.0024555064737796783, 0.00161241355817765, 0.005019655916839838, 0.006687097251415253, 0.024965662509202957]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629000425338745, 0.03709998354315758, 0.0, 0.0, 0.0, 0.0], [0.36801934242248535, 0.6152258515357971, 0.016754813492298126, 0.0, 0.0, 0.0], [0.3173511326313019, 0.6140013337135315, 0.05375149846076965, 0.014896026812493801, 0.0, 0.0], [0.48987284302711487, 0.21071474254131317, 0.04693019017577171, 0.20700432360172272, 0.04547784850001335, 0.0], [0.48774227499961853, 0.1769528090953827, 0.06915216147899628, 0.09849268198013306, 0.12091436982154846, 0.046745721250772476]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9794419407844543, 0.020558049902319908, 0.0, 0.0, 0.0, 0.0], [0.6677903532981873, 0.31032365560531616, 0.021886007860302925, 0.0, 0.0, 0.0], [0.7118757367134094, 0.11108540743589401, 0.14187385141849518, 0.03516504913568497, 0.0, 0.0], [0.4501457214355469, 0.04036055505275726, 0.040458209812641144, 0.388570100069046, 0.08046531677246094, 0.0], [0.49346262216567993, 0.013696977868676186, 0.008126799948513508, 0.13074499368667603, 0.3086138069629669, 0.04535480588674545]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846054315567017, 0.015394587069749832, 0.0, 0.0, 0.0, 0.0], [0.9806739091873169, 0.007713791914284229, 0.011612347327172756, 0.0, 0.0, 0.0], [0.932663083076477, 0.01957838423550129, 0.02410353161394596, 0.023654978722333908, 0.0, 0.0], [0.9422016739845276, 0.0009538981830701232, 0.0010898025939241052, 0.00319337984547019, 0.05256118252873421, 0.0], [0.9352930784225464, 0.0010279357666149735, 0.004444425459951162, 0.001637140172533691, 0.010590963996946812, 0.04700646549463272]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9985783100128174, 0.0014216724084690213, 0.0, 0.0, 0.0, 0.0], [0.9893348813056946, 0.0011178902350366116, 0.00954714696854353, 0.0, 0.0, 0.0], [0.9979978203773499, 7.997050124686211e-05, 0.00013218850654084235, 0.0017900333041325212, 0.0, 0.0], [0.9986976385116577, 4.1044117097044364e-05, 3.8683547245454974e-06, 2.3676282580709085e-05, 0.0012337174266576767, 0.0], [0.9971563816070557, 1.852225250331685e-05, 1.8826559653462027e-06, 2.7900125132873654e-05, 0.0006533482228405774, 0.0021419788245111704]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9768233299255371, 0.023176640272140503, 0.0, 0.0, 0.0, 0.0], [0.9194678068161011, 0.05088186264038086, 0.029650341719388962, 0.0, 0.0, 0.0], [0.8474554419517517, 0.06100169196724892, 0.04372376948595047, 0.04781914874911308, 0.0, 0.0], [0.8011623620986938, 0.041866958141326904, 0.04375807195901871, 0.041894737631082535, 0.07131782174110413, 0.0], [0.8031871914863586, 0.02450493723154068, 0.017323585227131844, 0.04744395986199379, 0.06109930947422981, 0.046441152691841125]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9829428195953369, 0.01705716922879219, 0.0, 0.0, 0.0, 0.0], [0.8863736987113953, 0.09492647647857666, 0.018699750304222107, 0.0, 0.0, 0.0], [0.9231085777282715, 0.03696346655488014, 0.032198335975408554, 0.007729663979262114, 0.0, 0.0], [0.9068527221679688, 0.016046639531850815, 0.014310522936284542, 0.04543786868453026, 0.017352323979139328, 0.0], [0.6555973887443542, 0.05091019719839096, 0.028384855017066002, 0.1256549060344696, 0.10546853393316269, 0.03398407623171806]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502318501472473, 0.049768079072237015, 0.0, 0.0, 0.0, 0.0], [0.8829865455627441, 0.1000962108373642, 0.01691717840731144, 0.0, 0.0, 0.0], [0.8057457804679871, 0.14463546872138977, 0.03018922731280327, 0.019429458305239677, 0.0, 0.0], [0.8706230521202087, 0.032440632581710815, 0.026951627805829048, 0.04410304129123688, 0.025881657376885414, 0.0], [0.688364565372467, 0.009681451134383678, 0.016449343413114548, 0.0987110361456871, 0.08971209079027176, 0.09708156436681747]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9792683124542236, 0.02073168195784092, 0.0, 0.0, 0.0, 0.0], [0.9523284435272217, 0.025933818891644478, 0.021737735718488693, 0.0, 0.0, 0.0], [0.9144353270530701, 0.017671240493655205, 0.022358495742082596, 0.04553484544157982, 0.0, 0.0], [0.9448292851448059, 0.006467597559094429, 0.006386063527315855, 0.03263096138834953, 0.00968620739877224, 0.0], [0.9347906112670898, 0.007862505502998829, 0.007788175716996193, 0.021432818844914436, 0.008491144515573978, 0.01963483914732933]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983370304107666, 0.016629677265882492, 0.0, 0.0, 0.0, 0.0], [0.963111400604248, 0.009229931980371475, 0.027658598497509956, 0.0, 0.0, 0.0], [0.9706628322601318, 0.0041494048200547695, 0.0068131014704704285, 0.018374638631939888, 0.0, 0.0], [0.987951934337616, 0.002165885642170906, 0.00034901127219200134, 0.001583816367201507, 0.00794942770153284, 0.0], [0.9457950592041016, 0.014583553187549114, 0.0003652951563708484, 0.0009569536778144538, 0.013621564954519272, 0.02467755414545536]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9878059029579163, 0.01219407469034195, 0.0, 0.0, 0.0, 0.0], [0.87103670835495, 0.09448163211345673, 0.03448161482810974, 0.0, 0.0, 0.0], [0.6309783458709717, 0.11090382188558578, 0.1923021823167801, 0.06581564992666245, 0.0, 0.0], [0.5360490083694458, 0.04618944972753525, 0.13605308532714844, 0.26455509662628174, 0.017153292894363403, 0.0], [0.8287520408630371, 0.023732755333185196, 0.02008037269115448, 0.07245264202356339, 0.030431220307946205, 0.024550989270210266]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8995685577392578, 0.10043150931596756, 0.0, 0.0, 0.0, 0.0], [0.270343542098999, 0.6504329442977905, 0.07922357320785522, 0.0, 0.0, 0.0], [0.20541730523109436, 0.5892508625984192, 0.18085837364196777, 0.024473490193486214, 0.0, 0.0], [0.5573861002922058, 0.1774134784936905, 0.08806808292865753, 0.09881848096847534, 0.07831384986639023, 0.0], [0.5922912359237671, 0.08700639009475708, 0.05643285810947418, 0.05685883015394211, 0.12181518226861954, 0.08559554070234299]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9316380620002747, 0.06836195290088654, 0.0, 0.0, 0.0, 0.0], [0.9572945833206177, 0.026243582367897034, 0.0164618119597435, 0.0, 0.0, 0.0], [0.9880544543266296, 0.00427332753315568, 0.002954584313556552, 0.004717645235359669, 0.0, 0.0], [0.99403977394104, 0.0009413420339114964, 0.0004739820142276585, 0.00011646930943243206, 0.004428447224199772, 0.0], [0.9806035161018372, 2.5468933017691597e-05, 0.00016239412070717663, 0.0001476418401580304, 0.0013442443450912833, 0.017716845497488976]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.993178129196167, 0.006821857299655676, 0.0, 0.0, 0.0, 0.0], [0.9756524562835693, 0.01318411435931921, 0.011163423769176006, 0.0, 0.0, 0.0], [0.9418966770172119, 0.004721744451671839, 0.0023818055633455515, 0.050999753177165985, 0.0, 0.0], [0.9905040860176086, 0.0022848136723041534, 6.198462506290525e-05, 0.0005984465242363513, 0.006550676189363003, 0.0], [0.9697660207748413, 0.0008878845837898552, 0.00023466735729016364, 0.0017040816601365805, 0.004128355998545885, 0.02327893301844597]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9716231822967529, 0.02837684564292431, 0.0, 0.0, 0.0, 0.0], [0.9223619699478149, 0.028907248750329018, 0.048730745911598206, 0.0, 0.0, 0.0], [0.8426317572593689, 0.023872116580605507, 0.04748132824897766, 0.08601479232311249, 0.0, 0.0], [0.8521121740341187, 0.020744236186146736, 0.04494619369506836, 0.05765002593398094, 0.02454746514558792, 0.0], [0.8800725936889648, 0.022448532283306122, 0.018235722556710243, 0.01925482600927353, 0.015854258090257645, 0.044134121388196945]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9412723779678345, 0.058727629482746124, 0.0, 0.0, 0.0, 0.0], [0.916313886642456, 0.05759201943874359, 0.02609400637447834, 0.0, 0.0, 0.0], [0.8392423391342163, 0.057690516114234924, 0.01382902916520834, 0.08923812955617905, 0.0, 0.0], [0.8987162113189697, 0.0134778693318367, 0.0003456450067460537, 0.003298751311376691, 0.08416149020195007, 0.0], [0.8701692223548889, 0.002700856188312173, 0.00143499206751585, 0.0056661744602024555, 0.08874300867319107, 0.031285665929317474]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9656725525856018, 0.03432750701904297, 0.0, 0.0, 0.0, 0.0], [0.9178615808486938, 0.062257930636405945, 0.019880469888448715, 0.0, 0.0, 0.0], [0.823314905166626, 0.06282395124435425, 0.03670429438352585, 0.07715693861246109, 0.0, 0.0], [0.8501748442649841, 0.03816927224397659, 0.03196492791175842, 0.0516013503074646, 0.02808968350291252, 0.0], [0.6572404503822327, 0.05877397954463959, 0.04336007311940193, 0.09013211727142334, 0.08146599680185318, 0.06902744621038437]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9162061810493469, 0.0837937667965889, 0.0, 0.0, 0.0, 0.0], [0.9451773762702942, 0.04099284112453461, 0.013829832896590233, 0.0, 0.0, 0.0], [0.8928355574607849, 0.05368670076131821, 0.017596954479813576, 0.03588071092963219, 0.0, 0.0], [0.8337052464485168, 0.04799601063132286, 0.033513229340314865, 0.04680858924984932, 0.03797686845064163, 0.0], [0.8167192339897156, 0.06337132304906845, 0.013286277651786804, 0.020469767972826958, 0.025292355567216873, 0.06086111441254616]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9525133371353149, 0.04748663306236267, 0.0, 0.0, 0.0, 0.0], [0.3019869327545166, 0.6520938873291016, 0.04591925069689751, 0.0, 0.0, 0.0], [0.285582959651947, 0.556952178478241, 0.1444743126630783, 0.012990524061024189, 0.0, 0.0], [0.843804121017456, 0.032251205295324326, 0.03954290598630905, 0.06848159432411194, 0.015920041128993034, 0.0], [0.6664940714836121, 0.06095913052558899, 0.04064354673027992, 0.06804485619068146, 0.09186329692602158, 0.07199501991271973]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9682655334472656, 0.031734466552734375, 0.0, 0.0, 0.0, 0.0], [0.738521933555603, 0.22856839001178741, 0.032909639179706573, 0.0, 0.0, 0.0], [0.5946676135063171, 0.2303314357995987, 0.14867636561393738, 0.02632458508014679, 0.0, 0.0], [0.6339254975318909, 0.05813034623861313, 0.09654320776462555, 0.14291946589946747, 0.06848153471946716, 0.0], [0.40375572443008423, 0.08945391327142715, 0.07635112851858139, 0.25587135553359985, 0.1433039754629135, 0.03126389905810356]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9869793653488159, 0.013020593672990799, 0.0, 0.0, 0.0, 0.0], [0.8631385564804077, 0.1105666309595108, 0.02629482001066208, 0.0, 0.0, 0.0], [0.9488080143928528, 0.028614996001124382, 0.006535546388477087, 0.016041526570916176, 0.0, 0.0], [0.9672170877456665, 0.006604980677366257, 0.00045171406236477196, 0.004844417329877615, 0.020881708711385727, 0.0], [0.9354621171951294, 0.02047806605696678, 0.0011700231116265059, 0.007056943140923977, 0.0163181871175766, 0.019514625892043114]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846673011779785, 0.015332723967730999, 0.0, 0.0, 0.0, 0.0], [0.9052747488021851, 0.08373606950044632, 0.010989243164658546, 0.0, 0.0, 0.0], [0.8145939111709595, 0.04283742979168892, 0.10568301379680634, 0.03688570484519005, 0.0, 0.0], [0.23519809544086456, 0.012018457986414433, 0.05280117318034172, 0.6516180038452148, 0.04836418479681015, 0.0], [0.31818512082099915, 0.018632443621754646, 0.03948190063238144, 0.3755541741847992, 0.20787373185157776, 0.04027257487177849]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9811733365058899, 0.018826685845851898, 0.0, 0.0, 0.0, 0.0], [0.8618939518928528, 0.06479164958000183, 0.07331438362598419, 0.0, 0.0, 0.0], [0.7664540410041809, 0.07330425828695297, 0.10353513062000275, 0.056706514209508896, 0.0, 0.0], [0.8128499984741211, 0.03215480223298073, 0.059005625545978546, 0.05416511744260788, 0.04182446748018265, 0.0], [0.8687856197357178, 0.026987861841917038, 0.02047000452876091, 0.01629738137125969, 0.03218390792608261, 0.03527523949742317]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9264583587646484, 0.07354167848825455, 0.0, 0.0, 0.0, 0.0], [0.8403540849685669, 0.06373751163482666, 0.09590838104486465, 0.0, 0.0, 0.0], [0.7330995798110962, 0.06451118737459183, 0.10380073636770248, 0.09858842939138412, 0.0, 0.0], [0.9143612384796143, 0.008257776498794556, 0.007320381235331297, 0.017966248095035553, 0.05209439620375633, 0.0], [0.8971915245056152, 0.008555498905479908, 0.007019453682005405, 0.014860544353723526, 0.03399762138724327, 0.03837529569864273]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9180347919464111, 0.08196526020765305, 0.0, 0.0, 0.0, 0.0], [0.8328666687011719, 0.1219901517033577, 0.04514322429895401, 0.0, 0.0, 0.0], [0.7994157075881958, 0.0874413549900055, 0.03605784848332405, 0.07708510011434555, 0.0, 0.0], [0.880984902381897, 0.020749641582369804, 0.020554615184664726, 0.017120830714702606, 0.06058995798230171, 0.0], [0.745303213596344, 0.044334057718515396, 0.022549288347363472, 0.0331527441740036, 0.03357058763504028, 0.12109009176492691]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9867060780525208, 0.013293893076479435, 0.0, 0.0, 0.0, 0.0], [0.982177734375, 0.012414131313562393, 0.005408108700066805, 0.0, 0.0, 0.0], [0.9630486369132996, 0.015290752984583378, 0.010345698334276676, 0.0113149369135499, 0.0, 0.0], [0.9213568568229675, 0.014132463373243809, 0.017639216035604477, 0.016567690297961235, 0.030303770676255226, 0.0], [0.9373326301574707, 0.009064299054443836, 0.007548365276306868, 0.006576443091034889, 0.011827622540295124, 0.027650514617562294]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9951004385948181, 0.00489962799474597, 0.0, 0.0, 0.0, 0.0], [0.9476007223129272, 0.041407931596040726, 0.010991275310516357, 0.0, 0.0, 0.0], [0.9142175316810608, 0.023523783311247826, 0.039145033806562424, 0.023113621398806572, 0.0, 0.0], [0.9534738659858704, 0.008932933211326599, 0.015272765420377254, 0.007908251136541367, 0.014412266202270985, 0.0], [0.9427101016044617, 0.00823307130485773, 0.004650997929275036, 0.004178107250481844, 0.005463531706482172, 0.03476419299840927]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9543376564979553, 0.045662373304367065, 0.0, 0.0, 0.0, 0.0], [0.9696040749549866, 0.01954760029911995, 0.01084828469902277, 0.0, 0.0, 0.0], [0.9710449576377869, 0.012425386346876621, 0.008068876340985298, 0.008460716344416142, 0.0, 0.0], [0.9726192951202393, 0.002697656163945794, 0.00044831327977590263, 0.0013814778067171574, 0.022853154689073563, 0.0], [0.9675466418266296, 0.009613442234694958, 0.003203035332262516, 0.00424883933737874, 0.007442260626703501, 0.00794589426368475]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887008666992188, 0.011299116536974907, 0.0, 0.0, 0.0, 0.0], [0.9382632374763489, 0.04204244911670685, 0.019694412127137184, 0.0, 0.0, 0.0], [0.8351995944976807, 0.03487853705883026, 0.05134471505880356, 0.07857715338468552, 0.0, 0.0], [0.9042676687240601, 0.010541575029492378, 0.016426723450422287, 0.025921987369656563, 0.04284200444817543, 0.0], [0.8913140892982483, 0.00891267228871584, 0.005010711494833231, 0.008175632916390896, 0.013514749705791473, 0.07307209819555283]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8693912029266357, 0.13060881197452545, 0.0, 0.0, 0.0, 0.0], [0.3507988452911377, 0.606351912021637, 0.04284917935729027, 0.0, 0.0, 0.0], [0.35475659370422363, 0.3502019941806793, 0.24722407758235931, 0.04781729355454445, 0.0, 0.0], [0.35370609164237976, 0.03527737781405449, 0.09567111730575562, 0.449796199798584, 0.06554921716451645, 0.0], [0.4132595360279083, 0.09055527299642563, 0.05286579951643944, 0.174679696559906, 0.173848956823349, 0.09479076415300369]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629756212234497, 0.037024300545454025, 0.0, 0.0, 0.0, 0.0], [0.9756426811218262, 0.01965854875743389, 0.004698706325143576, 0.0, 0.0, 0.0], [0.9775736927986145, 0.013286248780786991, 0.0025590297300368547, 0.006581062916666269, 0.0, 0.0], [0.9870142936706543, 0.007388236932456493, 0.0009579154429957271, 0.0018318220973014832, 0.0028077505994588137, 0.0], [0.9409245848655701, 0.016633737832307816, 0.0022979143541306257, 0.0058906711637973785, 0.0055129327811300755, 0.02874022163450718]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.962827205657959, 0.037172831594944, 0.0, 0.0, 0.0, 0.0], [0.9582237601280212, 0.024641817435622215, 0.017134377732872963, 0.0, 0.0, 0.0], [0.9351300001144409, 0.015331573784351349, 0.014810982160270214, 0.034727465361356735, 0.0, 0.0], [0.9225171208381653, 0.010528750717639923, 0.011010154150426388, 0.01944003626704216, 0.036503832787275314, 0.0], [0.8420165777206421, 0.04357199743390083, 0.007488282397389412, 0.01496153138577938, 0.02385285682976246, 0.06810864061117172]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9926387071609497, 0.00736132962629199, 0.0, 0.0, 0.0, 0.0], [0.9957393407821655, 0.0033469819463789463, 0.000913690309971571, 0.0, 0.0, 0.0], [0.9869900345802307, 0.001974786864593625, 0.001524551771581173, 0.009510699659585953, 0.0, 0.0], [0.9933527708053589, 0.001020324882119894, 0.00034337223041802645, 0.0010291127255186439, 0.004254369530826807, 0.0], [0.9749016761779785, 0.00043480272870510817, 0.0004306558985263109, 0.0012364407302811742, 0.0015347707085311413, 0.021461669355630875]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9897475242614746, 0.010252462700009346, 0.0, 0.0, 0.0, 0.0], [0.9790639281272888, 0.01650906540453434, 0.0044270907528698444, 0.0, 0.0, 0.0], [0.9521436095237732, 0.029432358220219612, 0.008943161927163601, 0.009480923414230347, 0.0, 0.0], [0.939594030380249, 0.021510960534214973, 0.010278552770614624, 0.004555229097604752, 0.024061163887381554, 0.0], [0.9205074906349182, 0.016153652220964432, 0.010818594135344028, 0.01664440892636776, 0.014566398225724697, 0.021309375762939453]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9898501634597778, 0.010149780660867691, 0.0, 0.0, 0.0, 0.0], [0.9820910096168518, 0.006907520350068808, 0.011001535691320896, 0.0, 0.0, 0.0], [0.9684997200965881, 0.008987602777779102, 0.015342563390731812, 0.007170087192207575, 0.0, 0.0], [0.9274120330810547, 0.009485266171395779, 0.022066107019782066, 0.03222890570759773, 0.008807653561234474, 0.0], [0.900665819644928, 0.021623756736516953, 0.013808279298245907, 0.009843860752880573, 0.008521373383700848, 0.04553695768117905]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954444169998169, 0.004555588588118553, 0.0, 0.0, 0.0, 0.0], [0.995254397392273, 0.002460238989442587, 0.002285485854372382, 0.0, 0.0, 0.0], [0.9862446188926697, 0.0015168144600465894, 0.004072288051247597, 0.008166354149580002, 0.0, 0.0], [0.9889963865280151, 0.001226040069013834, 0.0007996349013410509, 0.0006774227367714047, 0.008300574496388435, 0.0], [0.9865202903747559, 0.00039427157025784254, 0.0009571771952323616, 0.0004954367759637535, 0.0009604979422874749, 0.010672281496226788]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9821295142173767, 0.017870500683784485, 0.0, 0.0, 0.0, 0.0], [0.7489436268806458, 0.22002726793289185, 0.031029189005494118, 0.0, 0.0, 0.0], [0.28547799587249756, 0.21125678718090057, 0.47871601581573486, 0.024549242109060287, 0.0, 0.0], [0.8056644201278687, 0.026974644511938095, 0.04302806034684181, 0.06993705034255981, 0.05439583212137222, 0.0], [0.3307209014892578, 0.022326624020934105, 0.016627125442028046, 0.08019453287124634, 0.41574832797050476, 0.13438253104686737]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9697746634483337, 0.030225319787859917, 0.0, 0.0, 0.0, 0.0], [0.9800565838813782, 0.015018894337117672, 0.004924521781504154, 0.0, 0.0, 0.0], [0.9237861037254333, 0.052764780819416046, 0.00630240747705102, 0.017146753147244453, 0.0, 0.0], [0.9451844096183777, 0.03618047758936882, 0.001989208161830902, 0.003958724904805422, 0.012687299400568008, 0.0], [0.9633325934410095, 0.018662991002202034, 0.0030418417882174253, 0.007070912979543209, 0.0050094155594706535, 0.002882065251469612]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873244762420654, 0.012675459496676922, 0.0, 0.0, 0.0, 0.0], [0.9904569983482361, 0.0055419523268938065, 0.004001122899353504, 0.0, 0.0, 0.0], [0.9814971685409546, 0.004653455223888159, 0.003725277027115226, 0.010124054737389088, 0.0, 0.0], [0.9744365811347961, 0.004632251337170601, 0.002379992976784706, 0.006518087349832058, 0.012033028528094292, 0.0], [0.9624497294425964, 0.0033743639942258596, 0.0013198587112128735, 0.0017275003483518958, 0.002944675739854574, 0.028183799237012863]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9807674288749695, 0.01923258602619171, 0.0, 0.0, 0.0, 0.0], [0.9664245843887329, 0.015413926914334297, 0.018161438405513763, 0.0, 0.0, 0.0], [0.9632682204246521, 0.004538117907941341, 0.002925391308963299, 0.029268190264701843, 0.0, 0.0], [0.9562349319458008, 0.0012223608791828156, 0.0005304080550558865, 0.00867149606347084, 0.03334089741110802, 0.0], [0.9657101035118103, 0.0009808284230530262, 0.0016686266753822565, 0.002634831238538027, 0.005866361316293478, 0.023139292374253273]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639716148376465, 0.036028459668159485, 0.0, 0.0, 0.0, 0.0], [0.9562800526618958, 0.03373315557837486, 0.009986846707761288, 0.0, 0.0, 0.0], [0.8539998531341553, 0.08073022216558456, 0.03334445133805275, 0.031925540417432785, 0.0, 0.0], [0.9547491073608398, 0.009605025872588158, 0.004146162886172533, 0.0020133228972554207, 0.029486361891031265, 0.0], [0.9331137537956238, 0.028699662536382675, 0.005477475933730602, 0.006368075497448444, 0.012613046914339066, 0.013728085905313492]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9392993450164795, 0.06070063263177872, 0.0, 0.0, 0.0, 0.0], [0.9298391342163086, 0.061895377933979034, 0.008265496231615543, 0.0, 0.0, 0.0], [0.8471823334693909, 0.09035038203001022, 0.01763608679175377, 0.044831156730651855, 0.0, 0.0], [0.8857703804969788, 0.03918175399303436, 0.007867704145610332, 0.02276589721441269, 0.04441439360380173, 0.0], [0.8563280701637268, 0.10088995099067688, 0.006531452294439077, 0.008485927246510983, 0.007368441205471754, 0.020396249368786812]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8353264331817627, 0.1646735519170761, 0.0, 0.0, 0.0, 0.0], [0.6160858869552612, 0.3137648403644562, 0.07014927268028259, 0.0, 0.0, 0.0], [0.34316325187683105, 0.2758493721485138, 0.1196604073047638, 0.26132699847221375, 0.0, 0.0], [0.5908172130584717, 0.050290752202272415, 0.041665926575660706, 0.2199493646621704, 0.0972767099738121, 0.0], [0.8481413125991821, 0.06318090111017227, 0.014733693562448025, 0.055267371237277985, 0.00901501253247261, 0.009661628864705563]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9627319574356079, 0.03726799786090851, 0.0, 0.0, 0.0, 0.0], [0.7757522463798523, 0.1799626499414444, 0.044285036623477936, 0.0, 0.0, 0.0], [0.6317060589790344, 0.24380716681480408, 0.10925652086734772, 0.015230235643684864, 0.0, 0.0], [0.9539909958839417, 0.018182311207056046, 0.011601822450757027, 0.012299076654016972, 0.003925766795873642, 0.0], [0.40356943011283875, 0.14237558841705322, 0.05661217123270035, 0.1975736767053604, 0.0929921343922615, 0.10687707364559174]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9802619218826294, 0.019738124683499336, 0.0, 0.0, 0.0, 0.0], [0.9873908162117004, 0.007800452411174774, 0.004808681085705757, 0.0, 0.0, 0.0], [0.9283918738365173, 0.008301235735416412, 0.01330565195530653, 0.05000120773911476, 0.0, 0.0], [0.8981055021286011, 0.015591299161314964, 0.010177576914429665, 0.039987027645111084, 0.0361386202275753, 0.0], [0.9753499031066895, 0.00035433052107691765, 0.0005866039427928627, 0.0011877501383423805, 0.0010750899091362953, 0.021446440368890762]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9295330047607422, 0.07046692818403244, 0.0, 0.0, 0.0, 0.0], [0.9361506104469299, 0.04116682708263397, 0.022682538256049156, 0.0, 0.0, 0.0], [0.8486821055412292, 0.05802798643708229, 0.024856165051460266, 0.0684337466955185, 0.0, 0.0], [0.8661180734634399, 0.02232467755675316, 0.010369130410254002, 0.02600197121500969, 0.07518619298934937, 0.0], [0.8074421882629395, 0.044382549822330475, 0.01849711686372757, 0.03357789292931557, 0.018561245873570442, 0.07753907144069672]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9680535197257996, 0.03194643557071686, 0.0, 0.0, 0.0, 0.0], [0.9693689942359924, 0.02568492479622364, 0.004946070723235607, 0.0, 0.0, 0.0], [0.9620568156242371, 0.022552406415343285, 0.005471326876431704, 0.009919456206262112, 0.0, 0.0], [0.9727528095245361, 0.010137127712368965, 0.000757327419705689, 0.0028828983195126057, 0.013469807803630829, 0.0], [0.9624635577201843, 0.0031109037809073925, 0.0010007602395489812, 0.0019475930603221059, 0.008266227319836617, 0.02321087196469307]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8542501330375671, 0.14574992656707764, 0.0, 0.0, 0.0, 0.0], [0.9725967645645142, 0.014116315171122551, 0.01328685600310564, 0.0, 0.0, 0.0], [0.9257621765136719, 0.03257262706756592, 0.01461210660636425, 0.027053095400333405, 0.0, 0.0], [0.7923423051834106, 0.027305101975798607, 0.01880674995481968, 0.13854165375232697, 0.023004096001386642, 0.0], [0.6152060627937317, 0.02665526419878006, 0.029352931305766106, 0.05590886250138283, 0.11611279845237732, 0.15676409006118774]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9804654121398926, 0.019534552469849586, 0.0, 0.0, 0.0, 0.0], [0.9882452487945557, 0.007509466726332903, 0.004245325922966003, 0.0, 0.0, 0.0], [0.9584206938743591, 0.0109635591506958, 0.010456060990691185, 0.020159708335995674, 0.0, 0.0], [0.9604811668395996, 0.007182627450674772, 0.003072339342907071, 0.006898913532495499, 0.02236509881913662, 0.0], [0.966888964176178, 0.0032812939025461674, 0.00550054432824254, 0.004234083462506533, 0.005038043484091759, 0.015057181939482689]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498194456100464, 0.05018055811524391, 0.0, 0.0, 0.0, 0.0], [0.9781363606452942, 0.016430046409368515, 0.0054335566237568855, 0.0, 0.0, 0.0], [0.8618696331977844, 0.036093585193157196, 0.07555554062128067, 0.026481209322810173, 0.0, 0.0], [0.5449837446212769, 0.015411133877933025, 0.023516526445746422, 0.25743600726127625, 0.15865260362625122, 0.0], [0.9571874737739563, 0.0030803855042904615, 0.0014446862041950226, 0.006861559115350246, 0.014818714000284672, 0.01660723052918911]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6156560778617859, 0.3843439519405365, 0.0, 0.0, 0.0, 0.0], [0.36760634183883667, 0.42816370725631714, 0.20423001050949097, 0.0, 0.0, 0.0], [0.16471554338932037, 0.4136792719364166, 0.2509237229824066, 0.17068152129650116, 0.0, 0.0], [0.4184456169605255, 0.1524762362241745, 0.10305401682853699, 0.11071498692035675, 0.21530911326408386, 0.0], [0.19686934351921082, 0.2014620453119278, 0.12827259302139282, 0.09203246980905533, 0.09167550504207611, 0.2896881103515625]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9027364253997803, 0.09726352989673615, 0.0, 0.0, 0.0, 0.0], [0.9736634492874146, 0.014004302211105824, 0.01233230996876955, 0.0, 0.0, 0.0], [0.8504456281661987, 0.05690572410821915, 0.032060906291007996, 0.06058764085173607, 0.0, 0.0], [0.7661210298538208, 0.03530392050743103, 0.03433045372366905, 0.09675204753875732, 0.06749245524406433, 0.0], [0.8650374412536621, 0.020085260272026062, 0.01149806659668684, 0.01855834573507309, 0.018430285155773163, 0.06639053672552109]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9653082489967346, 0.03469168767333031, 0.0, 0.0, 0.0, 0.0], [0.9816323518753052, 0.014176066033542156, 0.004191514104604721, 0.0, 0.0, 0.0], [0.9275256395339966, 0.04737218841910362, 0.01152826938778162, 0.013573966920375824, 0.0, 0.0], [0.9293117523193359, 0.025833239778876305, 0.007227106485515833, 0.014300585724413395, 0.02332727052271366, 0.0], [0.8895062804222107, 0.04689619690179825, 0.0047171092592179775, 0.006286581978201866, 0.00609014043584466, 0.04650374501943588]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8938026428222656, 0.10619727522134781, 0.0, 0.0, 0.0, 0.0], [0.8221707940101624, 0.06304481625556946, 0.11478441953659058, 0.0, 0.0, 0.0], [0.5047380924224854, 0.15375731885433197, 0.2277037501335144, 0.11380083113908768, 0.0, 0.0], [0.4082071781158447, 0.09066355973482132, 0.11696872115135193, 0.24553199112415314, 0.13862857222557068, 0.0], [0.7291035652160645, 0.06638889014720917, 0.023112818598747253, 0.031103096902370453, 0.057143256068229675, 0.09314827620983124]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9247531890869141, 0.07524678111076355, 0.0, 0.0, 0.0, 0.0], [0.8957376480102539, 0.06989553570747375, 0.03436679765582085, 0.0, 0.0, 0.0], [0.7924937605857849, 0.0960114598274231, 0.05509118735790253, 0.056403566151857376, 0.0, 0.0], [0.7891505360603333, 0.07880303263664246, 0.03840155899524689, 0.05396979674696922, 0.03967496380209923, 0.0], [0.7807856798171997, 0.0799354612827301, 0.042531758546829224, 0.03234211727976799, 0.0178169384598732, 0.046588052064180374]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9480886459350586, 0.05191127583384514, 0.0, 0.0, 0.0, 0.0], [0.863694965839386, 0.04756204038858414, 0.08874296396970749, 0.0, 0.0, 0.0], [0.9341371059417725, 0.022224076092243195, 0.022624483332037926, 0.021014342084527016, 0.0, 0.0], [0.9588143229484558, 0.008020909503102303, 0.004490078426897526, 0.005862293299287558, 0.022812429815530777, 0.0], [0.9385918378829956, 0.021227721124887466, 0.0048724692314863205, 0.010940189473330975, 0.009524582885205746, 0.014843451790511608]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9763734340667725, 0.023626558482646942, 0.0, 0.0, 0.0, 0.0], [0.9884802103042603, 0.005189393647015095, 0.0063303736969828606, 0.0, 0.0, 0.0], [0.9477092027664185, 0.0179851483553648, 0.010156610049307346, 0.024149026721715927, 0.0, 0.0], [0.967192530632019, 0.006552813574671745, 0.0033227826934307814, 0.00556332478299737, 0.017368387430906296, 0.0], [0.9584562182426453, 0.007502961438149214, 0.0051363310776650906, 0.008071648888289928, 0.005997124593704939, 0.014835843816399574]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.884070873260498, 0.11592914164066315, 0.0, 0.0, 0.0, 0.0], [0.9931254386901855, 0.005070806015282869, 0.0018038019770756364, 0.0, 0.0, 0.0], [0.9534159302711487, 0.02382904477417469, 0.007748977281153202, 0.015006075613200665, 0.0, 0.0], [0.9151289463043213, 0.010873105376958847, 0.013190957717597485, 0.011050421744585037, 0.04975655674934387, 0.0], [0.8769673109054565, 0.03385210782289505, 0.00848648976534605, 0.009969149716198444, 0.03468578681349754, 0.036039214581251144]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003709519514814019, 0.999629020690918, 0.0, 0.0, 0.0, 0.0], [6.525027856696397e-05, 0.3737829029560089, 0.6261518597602844, 0.0, 0.0, 0.0], [4.606018774211407e-05, 0.210508793592453, 0.4115968942642212, 0.3778482675552368, 0.0, 0.0], [4.753069515572861e-05, 0.11616954207420349, 0.23264272511005402, 0.3985331058502197, 0.2526070475578308, 0.0], [1.247641534973809e-06, 0.14819711446762085, 0.15813173353672028, 0.30074331164360046, 0.11939018964767456, 0.27353641390800476]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.971555769443512, 0.028444187715649605, 0.0, 0.0, 0.0, 0.0], [0.9529065489768982, 0.03233075141906738, 0.014762768521904945, 0.0, 0.0, 0.0], [0.9343128204345703, 0.02351292595267296, 0.02049802988767624, 0.021676240488886833, 0.0, 0.0], [0.9529678225517273, 0.00855141133069992, 0.004359325394034386, 0.008064556866884232, 0.026056913658976555, 0.0], [0.9653593897819519, 0.008487647399306297, 0.003499280195683241, 0.002721576252952218, 0.0032828773837536573, 0.016649367287755013]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8630780577659607, 0.13692188262939453, 0.0, 0.0, 0.0, 0.0], [0.7696157097816467, 0.0851333811879158, 0.14525099098682404, 0.0, 0.0, 0.0], [0.7133337259292603, 0.10170899331569672, 0.11931268870830536, 0.06564456224441528, 0.0, 0.0], [0.7186222076416016, 0.05444284901022911, 0.01386815495789051, 0.07808027416467667, 0.13498654961585999, 0.0], [0.7990148663520813, 0.05805593729019165, 0.009447019547224045, 0.017770467326045036, 0.02113853208720684, 0.09457314014434814]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9518988728523254, 0.048101115971803665, 0.0, 0.0, 0.0, 0.0], [0.8580653071403503, 0.02944577857851982, 0.11248888075351715, 0.0, 0.0, 0.0], [0.6577738523483276, 0.08513449877500534, 0.1261308640241623, 0.1309608370065689, 0.0, 0.0], [0.8087368607521057, 0.0323016420006752, 0.01841817982494831, 0.06856140494346619, 0.07198194414377213, 0.0], [0.6683295965194702, 0.13281384110450745, 0.021880635991692543, 0.02787741646170616, 0.04923408478498459, 0.0998644009232521]]]], \"left_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"], \"right_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"]}], \"default_filter\": \"0\", \"display_mode\": \"dark\", \"root_div_id\": \"bertviz-3184429b902a44e391e08b8445c2cee0\", \"include_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"include_heads\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"total_heads\": 12} is a template marker that is replaced by actual params.\n",
       "        const config = {};\n",
       "\n",
       "        const MIN_X = 0;\n",
       "        const MIN_Y = 0;\n",
       "        const DIV_WIDTH = 970;\n",
       "        const THUMBNAIL_PADDING = 5;\n",
       "        const DETAIL_WIDTH = 300;\n",
       "        const DETAIL_ATTENTION_WIDTH = 140;\n",
       "        const DETAIL_BOX_WIDTH = 80;\n",
       "        const DETAIL_BOX_HEIGHT = 18;\n",
       "        const DETAIL_PADDING = 15;\n",
       "        const ATTN_PADDING = 0;\n",
       "        const DETAIL_HEADING_HEIGHT = 25;\n",
       "        const HEADING_TEXT_SIZE = 15;\n",
       "        const HEADING_PADDING = 5;\n",
       "        const TEXT_SIZE = 13;\n",
       "        const TEXT_PADDING = 5;\n",
       "        const LAYER_COLORS = d3.schemeCategory10;\n",
       "        const PALETTE = {\n",
       "            'light': {\n",
       "                'text': 'black',\n",
       "                'background': 'white',\n",
       "                'highlight': '#F5F5F5'\n",
       "            },\n",
       "            'dark': {\n",
       "                'text': '#ccc',\n",
       "                'background': 'black',\n",
       "                'highlight': '#222'\n",
       "            }\n",
       "        }\n",
       "\n",
       "        function render() {\n",
       "\n",
       "            // Set global state variables\n",
       "\n",
       "            var attData = config.attention[config.filter];\n",
       "            config.leftText = attData.left_text;\n",
       "            config.rightText = attData.right_text;\n",
       "            config.attn = attData.attn;\n",
       "            config.numLayers = config.attn.length;\n",
       "            config.numHeads = config.attn[0].length;\n",
       "            config.thumbnailBoxHeight = 7 * (12 / config.totalHeads);\n",
       "            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n",
       "            config.thumbnailHeight = Math.max(config.leftText.length, config.rightText.length) * config.thumbnailBoxHeight + 2 * THUMBNAIL_PADDING;\n",
       "            config.thumbnailWidth = (DIV_WIDTH - axisSize) / config.totalHeads;\n",
       "            config.detailHeight = Math.max(config.leftText.length, config.rightText.length) * DETAIL_BOX_HEIGHT + 2 * DETAIL_PADDING + DETAIL_HEADING_HEIGHT;\n",
       "            config.divHeight = Math.max(config.numLayers * config.thumbnailHeight + axisSize, config.detailHeight);\n",
       "\n",
       "            const vis = $(`#${config.rootDivId} #vis`)\n",
       "            vis.empty();\n",
       "            vis.attr(\"height\", config.divHeight);\n",
       "            config.svg = d3.select(`#${config.rootDivId} #vis`)\n",
       "                .append('svg')\n",
       "                .attr(\"width\", DIV_WIDTH)\n",
       "                .attr(\"height\", config.divHeight)\n",
       "                .attr(\"fill\", getBackgroundColor());\n",
       "\n",
       "            renderAxisLabels();\n",
       "\n",
       "            var i;\n",
       "            var j;\n",
       "            for (i = 0; i < config.numLayers; i++) {\n",
       "                for (j = 0; j < config.numHeads; j++) {\n",
       "                    renderThumbnail(i, j);\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "\n",
       "        function renderAxisLabels() {\n",
       "            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n",
       "            const tableWidth = config.thumbnailWidth * config.heads.length;\n",
       "            config.svg.append(\"text\")\n",
       "                .text(\"Heads\")\n",
       "                .attr(\"fill\", \"black\")\n",
       "                .attr(\"font-weight\", \"bold\")\n",
       "                .attr(\"font-size\", HEADING_TEXT_SIZE + \"px\")\n",
       "                .attr(\"x\", axisSize + tableWidth / 2)\n",
       "                .attr(\"text-anchor\", \"middle\")\n",
       "                .attr(\"y\", 0)\n",
       "                .attr(\"dy\", HEADING_TEXT_SIZE);\n",
       "            for (let i = 0; i < config.numHeads; i++) {\n",
       "                config.svg.append(\"text\")\n",
       "                    .text(config.heads[i])\n",
       "                    .attr(\"fill\", \"black\")\n",
       "                    .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
       "                    .attr(\"x\", axisSize + (i + .5) * config.thumbnailWidth)\n",
       "                    .attr(\"text-anchor\", \"middle\")\n",
       "                    .attr(\"y\", HEADING_TEXT_SIZE + HEADING_PADDING)\n",
       "                    .attr(\"dy\", TEXT_SIZE);\n",
       "            }\n",
       "            let x = 0;\n",
       "            let y = axisSize + config.thumbnailHeight * config.layers.length / 2;\n",
       "            console.log(\"x\", x, y)\n",
       "            config.svg.append(\"text\")\n",
       "                .text(\"Layers\")\n",
       "                .attr(\"fill\", \"black\")\n",
       "                .attr(\"font-weight\", \"bold\")\n",
       "                .attr(\"transform\", \"rotate(270, \" + x  + \", \" + y + \")\")\n",
       "                .attr(\"font-size\", HEADING_TEXT_SIZE + \"px\")\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"text-anchor\", \"middle\")\n",
       "                .attr(\"y\", y)\n",
       "                .attr(\"dy\", HEADING_TEXT_SIZE);\n",
       "            for (let i = 0; i < config.numLayers; i++) {\n",
       "                x = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE; // HACK\n",
       "                y = axisSize + (i + .5) * config.thumbnailHeight;\n",
       "                config.svg.append(\"text\")\n",
       "                    .text(config.layers[i])\n",
       "                    .attr(\"fill\", \"black\")\n",
       "                    .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
       "                    .attr(\"x\", x)\n",
       "                    .attr(\"text-anchor\", \"end\")\n",
       "                    .attr(\"y\", y)\n",
       "                    .attr(\"dy\", TEXT_SIZE / 2);\n",
       "            }\n",
       "        }\n",
       "\n",
       "\n",
       "        function renderThumbnail(layerIndex, headIndex) {\n",
       "            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING\n",
       "            const x = headIndex * config.thumbnailWidth + axisSize;\n",
       "            const y = layerIndex * config.thumbnailHeight + axisSize;\n",
       "            renderThumbnailAttn(x, y, config.attn[layerIndex][headIndex], layerIndex, headIndex);\n",
       "        }\n",
       "\n",
       "        function renderDetail(att, layerIndex, headIndex) {\n",
       "            const axisSize = TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n",
       "            var xOffset = .8 * config.thumbnailWidth;\n",
       "            var maxX = DIV_WIDTH;\n",
       "            var maxY = config.divHeight - 3;\n",
       "            var leftPos = axisSize + headIndex * config.thumbnailWidth;\n",
       "            var x = leftPos + THUMBNAIL_PADDING + xOffset;\n",
       "            if (x < MIN_X) {\n",
       "                x = MIN_X;\n",
       "            } else if (x + DETAIL_WIDTH > maxX) {\n",
       "                x = leftPos + THUMBNAIL_PADDING - DETAIL_WIDTH + 8;\n",
       "            }\n",
       "            var posLeftText = x;\n",
       "            var posAttention = posLeftText + DETAIL_BOX_WIDTH;\n",
       "            var posRightText = posAttention + DETAIL_ATTENTION_WIDTH;\n",
       "            var thumbnailHeight = Math.max(config.leftText.length, config.rightText.length) * config.thumbnailBoxHeight + 2 * THUMBNAIL_PADDING;\n",
       "            var yOffset = 20;\n",
       "            var y = layerIndex * thumbnailHeight + THUMBNAIL_PADDING + yOffset;\n",
       "            if (y < MIN_Y) {\n",
       "                y = MIN_Y;\n",
       "            } else if (y + config.detailHeight > maxY) {\n",
       "                y = maxY - config.detailHeight;\n",
       "            }\n",
       "            renderDetailFrame(x, y, layerIndex);\n",
       "            y = y + DETAIL_PADDING;\n",
       "            renderDetailHeading(x, y, layerIndex, headIndex);\n",
       "            y = y + DETAIL_HEADING_HEIGHT;\n",
       "            renderDetailText(config.leftText, \"leftText\", posLeftText, y , layerIndex);\n",
       "            renderDetailAttn(posAttention, y, att, layerIndex, headIndex);\n",
       "            renderDetailText(config.rightText, \"rightText\", posRightText, y, layerIndex);\n",
       "        }\n",
       "\n",
       "        function renderDetailHeading(x, y, layerIndex, headIndex) {\n",
       "            var fillColor = getTextColor();\n",
       "            config.svg.append(\"text\")\n",
       "                .classed(\"detail\", true)\n",
       "                .text('Layer ' + config.layers[layerIndex] + \", Head \" + config.heads[headIndex])\n",
       "                .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
       "                .attr(\"font-weight\", \"bold\")\n",
       "                .style(\"cursor\", \"default\")\n",
       "                .style(\"-webkit-user-select\", \"none\")\n",
       "                .attr(\"fill\", fillColor)\n",
       "                .attr(\"x\", x + DETAIL_WIDTH / 2)\n",
       "                .attr(\"text-anchor\", \"middle\")\n",
       "                .attr(\"y\", y)\n",
       "                .attr(\"height\", DETAIL_HEADING_HEIGHT)\n",
       "                .attr(\"width\", DETAIL_WIDTH)\n",
       "                .attr(\"dy\", HEADING_TEXT_SIZE);\n",
       "        }\n",
       "\n",
       "        function renderDetailText(text, id, x, y, layerIndex) {\n",
       "            var tokenContainer = config.svg.append(\"svg:g\")\n",
       "                .classed(\"detail\", true)\n",
       "                .selectAll(\"g\")\n",
       "                .data(text)\n",
       "                .enter()\n",
       "                .append(\"g\");\n",
       "\n",
       "            var fillColor = getTextColor();\n",
       "\n",
       "            tokenContainer.append(\"rect\")\n",
       "                .classed(\"highlight\", true)\n",
       "                .attr(\"fill\", fillColor)\n",
       "                .style(\"opacity\", 0.0)\n",
       "                .attr(\"height\", DETAIL_BOX_HEIGHT)\n",
       "                .attr(\"width\", DETAIL_BOX_WIDTH)\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"y\", function (d, i) {\n",
       "                    return y + i * DETAIL_BOX_HEIGHT;\n",
       "                });\n",
       "\n",
       "            var textContainer = tokenContainer.append(\"text\")\n",
       "                .classed(\"token\", true)\n",
       "                .text(function (d) {\n",
       "                    return d;\n",
       "                })\n",
       "                .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
       "                .style(\"cursor\", \"default\")\n",
       "                .style(\"-webkit-user-select\", \"none\")\n",
       "                .attr(\"fill\", fillColor)\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"y\", function (d, i) {\n",
       "                    return i * DETAIL_BOX_HEIGHT + y;\n",
       "                })\n",
       "                .attr(\"height\", DETAIL_BOX_HEIGHT)\n",
       "                .attr(\"width\", DETAIL_BOX_WIDTH)\n",
       "                .attr(\"dy\", TEXT_SIZE);\n",
       "\n",
       "            if (id == \"leftText\") {\n",
       "                textContainer.style(\"text-anchor\", \"end\")\n",
       "                    .attr(\"dx\", DETAIL_BOX_WIDTH - 2);\n",
       "                tokenContainer.on(\"mouseover\", function (d, index) {\n",
       "                    highlightSelection(index);\n",
       "                });\n",
       "                tokenContainer.on(\"mouseleave\", function () {\n",
       "                    unhighlightSelection();\n",
       "                });\n",
       "            }\n",
       "        }\n",
       "\n",
       "        function highlightSelection(index) {\n",
       "            config.svg.select(\"#leftText\")\n",
       "                .selectAll(\".highlight\")\n",
       "                .style(\"opacity\", function (d, i) {\n",
       "                    return i == index ? 1.0 : 0.0;\n",
       "                });\n",
       "            config.svg.selectAll(\".attn-line-group\")\n",
       "                .style(\"opacity\", function (d, i) {\n",
       "                    return i == index ? 1.0 : 0.0;\n",
       "                });\n",
       "        }\n",
       "\n",
       "        function unhighlightSelection() {\n",
       "            config.svg.select(\"#leftText\")\n",
       "                .selectAll(\".highlight\")\n",
       "                .style(\"opacity\", 0.0);\n",
       "            config.svg.selectAll(\".attn-line-group\")\n",
       "                .style(\"opacity\", 1);\n",
       "        }\n",
       "\n",
       "        function renderThumbnailAttn(x, y, att, layerIndex, headIndex) {\n",
       "\n",
       "            var attnContainer = config.svg.append(\"svg:g\");\n",
       "\n",
       "            var attnBackground = attnContainer.append(\"rect\")\n",
       "                .attr(\"id\", 'attn_background_' + layerIndex + \"_\" + headIndex)\n",
       "                .classed(\"attn_background\", true)\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"y\", y)\n",
       "                .attr(\"height\", config.thumbnailHeight)\n",
       "                .attr(\"width\", config.thumbnailWidth)\n",
       "                .attr(\"stroke-width\", 2)\n",
       "                .attr(\"stroke\", getLayerColor(layerIndex))\n",
       "                .attr(\"stroke-opacity\", 0)\n",
       "                .attr(\"fill\", getBackgroundColor());\n",
       "            var x1 = x + THUMBNAIL_PADDING;\n",
       "            var x2 = x1 + config.thumbnailWidth - 14;\n",
       "            var y1 = y + THUMBNAIL_PADDING;\n",
       "\n",
       "            attnContainer.selectAll(\"g\")\n",
       "                .data(att)\n",
       "                .enter()\n",
       "                .append(\"g\") // Add group for each source token\n",
       "                .attr(\"source-index\", function (d, i) { // Save index of source token\n",
       "                    return i;\n",
       "                })\n",
       "                .selectAll(\"line\")\n",
       "                .data(function (d) { // Loop over all target tokens\n",
       "                    return d;\n",
       "                })\n",
       "                .enter() // When entering\n",
       "                .append(\"line\")\n",
       "                .attr(\"x1\", x1)\n",
       "                .attr(\"y1\", function (d) {\n",
       "                    var sourceIndex = +this.parentNode.getAttribute(\"source-index\");\n",
       "                    return y1 + (sourceIndex + .5) * config.thumbnailBoxHeight;\n",
       "                })\n",
       "                .attr(\"x2\", x2)\n",
       "                .attr(\"y2\", function (d, targetIndex) {\n",
       "                    return y1 + (targetIndex + .5) * config.thumbnailBoxHeight;\n",
       "                })\n",
       "                .attr(\"stroke-width\", 2.2)\n",
       "                .attr(\"stroke\", getLayerColor(layerIndex))\n",
       "                .attr(\"stroke-opacity\", function (d) {\n",
       "                    return d;\n",
       "                });\n",
       "\n",
       "            var clickRegion = attnContainer.append(\"rect\")\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"y\", y)\n",
       "                .attr(\"height\", config.thumbnailHeight)\n",
       "                .attr(\"width\", config.thumbnailWidth)\n",
       "                .style(\"opacity\", 0);\n",
       "\n",
       "            clickRegion.on(\"click\", function (d, index) {\n",
       "                var attnBackgroundOther = config.svg.selectAll(\".attn_background\");\n",
       "                attnBackgroundOther.attr(\"fill\", getBackgroundColor());\n",
       "                attnBackgroundOther.attr(\"stroke-opacity\", 0);\n",
       "\n",
       "                config.svg.selectAll(\".detail\").remove();\n",
       "                if (config.detail_layer != layerIndex || config.detail_head != headIndex) {\n",
       "                    renderDetail(att, layerIndex, headIndex);\n",
       "                    config.detail_layer = layerIndex;\n",
       "                    config.detail_head = headIndex;\n",
       "                    attnBackground.attr(\"fill\", getHighlightColor());\n",
       "                    attnBackground.attr(\"stroke-opacity\", .8);\n",
       "                } else {\n",
       "                    config.detail_layer = null;\n",
       "                    config.detail_head = null;\n",
       "                    attnBackground.attr(\"fill\", getBackgroundColor());\n",
       "                    attnBackground.attr(\"stroke-opacity\", 0);\n",
       "                }\n",
       "            });\n",
       "\n",
       "            clickRegion.on(\"mouseover\", function (d) {\n",
       "                d3.select(this).style(\"cursor\", \"pointer\");\n",
       "            });\n",
       "        }\n",
       "\n",
       "        function renderDetailFrame(x, y, layerIndex) {\n",
       "            var detailFrame = config.svg.append(\"rect\")\n",
       "                .classed(\"detail\", true)\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"y\", y)\n",
       "                .attr(\"height\", config.detailHeight)\n",
       "                .attr(\"width\", DETAIL_WIDTH)\n",
       "                .style(\"opacity\", 1)\n",
       "                .attr(\"stroke-width\", 1.5)\n",
       "                .attr(\"stroke-opacity\", 0.7)\n",
       "                .attr(\"stroke\", getLayerColor(layerIndex));\n",
       "        }\n",
       "\n",
       "        function renderDetailAttn(x, y, att, layerIndex) {\n",
       "            var attnContainer = config.svg.append(\"svg:g\")\n",
       "                .classed(\"detail\", true)\n",
       "                .attr(\"pointer-events\", \"none\");\n",
       "            attnContainer.selectAll(\"g\")\n",
       "                .data(att)\n",
       "                .enter()\n",
       "                .append(\"g\") // Add group for each source token\n",
       "                .classed('attn-line-group', true)\n",
       "                .attr(\"source-index\", function (d, i) { // Save index of source token\n",
       "                    return i;\n",
       "                })\n",
       "                .selectAll(\"line\")\n",
       "                .data(function (d) { // Loop over all target tokens\n",
       "                    return d;\n",
       "                })\n",
       "                .enter()\n",
       "                .append(\"line\")\n",
       "                .attr(\"x1\", x + ATTN_PADDING)\n",
       "                .attr(\"y1\", function (d) {\n",
       "                    var sourceIndex = +this.parentNode.getAttribute(\"source-index\");\n",
       "                    return y + (sourceIndex + .5) * DETAIL_BOX_HEIGHT;\n",
       "                })\n",
       "                .attr(\"x2\", x + DETAIL_ATTENTION_WIDTH - ATTN_PADDING)\n",
       "                .attr(\"y2\", function (d, targetIndex) {\n",
       "                    return y + (targetIndex + .5) * DETAIL_BOX_HEIGHT;\n",
       "                })\n",
       "                .attr(\"stroke-width\", 2.2)\n",
       "                .attr(\"stroke\", getLayerColor(layerIndex))\n",
       "                .attr(\"stroke-opacity\", function (d) {\n",
       "                    return d;\n",
       "                });\n",
       "        }\n",
       "\n",
       "        function getLayerColor(layer) {\n",
       "          return LAYER_COLORS[config.layers[layer] % 10];\n",
       "        }\n",
       "\n",
       "        function getTextColor() {\n",
       "            return PALETTE[config.mode]['text']\n",
       "        }\n",
       "\n",
       "        function getBackgroundColor() {\n",
       "           return PALETTE[config.mode]['background']\n",
       "        }\n",
       "\n",
       "        function getHighlightColor() {\n",
       "           return PALETTE[config.mode]['highlight']\n",
       "        }\n",
       "\n",
       "        function initialize() {\n",
       "            config.attention = params['attention'];\n",
       "            config.filter = params['default_filter'];\n",
       "            config.mode = params['display_mode'];\n",
       "            config.layers = params['include_layers']\n",
       "            config.heads = params['include_heads']\n",
       "            config.totalHeads = params['total_heads']\n",
       "            config.rootDivId = params['root_div_id'];\n",
       "            $(`#${config.rootDivId} #filter`).on('change', function (e) {\n",
       "                config.filter = e.currentTarget.value;\n",
       "                render();\n",
       "            });\n",
       "        }\n",
       "\n",
       "        initialize();\n",
       "        render();\n",
       "\n",
       "    });"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, utils, AutoModelForCausalLM\n",
    "\n",
    "from bertviz import model_view\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
    "\n",
    "model_name = 'openai-community/gpt2'\n",
    "input_text = \"No, I am your father\"  \n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, output_attentions=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "inputs = tokenizer.encode(input_text, return_tensors='pt')  # Tokenize input text\n",
    "outputs = model(inputs)  # Run model\n",
    "attention = outputs[-1]  # Retrieve attention from model outputs\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # Convert input ids to token strings\n",
    "model_view(attention, tokens)  # Display model view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFq78-kjbrWp"
   },
   "source": [
    "Last week, Carlo discussed token embedding, which is when words are encoded into a vocabulary. Now, we just discussed attention mechanisms which account for context between words. Another question we should ask is how do we account for the order of words in an input sentence\n",
    "\n",
    "Consider the following two sentences to see why this is important:\n",
    "\n",
    "``The man ate the sandwich.``\n",
    "\n",
    "``The sandwich ate the man.``\n",
    "\n",
    "Clearly, these are two vastly different situations even though they have the same words. The Transformer can \n",
    "\n",
    "Transformers differentiate between these situations by adding a **Positional encoding** vector to each input embedding. These vectors follow a specific pattern that the model learns, which helps it determine the position of each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/positional_encoding.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "Image credit: https://medium.com/@xuer.chen.human/llm-study-notes-positional-encoding-0639a1002ec0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up positional encoding similarly as token embedding using the ``nn.Embedding`` tool. We use a simple embedding here but there are more complex positional encodings used such as sinusoidal. \n",
    "\n",
    "For an explanation of different positional encodings, refer to this post: https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 65\n",
    "n_embd = 64\n",
    "\n",
    "token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "position_embedding_table = nn.Embedding(block_size, n_embd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice the positional encoding size is `(block_size, n_embed)` because it encodes for the postion of a token within the sequence of size `block_size`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the position embedding used is simply added to the token embedding to apply positional embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at token embedding alone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9.6630e-05, -1.4031e+00,  6.1625e-01,  3.0717e-02,  1.2290e-01,\n",
      "        -4.0682e-01,  1.9496e+00,  1.1764e+00, -1.5591e+00,  7.2791e-02,\n",
      "        -2.3081e+00, -5.0737e-01, -6.9863e-01, -1.3517e+00, -2.1065e-02,\n",
      "        -9.5309e-01, -1.0516e+00,  7.7541e-02,  4.4402e-01,  8.8709e-01,\n",
      "         1.8823e-01,  7.1672e-02, -3.4917e-01, -5.7223e-01,  3.5027e-01,\n",
      "         7.1300e-01, -4.1757e-01,  1.2332e+00, -1.0018e+00,  6.6873e-01,\n",
      "         9.4601e-03, -1.8759e+00,  3.9894e-01,  6.6391e-01,  6.4071e-02,\n",
      "         1.6804e+00,  6.2182e-01, -1.6898e+00, -3.4645e-01, -3.1754e+00,\n",
      "         9.4335e-01,  1.7508e+00, -7.7534e-01, -8.0301e-01,  2.6676e+00,\n",
      "         3.1534e-01, -5.9224e-01,  4.7193e-01,  6.4641e-01,  4.3199e-01,\n",
      "         1.4329e+00, -1.0546e+00,  1.6986e+00, -1.2204e+00, -1.2765e-02,\n",
      "        -1.3485e+00, -4.3946e-01, -1.3725e-01,  4.2354e-01, -4.0840e-01,\n",
      "        -7.1900e-01, -6.6362e-01, -8.9380e-02,  1.4980e-01],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,3,15,4,7,1,4,9])\n",
    "x = token_embedding_table(x)\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And token + positional embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6103, -1.1454,  0.2832, -0.5627, -0.7867, -0.7475,  1.6190,  0.4168,\n",
      "        -2.4363,  0.1630, -2.2069,  0.1004,  0.3215, -0.9887, -0.2308,  0.1534,\n",
      "        -1.2566, -0.2798, -0.0496, -0.0997,  0.9740,  0.4581,  0.7802, -0.1746,\n",
      "         0.0531, -1.5154,  0.3336,  2.4084, -1.0335,  1.3728, -1.2628, -0.5919,\n",
      "         0.2460, -0.2431,  2.1009,  0.5958, -0.4106, -2.4724, -1.7571, -3.5932,\n",
      "         0.4605,  0.8671, -1.9192, -3.0066,  1.6024, -1.5752,  0.7494,  0.8431,\n",
      "         2.0244,  1.0557,  0.2076,  0.2220,  0.2793, -2.0823,  0.6992, -1.1937,\n",
      "        -0.3509,  0.8347,  1.0244,  0.5620, -0.3641, -1.3770, -0.1733, -1.4676],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,3,15,4,7,1,4,9])\n",
    "x= position_embedding_table(x) + token_embedding_table(x)\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see a clear offset between these two embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training process, these embeddings will be learned to best encode the token and positional embeddings of the sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iF1HzH9xNJ7S"
   },
   "source": [
    "## Output layers\n",
    "\n",
    "At the end of our Transformer model, we are left with a vector, so how do we turn this into a word?\n",
    "\n",
    "<img src=\"images/transformer-decoder-intro.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Using a final Linear layer and a Softmax Layer.\n",
    "The Linear layer projects the vector produced by the stack of decoders, into a larger vector called a logits vector.\n",
    "\n",
    "If our model knows 10,000 unique English words learned from its training dataset the logits vector is 10,000 cells wide ‚Äì each cell corresponds to the score of a unique word.\n",
    "\n",
    "The softmax layer turns those scores into probabilities. The cell with the highest probability is chosen, and the word associated with it is produced as the output for this time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transformer_decoder_output_softmax.png\" alt=\"Drawing\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HS6r-z8dN_RV"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XK8q67P03yr4"
   },
   "source": [
    "## Training\n",
    "\n",
    "How does an LLM improve over time?\n",
    "We want to compare the probabilitiy distribution for each token generated by our model to the ground truths. \n",
    "Our model produces a probability distribution for each token. We want to compare these probability distributions to the ground truths. \n",
    "For example, when translating the sentence: ‚Äúje suis √©tudiant‚Äù into ‚Äúi am a student‚Äù as can be seen in the example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/output_target_probability_distributions.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HS6r-z8dN_RV"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can calculate the loss between the vector it generates and the ground truth vector seen in this example. A commonly used loss function is cross entropy loss:\n",
    "\n",
    "$CE = -\\sum_{x \\in X} p(x) log q(x)$\n",
    "\n",
    "where p(x) represents the true distribution and q(x) represents the predicted distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9119)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "logits = torch.tensor([0.5, 0.1, 0.3])\n",
    "targets = torch.tensor([1.0, 0.0, 0.0])\n",
    "loss = F.cross_entropy(logits, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important metric commonly used in LLMs is **perplexity**.\n",
    "\n",
    "Intuitively, perplexity means to be surprised. We measure how much the model is surprised by seeing new data. The lower the perplexity, the better the training is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, perplexity is just the exponent of the negative cross entropy loss:\n",
    "\n",
    "$\\text{perplexity} = exp(\\text{CE})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4891)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are using cross entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train a mini-LLM from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 10\n",
    "learning_rate = 1e-3\n",
    "device = 'cpu' #'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4 ## so head_size = 16\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data and create train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to be using the tiny Shakespeare dataset. \n",
    "Data is tokenized according to a simple character based tokenizer.\n",
    "Data is split into a train and test set so we have something to test after performing training (9:1 split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the components of the Decoder block: \n",
    "* MultiHeadAttention\n",
    "* FeedForward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C) 16,32,16\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd), # Projection layer going back into the residual pathway\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine components into the Decoder block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))    # Communication\n",
    "        x = x + self.ffwd(self.ln2(x))  # Computation\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the full Transformer model \n",
    "This is a combination of the Token embeddings, Positional embeddings, a stack of Transformer blocks and an output block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super simple language model\n",
    "class LanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be training a larger LLM on distributed resources in session 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "1. In this notebook, we learned the various components of an LLM. \n",
    "    Your homework this week is to take the mini LLM we created from scratch and run your own training loop. Show how the training and validation perplexity change over the steps.\n",
    "      \n",
    "    Hint: this function might be useful for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run the same training loop but modify one of the hyperparameters from this list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': tensor(2.5088), 'val': tensor(2.5273)}\n",
      "{'train': tensor(2.3723), 'val': tensor(2.3877)}\n",
      "{'train': tensor(2.2762), 'val': tensor(2.2886)}\n",
      "{'train': tensor(2.1895), 'val': tensor(2.2079)}\n",
      "{'train': tensor(2.1121), 'val': tensor(2.1509)}\n",
      "{'train': tensor(2.0642), 'val': tensor(2.1198)}\n",
      "{'train': tensor(2.0062), 'val': tensor(2.0678)}\n",
      "{'train': tensor(1.9603), 'val': tensor(2.0357)}\n",
      "{'train': tensor(1.9257), 'val': tensor(2.0108)}\n",
      "{'train': tensor(1.8845), 'val': tensor(1.9834)}\n",
      "{'train': tensor(1.8586), 'val': tensor(1.9533)}\n",
      "{'train': tensor(1.8298), 'val': tensor(1.9456)}\n",
      "{'train': tensor(1.8138), 'val': tensor(1.9480)}\n",
      "{'train': tensor(1.7928), 'val': tensor(1.9235)}\n",
      "{'train': tensor(1.7736), 'val': tensor(1.9109)}\n",
      "{'train': tensor(1.7466), 'val': tensor(1.9031)}\n",
      "{'train': tensor(1.7437), 'val': tensor(1.8832)}\n",
      "{'train': tensor(1.7485), 'val': tensor(1.8915)}\n",
      "{'train': tensor(1.7195), 'val': tensor(1.8522)}\n",
      "{'train': tensor(1.7095), 'val': tensor(1.8493)}\n",
      "{'train': tensor(1.6982), 'val': tensor(1.8510)}\n",
      "{'train': tensor(1.6887), 'val': tensor(1.8358)}\n",
      "{'train': tensor(1.6696), 'val': tensor(1.8260)}\n",
      "{'train': tensor(1.6687), 'val': tensor(1.8142)}\n",
      "{'train': tensor(1.6761), 'val': tensor(1.8176)}\n",
      "{'train': tensor(1.6428), 'val': tensor(1.7964)}\n",
      "{'train': tensor(1.6566), 'val': tensor(1.8115)}\n",
      "{'train': tensor(1.6427), 'val': tensor(1.8241)}\n",
      "{'train': tensor(1.6333), 'val': tensor(1.8016)}\n",
      "{'train': tensor(1.6212), 'val': tensor(1.7970)}\n",
      "Training first model --> DONE\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "def train_one_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    for k in range(eval_iters):\n",
    "        X, Y = get_batch('train')\n",
    "        logits, loss = model(X, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "### FIRST MODEL ###\n",
    "\n",
    "# hyperparameters\n",
    "n_embd = 64\n",
    "n_head = 4 \n",
    "n_layer = 4\n",
    "n_epochs = 30\n",
    "\n",
    "train_history_1 = []\n",
    "val_history_1 = []\n",
    "\n",
    "model_1 = LanguageModel()\n",
    "optimizer_1 = torch.optim.AdamW(model_1.parameters(), learning_rate)\n",
    "    \n",
    "for j in range(n_epochs):\n",
    "    train_one_epoch(model_1, optimizer_1)\n",
    "    losses = estimate_loss(model_1)\n",
    "    train_history_1.append(losses['train'].item())\n",
    "    val_history_1.append(losses['val'].item())\n",
    "    print(losses)\n",
    "\n",
    "print('Training first model --> DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': tensor(2.2286), 'val': tensor(2.2570)}\n",
      "{'train': tensor(2.0223), 'val': tensor(2.0816)}\n",
      "{'train': tensor(1.9003), 'val': tensor(2.0184)}\n",
      "{'train': tensor(1.8424), 'val': tensor(1.9453)}\n",
      "{'train': tensor(1.7948), 'val': tensor(1.9199)}\n",
      "{'train': tensor(1.7441), 'val': tensor(1.8924)}\n",
      "{'train': tensor(1.7108), 'val': tensor(1.8499)}\n",
      "{'train': tensor(1.6844), 'val': tensor(1.8405)}\n",
      "{'train': tensor(1.6600), 'val': tensor(1.8294)}\n",
      "{'train': tensor(1.6525), 'val': tensor(1.8176)}\n",
      "{'train': tensor(1.6257), 'val': tensor(1.7959)}\n",
      "{'train': tensor(1.6192), 'val': tensor(1.7918)}\n",
      "{'train': tensor(1.5816), 'val': tensor(1.7514)}\n",
      "{'train': tensor(1.5982), 'val': tensor(1.7682)}\n",
      "{'train': tensor(1.5717), 'val': tensor(1.7513)}\n",
      "{'train': tensor(1.5617), 'val': tensor(1.7527)}\n",
      "{'train': tensor(1.5530), 'val': tensor(1.7323)}\n",
      "{'train': tensor(1.5438), 'val': tensor(1.7214)}\n",
      "{'train': tensor(1.5366), 'val': tensor(1.7287)}\n",
      "{'train': tensor(1.5360), 'val': tensor(1.7019)}\n",
      "{'train': tensor(1.5321), 'val': tensor(1.7091)}\n",
      "{'train': tensor(1.5035), 'val': tensor(1.7091)}\n",
      "{'train': tensor(1.5069), 'val': tensor(1.6978)}\n",
      "{'train': tensor(1.5109), 'val': tensor(1.7042)}\n",
      "{'train': tensor(1.4914), 'val': tensor(1.6992)}\n",
      "{'train': tensor(1.4984), 'val': tensor(1.6816)}\n",
      "{'train': tensor(1.4966), 'val': tensor(1.6814)}\n",
      "{'train': tensor(1.4820), 'val': tensor(1.6778)}\n",
      "{'train': tensor(1.4800), 'val': tensor(1.6865)}\n",
      "{'train': tensor(1.4706), 'val': tensor(1.6628)}\n",
      "Training second model --> DONE\n"
     ]
    }
   ],
   "source": [
    "### SECOND MODEL ###\n",
    "\n",
    "# hyperparameters\n",
    "n_embd = 256\n",
    "n_head = 4 \n",
    "n_layer = 4\n",
    "n_epochs = 30\n",
    "\n",
    "train_history_2 = []\n",
    "val_history_2 = []\n",
    "\n",
    "model_2 = LanguageModel()\n",
    "optimizer_2 = torch.optim.AdamW(model_2.parameters(), learning_rate)\n",
    "    \n",
    "for j in range(n_epochs):\n",
    "    train_one_epoch(model_2, optimizer_2)\n",
    "    losses = estimate_loss(model_2)\n",
    "    train_history_2.append(losses['train'].item())\n",
    "    val_history_2.append(losses['val'].item())\n",
    "    print(losses)\n",
    "    \n",
    "print('Training second model --> DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': tensor(2.5263), 'val': tensor(2.5395)}\n",
      "{'train': tensor(2.3994), 'val': tensor(2.4116)}\n",
      "{'train': tensor(2.3084), 'val': tensor(2.3236)}\n",
      "{'train': tensor(2.2260), 'val': tensor(2.2418)}\n",
      "{'train': tensor(2.1594), 'val': tensor(2.1828)}\n",
      "{'train': tensor(2.1089), 'val': tensor(2.1454)}\n",
      "{'train': tensor(2.0599), 'val': tensor(2.1045)}\n",
      "{'train': tensor(2.0210), 'val': tensor(2.0768)}\n",
      "{'train': tensor(1.9631), 'val': tensor(2.0355)}\n",
      "{'train': tensor(1.9308), 'val': tensor(2.0201)}\n",
      "{'train': tensor(1.9145), 'val': tensor(2.0023)}\n",
      "{'train': tensor(1.8808), 'val': tensor(1.9889)}\n",
      "{'train': tensor(1.8628), 'val': tensor(1.9919)}\n",
      "{'train': tensor(1.8388), 'val': tensor(1.9798)}\n",
      "{'train': tensor(1.8240), 'val': tensor(1.9680)}\n",
      "{'train': tensor(1.8208), 'val': tensor(1.9428)}\n",
      "{'train': tensor(1.7979), 'val': tensor(1.9189)}\n",
      "{'train': tensor(1.7734), 'val': tensor(1.9105)}\n",
      "{'train': tensor(1.7652), 'val': tensor(1.9000)}\n",
      "{'train': tensor(1.7498), 'val': tensor(1.9005)}\n",
      "{'train': tensor(1.7366), 'val': tensor(1.8892)}\n",
      "{'train': tensor(1.7301), 'val': tensor(1.8778)}\n",
      "{'train': tensor(1.7209), 'val': tensor(1.8675)}\n",
      "{'train': tensor(1.7100), 'val': tensor(1.8558)}\n",
      "{'train': tensor(1.7133), 'val': tensor(1.8555)}\n",
      "{'train': tensor(1.6814), 'val': tensor(1.8415)}\n",
      "{'train': tensor(1.6815), 'val': tensor(1.8430)}\n",
      "{'train': tensor(1.6829), 'val': tensor(1.8499)}\n",
      "{'train': tensor(1.6691), 'val': tensor(1.8387)}\n",
      "{'train': tensor(1.6700), 'val': tensor(1.8286)}\n",
      "Training third model --> DONE\n"
     ]
    }
   ],
   "source": [
    "### THIRD MODEL ###\n",
    "\n",
    "# hyperparameters\n",
    "n_embd = 64\n",
    "n_head = 16 \n",
    "n_layer = 4\n",
    "n_epochs = 30\n",
    "\n",
    "train_history_3 = []\n",
    "val_history_3 = []\n",
    "\n",
    "model_3 = LanguageModel()\n",
    "optimizer_3 = torch.optim.AdamW(model_3.parameters(), learning_rate)\n",
    "    \n",
    "for j in range(n_epochs):\n",
    "    train_one_epoch(model_3, optimizer_3)\n",
    "    losses = estimate_loss(model_3)\n",
    "    train_history_3.append(losses['train'].item())\n",
    "    val_history_3.append(losses['val'].item())\n",
    "    print(losses)\n",
    "    \n",
    "print('Training third model --> DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': tensor(2.4849), 'val': tensor(2.4859)}\n",
      "{'train': tensor(2.3297), 'val': tensor(2.3319)}\n",
      "{'train': tensor(2.2246), 'val': tensor(2.2437)}\n",
      "{'train': tensor(2.1378), 'val': tensor(2.1644)}\n",
      "{'train': tensor(2.0586), 'val': tensor(2.1068)}\n",
      "{'train': tensor(2.0013), 'val': tensor(2.0558)}\n",
      "{'train': tensor(1.9607), 'val': tensor(2.0261)}\n",
      "{'train': tensor(1.9060), 'val': tensor(1.9962)}\n",
      "{'train': tensor(1.8405), 'val': tensor(1.9633)}\n",
      "{'train': tensor(1.8355), 'val': tensor(1.9360)}\n",
      "{'train': tensor(1.7974), 'val': tensor(1.9256)}\n",
      "{'train': tensor(1.7803), 'val': tensor(1.8997)}\n",
      "{'train': tensor(1.7468), 'val': tensor(1.8784)}\n",
      "{'train': tensor(1.7484), 'val': tensor(1.8805)}\n",
      "{'train': tensor(1.7308), 'val': tensor(1.8571)}\n",
      "{'train': tensor(1.7039), 'val': tensor(1.8328)}\n",
      "{'train': tensor(1.6974), 'val': tensor(1.8343)}\n",
      "{'train': tensor(1.6750), 'val': tensor(1.8240)}\n",
      "{'train': tensor(1.6641), 'val': tensor(1.8063)}\n",
      "{'train': tensor(1.6581), 'val': tensor(1.8093)}\n",
      "{'train': tensor(1.6260), 'val': tensor(1.7806)}\n",
      "{'train': tensor(1.6332), 'val': tensor(1.7833)}\n",
      "{'train': tensor(1.6238), 'val': tensor(1.7998)}\n",
      "{'train': tensor(1.6228), 'val': tensor(1.8007)}\n",
      "{'train': tensor(1.6041), 'val': tensor(1.7790)}\n",
      "{'train': tensor(1.5973), 'val': tensor(1.7572)}\n",
      "{'train': tensor(1.5968), 'val': tensor(1.7623)}\n",
      "{'train': tensor(1.5978), 'val': tensor(1.7450)}\n",
      "{'train': tensor(1.5886), 'val': tensor(1.7572)}\n",
      "{'train': tensor(1.5807), 'val': tensor(1.7565)}\n",
      "Training fourth model --> DONE\n"
     ]
    }
   ],
   "source": [
    "### FOURTH MODEL ###\n",
    "\n",
    "# hyperparameters\n",
    "n_embd = 64\n",
    "n_head = 4 \n",
    "n_layer = 8\n",
    "n_epochs = 30\n",
    "\n",
    "train_history_4 = []\n",
    "val_history_4 = []\n",
    "\n",
    "model_4 = LanguageModel()\n",
    "optimizer_4 = torch.optim.AdamW(model_4.parameters(), learning_rate)\n",
    "    \n",
    "for j in range(n_epochs):\n",
    "    train_one_epoch(model_4, optimizer_4)\n",
    "    losses = estimate_loss(model_4)\n",
    "    train_history_4.append(losses['train'].item())\n",
    "    val_history_4.append(losses['val'].item())\n",
    "    print(losses)\n",
    "    \n",
    "print('Training fourth model --> DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 960x960 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize=(12,12), dpi = 80)\n",
    "x_axis = np.arange(0, len(train_history_1))\n",
    "\n",
    "train_perp_1 = np.asarray(train_history_1)\n",
    "val_perp_1 = np.asarray(val_history_1)\n",
    "train_perp_2 = np.asarray(train_history_2)\n",
    "val_perp_2 = np.asarray(val_history_2)\n",
    "train_perp_3 = np.asarray(train_history_3)\n",
    "val_perp_3 = np.asarray(val_history_3)\n",
    "train_perp_4 = np.asarray(train_history_4)\n",
    "val_perp_4 = np.asarray(val_history_4)\n",
    "\n",
    "# Plot perplexity for training and validation data over training steps \n",
    "ax[0][0].plot(x_axis, train_perp_1, label='Training')\n",
    "ax[0][0].plot(x_axis, val_perp_1, label='Validation')\n",
    "ax[0][1].plot(x_axis, train_perp_2, label='Training')\n",
    "ax[0][1].plot(x_axis, val_perp_2, label='Validation')\n",
    "ax[1][0].plot(x_axis, train_perp_3, label='Training')\n",
    "ax[1][0].plot(x_axis, val_perp_3, label='Validation')\n",
    "ax[1][1].plot(x_axis, train_perp_4, label='Training')\n",
    "ax[1][1].plot(x_axis, val_perp_4, label='Validation')\n",
    "\n",
    "# Set axis labels \n",
    "ax[0][0].set_ylim(1.4, 2.7)\n",
    "ax[0][0].set_title('Model 1')\n",
    "ax[0][0].set_xlabel('Epochs')\n",
    "ax[0][0].set_ylabel('Perplexity')\n",
    "ax[0][0].legend()\n",
    "ax[0][1].set_ylim(1.4, 2.7)\n",
    "ax[0][1].set_title('Model 2')\n",
    "ax[0][1].set_xlabel('Epochs')\n",
    "ax[0][1].set_ylabel('Perplexity')\n",
    "ax[0][1].legend()\n",
    "ax[1][0].set_ylim(1.4, 2.7)\n",
    "ax[1][0].set_title('Model 3')\n",
    "ax[1][0].set_xlabel('Epochs')\n",
    "ax[1][0].set_ylabel('Perplexity')\n",
    "ax[1][0].legend()\n",
    "ax[1][1].set_ylim(1.4, 2.7)\n",
    "ax[1][1].set_title('Model 4')\n",
    "ax[1][1].set_xlabel('Epochs')\n",
    "ax[1][1].set_ylabel('Perplexity')\n",
    "ax[1][1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation for the homework\n",
    "\n",
    "The change in perplexity is as expected, at the first couple of epochs, it is quite fast. It's followed by diminishing returns at subsequent epochs. At first, training and validation perplexity are also similar, but later diverging, as training perplexity becomes lower than validation. \n",
    "\n",
    "Model 2 with higher embedding performs the best, though it's difficult to say for certain, as this model also started with a lower perplexity of ~2.2 (rather than ~2.5 for the rest). This better performance might be a consequence of the slight head-start it had compared to the other models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am dying for my love, and I haOsT\n",
      "To call, unto\n",
      "I am dying for my love, and I am one might not al\n",
      "I am dying for my love, and In you;\n",
      "And-would sub\n",
      "I am dying for my love, and I amached far'd of th\n",
      "Why did the chicken crossat;\n",
      "As upon young di\n",
      "Why did the chicken crossing.\n",
      "Down sears you,\n",
      "Why did the chicken crossehs, I\n",
      "PAMPengering \n",
      "Why did the chicken cross himer ever\n",
      "Agains f\n",
      "Was it orange the color or the orange the fruit first in this such of seen;\n",
      "Traig\n",
      "Was it orange the color or the orange the fruit first in this prover of him.\n",
      "\n",
      "HER\n",
      "Was it orange the color or the orange the fruit first in this day and,\n",
      "This daes \n",
      "Was it orange the color or the orange the fruit first in this desome,\n",
      "I'll never \n"
     ]
    }
   ],
   "source": [
    "def text_generation(string_input, model, num_chars):\n",
    "    input_text = encode(string_input)\n",
    "    generated = list(model.generate(torch.tensor([input_text]), num_chars)[0])\n",
    "    generated = [i.item() for i in generated]\n",
    "    return decode(generated)\n",
    "    \n",
    "input_text = 'I am dying for my love, and I'\n",
    "    \n",
    "print(text_generation(input_text, model_1, 20))\n",
    "print(text_generation(input_text, model_2, 20))\n",
    "print(text_generation(input_text, model_3, 20))\n",
    "print(text_generation(input_text, model_4, 20))\n",
    "\n",
    "input_text = 'Why did the chicken cross'\n",
    "\n",
    "print(text_generation(input_text, model_1, 20))\n",
    "print(text_generation(input_text, model_2, 20))\n",
    "print(text_generation(input_text, model_3, 20))\n",
    "print(text_generation(input_text, model_4, 20))\n",
    "\n",
    "input_text = 'Was it orange the color or the orange the fruit first in this'\n",
    "\n",
    "print(text_generation(input_text, model_1, 20))\n",
    "print(text_generation(input_text, model_2, 20))\n",
    "print(text_generation(input_text, model_3, 20))\n",
    "print(text_generation(input_text, model_4, 20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be honest, I don't think any of the outputs make that much sense. But I think them not making sense, makes some sense, given our language model is very primitive, and it hasn't had extensive training. Even though it's trained on Shakespeare data, it doesn't sound like him at all :D \n",
    "\n",
    "Changing the hyperparameters between Model 1,2,3,4 didn't seem to have much of an effect in the end result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this at least 4 times with a different value and plot each perplexity over training step. Write a sentence on how the perplexity changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus 1: output some generated text from each model you trained. Did the output make more sense with some hyperparameters than others? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus 2: We saw a cool visualization of attention mechanisms with BertViz. Take a more complicated model than GPT2 such as \"meta-llama/Llama-2-7b-chat-hf\" and see how the attention mechanisms are different "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDXLTusqxXHf"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some recommendations for further reading and additional code for review.\n",
    "\n",
    "* \"The Illustrated Transformer\" by Jay Alammar\n",
    "* \"Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)\"\n",
    "* \"The Illustrated GPT-2 (Visualizing Transformer Language Models)\"\n",
    "* \"A gentle introduction to positional encoding\"\n",
    "* \"LLM Tutorial Workshop (Argonne National Laboratory)\"\n",
    "* \"LLM Tutorial Workshop Part 2 (Argonne National Laboratory)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "datascience/conda-2023-01-10",
   "language": "python",
   "name": "conda-2023-01-10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
